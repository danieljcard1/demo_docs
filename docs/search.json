[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Rhetorics",
    "section": "",
    "text": "This site is for use in WRIT 8520: Computational Rhetorics. The code and documentation found here is offered as is with no guarantee of utility for anyone in any context. Enjoy!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 02: Exploring TC journals (pt 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 03: Exploring TC journals, (pt 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 03: Exploring TC journals, (pt 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 05: Titles in TC Journals, pt. 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 05: Titles in TC Journals, pt. 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 06: Tracking ngrams in TC Research\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 08: Sentiment Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 09: Network Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 09: Network Analysis, pt 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWk 10: Reddit API\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "demos/week09/wk09_tidy_networks.html",
    "href": "demos/week09/wk09_tidy_networks.html",
    "title": "Wk 09: Network Analysis",
    "section": "",
    "text": "Web of Science Queries (articles only)\n\nTechnical Communication Quarterly\nIEEE Transactions on Professional Communication\nJournal of Business and Technical Communication\nTechnical Communication\n\nOther resources:\n\nArticle that presents a tutorial for Bibliometrix"
  },
  {
    "objectID": "demos/week09/wk09_tidy_networks.html#overview-network-analysis",
    "href": "demos/week09/wk09_tidy_networks.html#overview-network-analysis",
    "title": "Wk 09: Network Analysis",
    "section": "",
    "text": "Web of Science Queries (articles only)\n\nTechnical Communication Quarterly\nIEEE Transactions on Professional Communication\nJournal of Business and Technical Communication\nTechnical Communication\n\nOther resources:\n\nArticle that presents a tutorial for Bibliometrix"
  },
  {
    "objectID": "demos/week09/wk09_tidy_networks.html#key-library-bibliometrix",
    "href": "demos/week09/wk09_tidy_networks.html#key-library-bibliometrix",
    "title": "Wk 09: Network Analysis",
    "section": "Key library: Bibliometrix",
    "text": "Key library: Bibliometrix\nBibliometrix\n\nCodelibrary(tidyverse)\nlibrary(janitor)\nlibrary(bibliometrix)\n\n\nTo use biblioshiny (Graphical interface built with RShiny)\n\nCode#library(bibliometrix)\n#biblioshiny()"
  },
  {
    "objectID": "demos/week09/wk09_tidy_networks.html#convert-.bib-to-dataframes",
    "href": "demos/week09/wk09_tidy_networks.html#convert-.bib-to-dataframes",
    "title": "Wk 09: Network Analysis",
    "section": "Convert .bib to dataframes",
    "text": "Convert .bib to dataframes\nSet file locations\n\nCodetcq &lt;- \"data/wos-tcq.bib\"\nieee &lt;- \"data/wos-ieee.bib\"\njbtc &lt;- \"data/wos-jbtc.bib\"\ntc &lt;- \"data/wos-tc.bib\"\n\n\nConvert each bib file to a dataframe\n\nCode#help(convert2df)\n\n\n# TCQ\ndf_tcq &lt;- convert2df(file = tcq,\n                  dbsource = \"wos\",\n                  format = \"bibtex\")\n\n\nConverting your wos collection into a bibliographic dataframe\n\n\nWarning:\nIn your file, some mandatory metadata are missing. Bibliometrix functions may not work properly!\n\nPlease, take a look at the vignettes:\n- 'Data Importing and Converting' (https://www.bibliometrix.org/vignettes/Data-Importing-and-Converting.html)\n- 'A brief introduction to bibliometrix' (https://www.bibliometrix.org/vignettes/Introduction_to_bibliometrix.html)\n\n\nMissing fields:  C1 \nDone!\n\nCode# IEEE\ndf_ieee &lt;- convert2df(file = ieee,\n                  dbsource = \"wos\",\n                  format = \"bibtex\")\n\n\nConverting your wos collection into a bibliographic dataframe\n\n\nWarning:\nIn your file, some mandatory metadata are missing. Bibliometrix functions may not work properly!\n\nPlease, take a look at the vignettes:\n- 'Data Importing and Converting' (https://www.bibliometrix.org/vignettes/Data-Importing-and-Converting.html)\n- 'A brief introduction to bibliometrix' (https://www.bibliometrix.org/vignettes/Introduction_to_bibliometrix.html)\n\n\nMissing fields:  C1 \nDone!\n\nCode# JBTC\ndf_jbtc &lt;- convert2df(file = jbtc,\n                  dbsource = \"wos\",\n                  format = \"bibtex\")\n\n\nConverting your wos collection into a bibliographic dataframe\n\n\nWarning:\nIn your file, some mandatory metadata are missing. Bibliometrix functions may not work properly!\n\nPlease, take a look at the vignettes:\n- 'Data Importing and Converting' (https://www.bibliometrix.org/vignettes/Data-Importing-and-Converting.html)\n- 'A brief introduction to bibliometrix' (https://www.bibliometrix.org/vignettes/Introduction_to_bibliometrix.html)\n\n\nMissing fields:  C1 \nDone!\n\nCode# TC\ndf_tc &lt;- convert2df(file = tc,\n                  dbsource = \"wos\",\n                  format = \"bibtex\")\n\n\nConverting your wos collection into a bibliographic dataframe\n\n\nWarning:\nIn your file, some mandatory metadata are missing. Bibliometrix functions may not work properly!\n\nPlease, take a look at the vignettes:\n- 'Data Importing and Converting' (https://www.bibliometrix.org/vignettes/Data-Importing-and-Converting.html)\n- 'A brief introduction to bibliometrix' (https://www.bibliometrix.org/vignettes/Introduction_to_bibliometrix.html)\n\n\nMissing fields:  C1 \nDone!\n\n\nCombine the resulting dataframes\n\nCodeM &lt;- bind_rows(\n  df_ieee,\n  df_jbtc,\n  df_tc,\n  df_tcq\n)\n\n#write_rds(M, \"data/comb.rds\")\n\n#install.packages(\"bib2df\")\n#library(bib2df)\n#df2bib(M, \"data/comb.bib\")\n\n#write_csv(M, \"data/comb.csv\")\n\n# get subset for analysis\n\nM &lt;- M %&gt;%\n  filter(PY &gt; 1992)\n\n\n\nCode# run a stock analysis (generates a list of dataframes)\nresults &lt;- biblioAnalysis(M, sep = \";\")\n\n# create a summary of the results\noptions(width=100)\nS &lt;- summary(object = results, k = 10, pause = FALSE)\n\n\n\nMAIN INFORMATION ABOUT DATA\n\n Timespan                              1994 : 2023 \n Sources (Journals, Books, etc)        4 \n Documents                             1866 \n Annual Growth Rate %                  8.76 \n Document Average Age                  11.8 \n Average citations per doc             12.12 \n Average citations per year per doc    1.022 \n References                            52452 \n \nDOCUMENT TYPES                     \n article                         1826 \n article; early access           30 \n article; proceedings paper      10 \n \nDOCUMENT CONTENTS\n Keywords Plus (ID)                    1476 \n Author's Keywords (DE)                4048 \n \nAUTHORS\n Authors                               2201 \n Author Appearances                    3370 \n Authors of single-authored docs       654 \n \nAUTHORS COLLABORATION\n Single-authored docs                  970 \n Documents per Author                  0.848 \n Co-Authors per Doc                    1.81 \n International co-authorships %        0 \n \n\nAnnual Scientific Production\n\n Year    Articles\n    1994        7\n    1995       20\n    1996       17\n    1997       40\n    1998       42\n    1999       42\n    2000       51\n    2001       52\n    2002       40\n    2003       52\n    2004       46\n    2005       84\n    2006       63\n    2007       82\n    2008       76\n    2009       72\n    2010       80\n    2011       65\n    2012       72\n    2013       66\n    2014       60\n    2015       67\n    2016       73\n    2017       75\n    2018       81\n    2019       83\n    2020       80\n    2021      109\n    2022       89\n    2023       80\n\nAnnual Percentage Growth Rate 8.76 \n\n\nMost Productive Authors\n\n   Authors        Articles Authors        Articles Fractionalized\n1    CARLINER S         16 CARLINER S                       13.42\n2    DE JONG MDT        16 MACKIEWICZ J                     13.03\n3    MACKIEWICZ J       16 SWARTS J                         12.00\n4    SPINUZZI C         16 FRIESS E                         10.50\n5    LAM C              14 LAM C                            10.50\n6    MELONCON L         14 SPINUZZI C                        9.50\n7    FRIESS E           13 MELONCON L                        8.67\n8    SWARTS J           13 BATOVA T                          8.00\n9    WALTON R           12 MALONE EA                         7.50\n10   DE JONG M          11 VAN DER MEIJ H                    7.50\n\n\nTop manuscripts per citations\n\n                               Paper                                    DOI  TC TCperYear   NTC\n1  LOWRY PB, 2014, IEEE Trans. Prof. Commun.  10.1109/TPC.2014.2312452      964     96.40 33.18\n2  SPINUZZI C, 2005, Tech. Commun.            NA                            502     26.42 18.49\n3  SPINUZZI C, 2012, J. Bus. Tech. Commun.    10.1177/1050651912444070      339     28.25 16.72\n4  BOREN MT, 2000, IEEE Trans. Prof. Commun.  10.1109/47.867942             325     13.54 13.55\n5  KOCK N, 2005, IEEE Trans. Prof. Commun.    10.1109/TPC.2005.849649       227     11.95  8.36\n6  ROBERT LP, 2005, IEEE Trans. Prof. Commun. 10.1109/TPC.2004.843292       154      8.11  5.67\n7  RUPPEL CP, 2001, IEEE Trans. Prof. Commun. 10.1109/47.911131             147      6.39  6.41\n8  HAAS AM, 2012, J. Bus. Tech. Commun.       10.1177/1050651912439539      128     10.67  6.31\n9  ROBEY D, 2000, Tech. Commun.               10.1109/47.826416             126      5.25  5.25\n10 JONES NN, 2016, Tech. Commun. Q.-a         10.1080/10572252.2016.1224655 125     15.62 10.14\n\n\nMost Relevant Sources\n\n                                   Sources        Articles\n1 TECHNICAL COMMUNICATION                              545\n2 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION      460\n3 IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION      454\n4 TECHNICAL COMMUNICATION QUARTERLY                    407\n\n\nMost Relevant Keywords\n\n   Author Keywords (DE)      Articles  Keywords-Plus (ID)     Articles\n1    COMMUNICATION                113 COMMUNICATION                165\n2    TECHNICAL COMMUNICATION       83 TECHNICAL COMMUNICATION       94\n3    COLLABORATION                 59 TECHNOLOGY                    81\n4    PEDAGOGY                      52 GENRE                         68\n5    USABILITY                     50 INFORMATION                   65\n6    ETHICS                        49 DESIGN                        61\n7    WRITING                       47 WORK                          58\n8    RHETORIC                      45 PERFORMANCE                   56\n9    SOCIAL MEDIA                  42 MODEL                         52\n10   SOCIAL JUSTICE                39 DISCOURSE                     42"
  },
  {
    "objectID": "demos/week09/wk09_tidy_networks.html#citation-analysis",
    "href": "demos/week09/wk09_tidy_networks.html#citation-analysis",
    "title": "Wk 09: Network Analysis",
    "section": "Citation analysis",
    "text": "Citation analysis\nMost cited articles\n\nCode# Get citations\nCR &lt;- citations(M, field = \"article\", sep = \";\")\n\n# Top 50 most cited articles\ncbind(CR$Cited[1:50])\n\n                                                                                                                                               [,1]\nANONYMOUS, TECHNICAL COMMUNICAT                                                                                                                 209\nMILLER CR, 1984, Q J SPEECH, V70, P151, DOI 10.1080/00335638409383686                                                                           118\nMILLER CR, 1979, COLL ENGL, V40, P610, DOI 10.2307/375964                                                                                        85\nJONES NN, 2016, TECH COMMUN Q, V25, P211, DOI 10.1080/10572252.2016.1224655                                                                      80\nJONES N. N., 2016, J TECH WRIT COMMUN, V46, P342, DOI DOI 10.1177/0047281616639472                                                               69\nRUSSELL DR, 1997, WRIT COMMUN, V14, P504, DOI 10.1177/0741088397014004004                                                                        66\nAGBOKA GY, 2013, TECH COMMUN Q, V22, P28, DOI 10.1080/10572252.2013.730966                                                                       62\nSWALES J, 1990, GENRE ANAL ENGLISH A                                                                                                             62\nHAAS AM, 2012, J BUS TECH COMMUN, V26, P277, DOI 10.1177/1050651912439539                                                                        61\nANONYMOUS, 1996, TECH COMMUN Q                                                                                                                   57\nRUDE CD, 2009, J BUS TECH COMMUN, V23, P174, DOI 10.1177/1050651908329562                                                                        56\nBAZERMAN CHARLES, 1988, SHAPING WRITTEN KNOW                                                                                                     53\nSPINUZZI C., 2003, TRACING GENRES ORG S                                                                                                          53\nBERKENKOTTER C., 1995, GENRE KNOWLEDGE DISC                                                                                                      52\nKATZ SB, 1992, COLL ENGL, V54, P255, DOI 10.2307/378062                                                                                          52\nSCHRIVER KA., 1997, DYNAMICS DOCUMENT DE                                                                                                         49\nANONYMOUS, 1998, TECH COMMUN Q, DOI 10.1080/10572259809364640, DOI 10.1080/10572259809364640                                                     48\nAGBOKA G. Y., 2014, J TECHNICAL WRITING, V44, P297                                                                                               44\nDAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/MNSC.32.5.554                                                                                  42\nDRAGGA S, 2001, TECH COMMUN, V48, P265                                                                                                           42\nJOHNSON R. R., 1998, USER CTR TECHNOLOGY                                                                                                         42\nMILES M. B., 1994, QUALITATIVE DATA ANA                                                                                                          42\nANONYMOUS, NO TITLE CAPTURED                                                                                                                     41\nHOFT NANCY L, 1995, INT TECHNICAL COMMUN                                                                                                         41\nRAINEY KT, 2005, TECH COMMUN-STC, V52, P323                                                                                                      41\nANONYMOUS, 2000, SPURIOUS COIN HIST S                                                                                                            39\nKIMBALL MA, 2006, TECH COMMUN Q, V15, P67, DOI 10.1207/S15427625TCQ1501\\\\_6                                                                      38\nSPINUZZI C, 2007, TECH COMMUN Q, V16, P265, DOI 10.1080/10572250701290998                                                                        38\nHOFSTEDE G., 2001, CULTURES CONSEQUENCE                                                                                                          37\nSLACK JENNIFER DARYLL, 1993, J BUS TECH COMMUN, V7, P12, DOI 10.1177/1050651993007001002                                                         37\nANONYMOUS, 2004, TECH COMMUN Q                                                                                                                   36\nANONYMOUS, J TECHNICAL WRITING                                                                                                                   36\nWALTON R., 2019, TECHNICAL COMMUNICAT                                                                                                            36\nANONYMOUS, INTERCOM                                                                                                                              34\nJONES NN, 2018, KEY THEORETICAL FRAMEWORKS: TEACHING TECHNICAL COMMUNICATION IN THE TWENTY-FIRST CENTURY, P241, DOI 10.7330/9781607327585.C010   34\nSALDA├A┬▒A J., 2016, CODING MANUAL QUALIT                                                                                                        34\nSUN HT, 2006, TECH COMMUN Q, V15, P457, DOI 10.1207/S15427625TCQ1504\\\\_3                                                                         33\nFARKAS DK, 1999, TECH COMMUN, V46, P42                                                                                                           32\nANONYMOUS, J BUSINESS COMMUNICA                                                                                                                  31\nDURACK K. T., 1997, TECH COMMUN Q, V6, P249                                                                                                      31\nSPINUZZI C., 2008, NETWORK THEORIZING K                                                                                                          31\nYATES J, 1992, ACAD MANAGE REV, V17, P299, DOI 10.2307/258774                                                                                    31\nMISTRY ROHINTON, 2002, FAMILY MATTERS                                                                                                            30\nPARETTI MC, 2007, TECH COMMUN Q, V16, P327, DOI 10.1080/10572250701291087                                                                        29\nANONYMOUS, 2007, COMMUNICATIVE PRACTI                                                                                                            28\nANONYMOUS, PROFESSIONAL COMMUNI                                                                                                                  28\nBRUMBERGER E, 2015, TECH COMMUN-STC, V62, P224                                                                                                   28\nDAFT RL, 1987, MIS QUART, V11, P355, DOI 10.2307/248682                                                                                          28\nKOERBER A, 2006, TECH COMMUN Q, V15, P87, DOI 10.1207/S15427625TCQ1501\\\\_7                                                                       28\nSCHRIVER K, 1997, DYNAMICS DOCUMENT DE                                                                                                           28\n\n\nMost cited first authors\n\nCodeCR &lt;- citations(M, field = \"author\", sep = \";\")\n\ncbind(CR$Cited[1:25])\n\n                  [,1]\nANONYMOUS         7766\nSPINUZZI C         405\nMILLER CR          244\nNO TITLE CAPTURED  223\nJONES NN           191\nWALTON R           171\nCARLINER S         161\nHOFSTEDE G         143\nDRAGGA S           126\nWINSOR DA          123\nLATOUR B           119\nKOSTELNICK C       118\nMELONCON L         116\nBERKENKOTTER C     114\nNIELSEN J          111\nFREEDMAN A         109\nJONES N N          108\nBAZERMAN CHARLES   107\nVAN DER MEIJ H     107\nMACKIEWICZ J       102\nSWARTS J           102\nHAAS AM            101\nMIREL B             93\nTEBEAUX E           92\nKIMBALL MA          90\n\n\nLocal citations\nNot working :(\n\nCodeCR &lt;- localCitations(M, sep = \";\")\nCR$Authors[1:10, ]\n\n          Author LocalCitations\n1  [ANONYMOUS] A              0\n2       ABBOTT C              0\n3       ABBOTT L              0\n4        ABELL J              0\n5     ACHARYA KR              0\n6     ACKERMAN M              0\n7          ADA S              0\n8         ADAM C              0\n9        ADAMS A              0\n10      ADAMS AH              0\n\n\nNot working :(\n\nCodeCR$Papers[1:10,]\n\n                                       Paper                         DOI Year LCS GCS\n1    HOPKINS WE, 1994, J. Bus. Tech. Commun. 10.1177/1050651994008003005 1994   0   0\n2        ZAK MW, 1994, J. Bus. Tech. Commun. 10.1177/1050651994008003002 1994   0   7\n3  NICHOLSON JD, 1994, J. Bus. Tech. Commun. 10.1177/1050651994008003006 1994   0   0\n4     LIMAYE MR, 1994, J. Bus. Tech. Commun. 10.1177/1050651994008003007 1994   0   3\n5   GRIFFETH RW, 1994, J. Bus. Tech. Commun. 10.1177/1050651994008003003 1994   0   3\n6     KOSSEK EE, 1994, J. Bus. Tech. Commun. 10.1177/1050651994008003004 1994   0  12\n7   LIMAYE MR, 1994, J. Bus. Tech. Commun.-a 10.1177/1050651994008003001 1994   0   0\n8     THOMAS SG, 1995, J. Bus. Tech. Commun. 10.1177/1050651995009004004 1995   0   5\n9      GOLEN SP, 1995, J. Bus. Tech. Commun. 10.1177/1050651995009003003 1995   0   0\n10      MIREL B, 1995, J. Bus. Tech. Commun. 10.1177/1050651995009003001 1995   0   6\n\n\n\nCodeDF &lt;- dominance(results, k = 12)\nDF\n\n         Author Dominance Factor Tot Articles Single-Authored Multi-Authored First-Authored Rank by Articles Rank by DF\n1  MACKIEWICZ J        0.6000000           16              11              5              3                1          1\n2      FRIESS E        0.6000000           13               8              5              3                7          1\n3    SPINUZZI C        0.5555556           16               7              9              5                1          3\n4     GRAHAM SS        0.5555556           11               2              9              5                9          3\n5    CARLINER S        0.5000000           16              12              4              2                1          5\n6    MELONCON L        0.4444444           14               5              9              4                5          6\n7      WALTON R        0.4000000           12               2             10              4                8          7\n8     DE JONG M        0.3636364           11               0             11              4                9          8\n9     MALONE EA        0.3333333           11               5              6              2                9          9\n10        LAM C        0.2857143           14               7              7              2                5         10\n11  DE JONG MDT        0.2500000           16               0             16              4                1         11\n12   KARREMAN J        0.1818182           11               0             11              2                9         12\n\n\n\nCodetopAU &lt;- authorProdOverTime(M, k = 20, graph = TRUE)\n\n\n\n\n\nCodehead(topAU$dfAU)\n\n       Author year freq TC      TCpY\n1    BATOVA T 2010    1 11 0.7857143\n2    BATOVA T 2015    2 34 3.7777778\n3    BATOVA T 2018    3 25 4.1666667\n4    BATOVA T 2019    1  1 0.2000000\n5    BATOVA T 2021    2 13 4.3333333\n6 BOETTGER RK 2010    2 77 5.5000000"
  },
  {
    "objectID": "demos/week09/wk09_tidy_networks.html#co-citation",
    "href": "demos/week09/wk09_tidy_networks.html#co-citation",
    "title": "Wk 09: Network Analysis",
    "section": "Co-Citation",
    "text": "Co-Citation\n\nCodeNetMatrix &lt;- biblioNetwork(M, analysis = \"co-citation\", network = \"references\", sep = \";\")\n\n## Plot the network\nnet=networkPlot(NetMatrix,\n                n = 25, \n                Title = \"Co-Citation Network\", \n                type = \"fruchterman\", \n                size=T,\n                label.cex=TRUE,\n                label.color=TRUE,\n                halo=FALSE,\n                remove.multiple=FALSE, \n                labelsize=.7,\n                edgesize = 3,\n                cluster = \"none\",\n                community.repulsion = .3,\n                edges.min = 1)"
  },
  {
    "objectID": "demos/week08/wk08_sentiment-analysis.html",
    "href": "demos/week08/wk08_sentiment-analysis.html",
    "title": "Wk 08: Sentiment Analysis",
    "section": "",
    "text": "Here is some sample code to get sentiment data from bing and nrc dictionaries."
  },
  {
    "objectID": "demos/week08/wk08_sentiment-analysis.html#overview",
    "href": "demos/week08/wk08_sentiment-analysis.html#overview",
    "title": "Wk 08: Sentiment Analysis",
    "section": "",
    "text": "Here is some sample code to get sentiment data from bing and nrc dictionaries."
  },
  {
    "objectID": "demos/week08/wk08_sentiment-analysis.html#the-data",
    "href": "demos/week08/wk08_sentiment-analysis.html#the-data",
    "title": "Wk 08: Sentiment Analysis",
    "section": "The data",
    "text": "The data\n\nCodelibrary(tidyverse)\nload(\"data/tmm_comments.Rdata\")\n\nglimpse(data)\n\nRows: 38,661\nColumns: 6\n$ `Letter #`          &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…\n$ `Organization Name` &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Letter Text`       &lt;chr&gt; \"The proposal to renew expired mineral leases on t…\n$ ...4                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ...5                &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ...6                &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…"
  },
  {
    "objectID": "demos/week08/wk08_sentiment-analysis.html#sentiment-analysis",
    "href": "demos/week08/wk08_sentiment-analysis.html#sentiment-analysis",
    "title": "Wk 08: Sentiment Analysis",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\n\nCodelibrary(janitor)\ndata &lt;- data %&gt;%\n  clean_names()\n\nglimpse(data)\n\nRows: 38,661\nColumns: 6\n$ letter_number     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ organization_name &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ letter_text       &lt;chr&gt; \"The proposal to renew expired mineral leases on the…\n$ x4                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ x5                &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ x6                &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\nLetter text\n\nCodehead(data$letter_text, n = 1)\n\n[1] \"The proposal to renew expired mineral leases on the Superior National Forest near the Boundary Waters shows a disregard for science, economics, and public opinion. The U.S. Forest Service rejected these very leases in 2016 because allowing mining to proceed would be inconsistent with its obligation to manage and protect these lands and waters for future generations. The Trump Administration has reversed the U.S. Forest Services prior decisions and illegally put the project into the hands of the Interior Departments Bureau of Land Management. The U.S. Forest Service has an obligation to protect the Boundary Waters. The BLMs inadequate environmental review rejects the U.S. Forest Services authority and ignores the overwhelming science and economics that support long-term mining protections for this area. Refusing to renew the expired mineral leases is the way to ensure that the conservation and protection of the Boundary Waters continues. The BLM must at least prepare a full environmental impact statement that includes a no-lease-renewal alternative and thoroughly examines the significant impacts of mining should it decide to proceed with reckless and illegal lease renewal.Thank you.\"\n\n\n\nCodelibrary(tidytext)\n\n#install.packages(\"textdata\")\nlibrary(textdata)\n\n\nAFINN\n\nCode# get AFINN sentiment dictionary (you may have to download)\n#get_sentiments(\"afinn\")\n\n\nBing\n\nCode# get bing sentiment dictionary\n#get_sentiments(\"bing\")\n\n\nNRC\n\nCode# get nrc dictionary (you may have to download)\nget_sentiments(\"nrc\")\n\n# A tibble: 13,872 × 2\n   word        sentiment\n   &lt;chr&gt;       &lt;chr&gt;    \n 1 abacus      trust    \n 2 abandon     fear     \n 3 abandon     negative \n 4 abandon     sadness  \n 5 abandoned   anger    \n 6 abandoned   fear     \n 7 abandoned   negative \n 8 abandoned   sadness  \n 9 abandonment anger    \n10 abandonment fear     \n# ℹ 13,862 more rows\n\n\nSetting up our data\n\nCodedata &lt;- data %&gt;%\n  select(letter_number, organization_name, letter_text)\n\n\n\nCodetokens &lt;- data %&gt;%\n  unnest_tokens(word, letter_text)\n\nhead(tokens)\n\n# A tibble: 6 × 3\n  letter_number organization_name word    \n          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;   \n1             1 &lt;NA&gt;              the     \n2             1 &lt;NA&gt;              proposal\n3             1 &lt;NA&gt;              to      \n4             1 &lt;NA&gt;              renew   \n5             1 &lt;NA&gt;              expired \n6             1 &lt;NA&gt;              mineral \n\n\nGet bing sentiment scores\nIn the following code, we\n\nCodebing_sentiments &lt;- tokens %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = c(word = \"word\")) %&gt;%\n  group_by(letter_number) %&gt;%\n  summarise(bing_sentiment = sum(sentiment == \"positive\") - sum(sentiment == \"negative\"))\n\n\nbing_sentiments\n\n# A tibble: 38,347 × 2\n   letter_number bing_sentiment\n           &lt;dbl&gt;          &lt;int&gt;\n 1             1             -5\n 2             2             -5\n 3             3             -5\n 4             4             -3\n 5             5             -5\n 6             6             -5\n 7             7             -5\n 8             8             -5\n 9             9             -5\n10            10             -5\n# ℹ 38,337 more rows\n\n\nGet NRC sentiment scores\n\nCode# Calculate sentiment scores using the NRC lexicon\nnrc_sentiments &lt;- tokens %&gt;%\n  inner_join(get_sentiments(\"nrc\"), by = c(word = \"word\")) %&gt;%\n  group_by(letter_number, sentiment) %&gt;%\n  summarise(sentiment_count = n()) %&gt;%  # Count the number of each sentiment\n  pivot_wider(names_from = sentiment, values_from = sentiment_count, values_fill = 0) %&gt;%\n  ungroup(.)\n\n# rename columns to include prefix \"nrc_\"\nnrc_sentiments &lt;- nrc_sentiments %&gt;%\n  rename_with(~ paste0(\"nrc_\", .), -letter_number)\n\nhead(nrc_sentiments)\n\n# A tibble: 6 × 11\n  letter_number nrc_anger nrc_anticipation nrc_disgust nrc_fear nrc_negative\n          &lt;dbl&gt;     &lt;int&gt;            &lt;int&gt;       &lt;int&gt;    &lt;int&gt;        &lt;int&gt;\n1             1         3                4           2        3            8\n2             2         3                4           2        3            8\n3             3         3                4           2        3            8\n4             4         2                1           0        1            2\n5             5         3                4           2        3            8\n6             6         3                4           2        3            8\n# ℹ 5 more variables: nrc_positive &lt;int&gt;, nrc_sadness &lt;int&gt;,\n#   nrc_surprise &lt;int&gt;, nrc_trust &lt;int&gt;, nrc_joy &lt;int&gt;\n\n\n\nCode# Join the sentiment scores with the original DataFrame\nresults &lt;- data %&gt;%\n  left_join(bing_sentiments, by = \"letter_number\") %&gt;%\n  left_join(nrc_sentiments, by = \"letter_number\")\n\n# View the resulting DataFrame\nhead(results)\n\n# A tibble: 6 × 14\n  letter_number organization_name letter_text           bing_sentiment nrc_anger\n          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;                          &lt;int&gt;     &lt;int&gt;\n1             1 &lt;NA&gt;              The proposal to rene…             -5         3\n2             2 &lt;NA&gt;              The proposal to rene…             -5         3\n3             3 &lt;NA&gt;              The proposal to rene…             -5         3\n4             4 &lt;NA&gt;              The renewal of these…             -3         2\n5             5 &lt;NA&gt;              The proposal to rene…             -5         3\n6             6 &lt;NA&gt;              The proposal to rene…             -5         3\n# ℹ 9 more variables: nrc_anticipation &lt;int&gt;, nrc_disgust &lt;int&gt;,\n#   nrc_fear &lt;int&gt;, nrc_negative &lt;int&gt;, nrc_positive &lt;int&gt;, nrc_sadness &lt;int&gt;,\n#   nrc_surprise &lt;int&gt;, nrc_trust &lt;int&gt;, nrc_joy &lt;int&gt;\n\n\nWrite out results for later use\n\nCodesave(results, file = \"out/tmm_sentiment_results.Rdata\")"
  },
  {
    "objectID": "demos/week08/wk08_sentiment-analysis.html#explore-sentiment-results",
    "href": "demos/week08/wk08_sentiment-analysis.html#explore-sentiment-results",
    "title": "Wk 08: Sentiment Analysis",
    "section": "Explore sentiment results",
    "text": "Explore sentiment results\n\nCode# Define the sentiment category you want to use (replace with the desired category)\nsentiment_category &lt;- \"nrc_trust\"\n\n# Extract the top 5 observations for the specified sentiment category\ntop_5_sentiment &lt;- results %&gt;%\n  arrange(desc({{sentiment_category}})) %&gt;%\n  slice_head(n = 5) %&gt;%\n  select(letter_number, letter_text, {{sentiment_category}})\n\n# Print the top 5 observations\nprint(top_5_sentiment)\n\n# A tibble: 5 × 3\n  letter_number letter_text                                            nrc_trust\n          &lt;dbl&gt; &lt;chr&gt;                                                      &lt;int&gt;\n1             1 The proposal to renew expired mineral leases on the S…         6\n2             2 The proposal to renew expired mineral leases on the S…         6\n3             3 The proposal to renew expired mineral leases on the S…         6\n4             4 The renewal of these leases is arbitrary and done in …         1\n5             5 The proposal to renew expired mineral leases on the S…         6"
  },
  {
    "objectID": "demos/week08/wk08_sentiment-analysis.html#filter-out-repeat-letters-create-subsets",
    "href": "demos/week08/wk08_sentiment-analysis.html#filter-out-repeat-letters-create-subsets",
    "title": "Wk 08: Sentiment Analysis",
    "section": "Filter out repeat letters; create subsets",
    "text": "Filter out repeat letters; create subsets\n\nCode# Create a new df with unique 'letter_text' observations\nresults_filtered &lt;- results %&gt;%\n  distinct(letter_text, .keep_all = TRUE)\n\n# create subsets for exploration\nresults_anger &lt;- results_filtered %&gt;%\n  select(letter_number, letter_text, nrc_anger)\n\n\n\nCodelibrary(reactable)\n\n# create table (define columns, add parameters & formatting)\nreactable(results_anger, searchable = TRUE, filterable = TRUE)"
  },
  {
    "objectID": "demos/week05/wk05_tc-titles.html",
    "href": "demos/week05/wk05_tc-titles.html",
    "title": "Wk 05: Titles in TC Journals, pt. 1",
    "section": "",
    "text": "Here, we prepare a dataset consisting of article metadata for five major tc journals:\n\nJournals: Technical Communication Quarterly (TCQ), Technical Communication (TC), Journal of Technical Writing and Communication (JTWC) , Communication Design Quarterly (CDQ), and Journal of Business and Technical Communication (JBTC)\nYears: 2005 - 2023\nArticle Metadata: Journal, Authors, Title, Abstract, Publication Year"
  },
  {
    "objectID": "demos/week05/wk05_tc-titles.html#overview",
    "href": "demos/week05/wk05_tc-titles.html#overview",
    "title": "Wk 05: Titles in TC Journals, pt. 1",
    "section": "",
    "text": "Here, we prepare a dataset consisting of article metadata for five major tc journals:\n\nJournals: Technical Communication Quarterly (TCQ), Technical Communication (TC), Journal of Technical Writing and Communication (JTWC) , Communication Design Quarterly (CDQ), and Journal of Business and Technical Communication (JBTC)\nYears: 2005 - 2023\nArticle Metadata: Journal, Authors, Title, Abstract, Publication Year"
  },
  {
    "objectID": "demos/week05/wk05_tc-titles.html#prepare-data",
    "href": "demos/week05/wk05_tc-titles.html#prepare-data",
    "title": "Wk 05: Titles in TC Journals, pt. 1",
    "section": "Prepare data",
    "text": "Prepare data\nWe need to drop written comm from our “full data” and read in and clean bibtex data from Communication Design Quarterly and Journal of Technical Writing and Communication\nLoad libraries\n\nCode#install.packages(\"bib2df\")\nlibrary(bib2df)\nlibrary(janitor)\nlibrary(tidyverse)\n\n\nFirst, we’ll read in CDQ.\n\nCode# CDQ: read in and clean names\ncdq_raw &lt;- bib2df(\"data/acm-cdq.bib\")%&gt;%\n  clean_names()\n\nhead(cdq_raw)\n\n# A tibble: 6 × 33\n  category bibtexkey    address annote author booktitle chapter crossref edition\n  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;  &lt;list&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  \n1 ARTICLE  10.1145/356… New Yo… &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n2 ARTICLE  10.1145/350… New Yo… &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n3 ARTICLE  10.1145/350… New Yo… &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n4 ARTICLE  10.1145/350… New Yo… &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n5 ARTICLE  10.1145/350… New Yo… &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n6 ARTICLE  10.1145/348… New Yo… &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n# ℹ 24 more variables: editor &lt;list&gt;, howpublished &lt;chr&gt;, institution &lt;chr&gt;,\n#   journal &lt;chr&gt;, key &lt;chr&gt;, month &lt;chr&gt;, note &lt;chr&gt;, number &lt;chr&gt;,\n#   organization &lt;chr&gt;, pages &lt;chr&gt;, publisher &lt;chr&gt;, school &lt;chr&gt;,\n#   series &lt;chr&gt;, title &lt;chr&gt;, type &lt;chr&gt;, volume &lt;chr&gt;, year &lt;dbl&gt;,\n#   issue_date &lt;chr&gt;, url &lt;chr&gt;, doi &lt;chr&gt;, abstract &lt;chr&gt;, numpages &lt;chr&gt;,\n#   keywords &lt;chr&gt;, issn &lt;chr&gt;\n\n\nSecond, we’ll read in JWTC.\n\nCode# JWTC: read in and clean names\njtwc_raw &lt;- bib2df(\"data/jtwc.bib\")%&gt;%\n  clean_names()\n\nhead(jtwc_raw)\n\n# A tibble: 6 × 30\n  category bibtexkey    address annote author booktitle chapter crossref edition\n  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;  &lt;list&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  \n1 ARTICLE  17004768420… &lt;NA&gt;    &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n2 ARTICLE  17004768320… &lt;NA&gt;    &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n3 ARTICLE  17004768220… &lt;NA&gt;    &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n4 ARTICLE  17004768720… &lt;NA&gt;    &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n5 ARTICLE  17004768520… &lt;NA&gt;    &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n6 ARTICLE  17004768620… &lt;NA&gt;    &lt;NA&gt;   &lt;chr&gt;  &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;     &lt;NA&gt;   \n# ℹ 21 more variables: editor &lt;list&gt;, howpublished &lt;chr&gt;, institution &lt;chr&gt;,\n#   journal &lt;chr&gt;, key &lt;chr&gt;, month &lt;chr&gt;, note &lt;chr&gt;, number &lt;chr&gt;,\n#   organization &lt;chr&gt;, pages &lt;chr&gt;, publisher &lt;chr&gt;, school &lt;chr&gt;,\n#   series &lt;chr&gt;, title &lt;chr&gt;, type &lt;chr&gt;, volume &lt;chr&gt;, year &lt;dbl&gt;,\n#   abstract &lt;chr&gt;, issn &lt;chr&gt;, keywords &lt;chr&gt;, url &lt;chr&gt;\n\n\nThird, we’ll read in our full data and drop WC\n\nCode# read in full data and drop Written Comm entries\nfullish &lt;- read_csv(\"data/full_data.csv\") %&gt;%\n  filter(abbreviation != \"WC\") %&gt;%\n  select(source_title,\n         author_full_names,\n         article_title,\n         abstract,\n         publication_year,\n         abbreviation)\n\n#head(fullish)\n\n#glimpse(fullish)\n\n#unique(fullish$abbreviation)\n\n\nUnify the dataset\nFor this analysis, we want consistent data and column names for each journal in the dataset. Here are the datapoints, using the column names from our preexisting data:\n\nsource_title\nauthor_full_names\narticle_title\nabstract\npublication_year\nabbreviation\n\nLet’s select the target fields, add the journal abbreviation, and rename the columns to harmonize the data with our preexisting set.\n\nCode#glimpse(cdq_raw)\n\n# select fields to keep; add an abbreviation column; rename columns\ncdq_select &lt;- cdq_raw %&gt;%\n  select(journal,\n         author,\n         title,\n         abstract,\n         year) %&gt;%\n  mutate(abbreviation = \"CDQ\")%&gt;%\n  rename(source_title = journal,\n         author_full_names = author,\n         article_title = title,\n         abstract = abstract,\n         publication_year = year,\n         abbreviation = abbreviation)%&gt;%\n  mutate(author_full_names = map_chr(author_full_names, ~ paste(.x, collapse = \"; \")))\n\nglimpse(cdq_select)\n\nRows: 336\nColumns: 6\n$ source_title      &lt;chr&gt; \"Commun. Des. Q. Rev\", \"Commun. Des. Q. Rev\", \"Commu…\n$ author_full_names &lt;chr&gt; \"Carter, Daniel\", \"York, Eric J.\", \"Davis, Katlynne;…\n$ article_title     &lt;chr&gt; \"Constructing Structured Content on WordPress: Emerg…\n$ abstract          &lt;chr&gt; \"Web content management systems (WCMSs) are widely u…\n$ publication_year  &lt;dbl&gt; 2023, 2022, 2022, 2022, 2022, 2022, 2021, 2021, 2020…\n$ abbreviation      &lt;chr&gt; \"CDQ\", \"CDQ\", \"CDQ\", \"CDQ\", \"CDQ\", \"CDQ\", \"CDQ\", \"CD…\n\n\nNow the same for JTWC!\n\nCode#glimpse(jtwc_raw)\n\n# select fields to keep; add an abbreviation column; rename columns\njtwc_select &lt;- jtwc_raw %&gt;%\n  select(journal,\n         author,\n         title,\n         abstract,\n         year) %&gt;%\n  mutate(abbreviation = \"JTWC\")%&gt;%\n  rename(source_title = journal,\n         author_full_names = author,\n         article_title = title,\n         abstract = abstract,\n         publication_year = year,\n         abbreviation = abbreviation)%&gt;%\n  mutate(author_full_names = map_chr(author_full_names, ~ paste(.x, collapse = \"; \")))\n\nglimpse(jtwc_select)\n\nRows: 452\nColumns: 6\n$ source_title      &lt;chr&gt; \"Journal of Technical Writing & Communication\", \"Jou…\n$ author_full_names &lt;chr&gt; \"Getto, Guiseppe;  Flanagan, Suzan;  Labriola, Jack\"…\n$ article_title     &lt;chr&gt; \"Introduction to Special Issue: The People, Practice…\n$ abstract          &lt;chr&gt; \"This special issue of the Journal of Technical Writ…\n$ publication_year  &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023…\n$ abbreviation      &lt;chr&gt; \"JTWC\", \"JTWC\", \"JTWC\", \"JTWC\", \"JTWC\", \"JTWC\", \"JTW…\n\n\nNow we can join the three\n\nCodetc_journals &lt;- bind_rows(fullish, cdq_select, jtwc_select)\n\nglimpse(tc_journals)\n\nRows: 2,002\nColumns: 6\n$ source_title      &lt;chr&gt; \"JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\", \"…\n$ author_full_names &lt;chr&gt; \"Wickman, Chad\", \"DeJeu, Emily Barrow\", \"DeVasto, Da…\n$ article_title     &lt;chr&gt; \"Genre and Metagenre in Biomedical Research Writing\"…\n$ abstract          &lt;chr&gt; \"The use of reporting guidelines is an established y…\n$ publication_year  &lt;dbl&gt; 2023, 2022, 2016, 2009, 2009, 2020, 2016, 2012, 2011…\n$ abbreviation      &lt;chr&gt; \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBT…"
  },
  {
    "objectID": "demos/week05/wk05_tc-titles.html#check-work-plot-the-data",
    "href": "demos/week05/wk05_tc-titles.html#check-work-plot-the-data",
    "title": "Wk 05: Titles in TC Journals, pt. 1",
    "section": "Check work: Plot the data",
    "text": "Check work: Plot the data\n\nCode# Plot 1: Count of observations by journal abbreviation\ntc_journals %&gt;%\n  count(abbreviation) %&gt;%\n  ggplot(aes(x = reorder(abbreviation, n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  coord_flip() +\n  labs(title = \"Articles published (2005-2023) in major TC Journals\", x = \"Journal\", y = \"Articles\")\n\n\n\n\n\nCode# Plot 2: Bar chart of the number of articles published per year, colored by journal abbreviation\ntc_journals %&gt;%\n  group_by(publication_year, abbreviation) %&gt;%\n  summarise(num_articles = n()) %&gt;%\n  ggplot(aes(x = publication_year, y = num_articles, fill = abbreviation)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Articles Published per Year, by Journal Abbreviation\", x = \"Publication Year\", y = \"Number of Articles\") +\n  scale_fill_discrete(name = \"Journal Abbreviation\")\n\n\n\n\n\nCode# Plot 3: Dot plot of the number of articles published per year, colored by journal abbreviation with trend lines\ntc_journals %&gt;%\n  group_by(publication_year, abbreviation) %&gt;%\n  summarise(num_articles = n()) %&gt;%\n  ggplot(aes(x = publication_year, y = num_articles, color = abbreviation)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE, size = .7, aes(group = abbreviation), linetype = \"dashed\") +\n  labs(title = \"Articles Published per Year, by Journal Abbreviation\", x = \"Publication Year\", y = \"Number of Articles\") +\n  scale_color_discrete(name = \"Journal Abbreviation\")\n\n\n\n\n\nCode# Plot 4: Bar chart of articles per year\ntc_journals %&gt;%\n  group_by(publication_year) %&gt;%\n  summarise(num_articles = n()) %&gt;%\n  ggplot(aes(x = publication_year, y = num_articles)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(title = \"Total Articles per Year across Major TC Journals\", x = \"Publication Year\", y = \"Number of Articles\")"
  },
  {
    "objectID": "demos/week05/wk05_tc-titles.html#write-out-new-data",
    "href": "demos/week05/wk05_tc-titles.html#write-out-new-data",
    "title": "Wk 05: Titles in TC Journals, pt. 1",
    "section": "Write out new data",
    "text": "Write out new data\n\nCode# save as csv\n\nwrite_csv(tc_journals, \"data/tc_journals.csv\")\n\n\nsave(tc_journals, file = \"data/tc_journals.RData\")"
  },
  {
    "objectID": "demos/week03/wk03_wos_journals.html",
    "href": "demos/week03/wk03_wos_journals.html",
    "title": "Wk 03: Exploring TC journals, (pt 2)",
    "section": "",
    "text": "Last week we started with a CSV of results for TC and a separate CSV of results for TCQ. We cleaned, explored, merged, and visualized the data before saving it out in two formats: an .RData file and a .csv.\nThis week we’ll add two more journals…"
  },
  {
    "objectID": "demos/week03/wk03_wos_journals.html#overview",
    "href": "demos/week03/wk03_wos_journals.html#overview",
    "title": "Wk 03: Exploring TC journals, (pt 2)",
    "section": "",
    "text": "Last week we started with a CSV of results for TC and a separate CSV of results for TCQ. We cleaned, explored, merged, and visualized the data before saving it out in two formats: an .RData file and a .csv.\nThis week we’ll add two more journals…"
  },
  {
    "objectID": "demos/week03/wk03_wos_journals.html#load-libraries-and-data",
    "href": "demos/week03/wk03_wos_journals.html#load-libraries-and-data",
    "title": "Wk 03: Exploring TC journals, (pt 2)",
    "section": "Load libraries and data",
    "text": "Load libraries and data\n\nCodelibrary(tidyverse)\n\nload(\"data/both_data.RData\")\n\n\nLet’s confirm the data is what we expect.\n\nCodeglimpse(both_data)\n\nRows: 914\nColumns: 8\n$ author_full_names     &lt;chr&gt; \"Fuglsby, Brandi J.; Veeramoothoo, Saveena (Chak…\n$ article_title         &lt;chr&gt; \"Regulating Emotions for Social Action: Emotiona…\n$ source_title          &lt;chr&gt; \"TECHNICAL COMMUNICATION QUARTERLY\", \"TECHNICAL …\n$ abstract              &lt;chr&gt; \"This article describes students' emotional inte…\n$ cited_references      &lt;chr&gt; \"Agboka Godwin Y., 2018, CITIZENSHIP ADVOCACY; […\n$ cited_reference_count &lt;dbl&gt; 32, 86, 54, 28, 66, 22, 27, 38, 5, 20, 50, 4, 55…\n$ publication_year      &lt;dbl&gt; 2023, 2021, 2020, 2015, 2014, 2013, 2010, 2009, …\n$ publication_type      &lt;chr&gt; \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\"…\n\n\nAnd recreate our plot.\n\nCodelibrary(ggthemes)\n\n# count of articles by year, by journal\nyear_plot &lt;- ggplot(both_data, aes(x = publication_year)) +\n  geom_bar() +\n  labs(title = \"Articles per Year in TC and TCQ\",\n       x = \"Publication Year\",\n       y = \"Number of Articles\") +\n   facet_wrap(~ source_title, ncol = 1) +\n  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5, size = 4)+\n  theme_economist_white()\n\nyear_plot"
  },
  {
    "objectID": "demos/week03/wk03_wos_journals.html#read-in-new-data",
    "href": "demos/week03/wk03_wos_journals.html#read-in-new-data",
    "title": "Wk 03: Exploring TC journals, (pt 2)",
    "section": "Read in new data",
    "text": "Read in new data\nI’ve gone to web of science and queried for articles published 2005 to present in two journals:\n\nJournal of Business and Technical Communication\nWritten Communication\n\nBoth are .xls files located in my data folder.\n\nCodelibrary(readxl)\n\n# read in JBTC data\njbtc &lt;- read_excel(\"data/wos_jbtc.xls\")\n\n# read in Written Comm data\nwc &lt;- read_excel(\"data/wos_wc.xls\")"
  },
  {
    "objectID": "demos/week03/wk03_wos_journals.html#join-datasets",
    "href": "demos/week03/wk03_wos_journals.html#join-datasets",
    "title": "Wk 03: Exploring TC journals, (pt 2)",
    "section": "Join datasets",
    "text": "Join datasets\nOur goal is to add our two new datasets into the TC and TCQ data we already created.\nCheck data\nUpon checking the dimensions of the data, I see I have a lot of data columns I don’t need.\n\nCodedim(jbtc)\n\n[1] 300  72\n\nCodedim(wc)\n\n[1] 323  72\n\n\nClean names\nBefore we can join the datasets, we have to clean names.\n\nCodelibrary(janitor)\n\n# clean names of jbtc and wc \njbtc &lt;- clean_names(jbtc)\n\nwc &lt;- clean_names(wc)\n\n\nCombine jbtc and wc with bind_rows\nBecause they have the same variables, we can use bind_rows\n\nCode# create a combined dataset with bind rows\njbtc_wc &lt;- bind_rows(wc, jbtc)\n\n# check dimensions\ndim(jbtc_wc)\n\n[1] 623  72\n\n\nSelect target columns\nWe’ll reuse our code from week 2 to select the columns of interest.\n\nCodejbtc_wc &lt;- jbtc_wc %&gt;%\n  select(author_full_names,\n         article_title,\n         source_title,\n         abstract,\n         cited_references,\n         cited_reference_count,\n         publication_year,\n         publication_type)\n\n\nJoin the two combined sets\nBefore we join them, let’s do some math to see how many articles we should end up with.\n\nCode# number of articles (rows) in both_data (TC and TCQ)\ntc_and_tcq &lt;- nrow(both_data)\n\n# number of articles (rows) in jbtc_wc (JBTC and WC)\njbtc_and_wc &lt;- nrow(jbtc_wc)\n\n# The sum of articles in each\nprint(tc_and_tcq + jbtc_and_wc)\n\n[1] 1537\n\n\nNow, let’s join them and see how many articles we actually end up with.\n\nCode# combine the two sets (tcq+tc and jbtc+wc)\nfull_data &lt;- bind_rows(both_data, jbtc_wc)\n\n# check the dimensions\ndim(full_data)\n\n[1] 1537    8"
  },
  {
    "objectID": "demos/week03/wk03_wos_journals.html#explore-the-full-data",
    "href": "demos/week03/wk03_wos_journals.html#explore-the-full-data",
    "title": "Wk 03: Exploring TC journals, (pt 2)",
    "section": "Explore the full data",
    "text": "Explore the full data\n\nCode# provides overview of numeric variables\nsummary(full_data) \n\n author_full_names  article_title      source_title         abstract        \n Length:1537        Length:1537        Length:1537        Length:1537       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n cited_references   cited_reference_count publication_year publication_type  \n Length:1537        Min.   :  0.00        Min.   :2005     Length:1537       \n Class :character   1st Qu.: 18.00        1st Qu.:2009     Class :character  \n Mode  :character   Median : 34.00        Median :2015     Mode  :character  \n                    Mean   : 35.59        Mean   :2014                       \n                    3rd Qu.: 51.00        3rd Qu.:2019                       \n                    Max.   :169.00        Max.   :2023                       \n                    NA's   :623                                              \n\n\nDo we have all four journals represented?\n\nCodeunique(full_data$source_title)\n\n[1] \"TECHNICAL COMMUNICATION QUARTERLY\"              \n[2] \"TECHNICAL COMMUNICATION\"                        \n[3] \"WRITTEN COMMUNICATION\"                          \n[4] \"JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\"\n\n\nAdd journal abbreviation column\nFor visualization purposes, let’s add a new column of journal abbreviations\n\nCode# this dataframe maps each full name to an abbreviation\njournal_abbreviations &lt;- data.frame(\n  full_name = c(\"TECHNICAL COMMUNICATION QUARTERLY\", \"TECHNICAL COMMUNICATION\", \"WRITTEN COMMUNICATION\", \"JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\"),\n  abbreviation = c(\"TCQ\", \"TC\", \"WC\", \"JBTC\")\n)\n\njournal_abbreviations\n\n                                        full_name abbreviation\n1               TECHNICAL COMMUNICATION QUARTERLY          TCQ\n2                         TECHNICAL COMMUNICATION           TC\n3                           WRITTEN COMMUNICATION           WC\n4 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION         JBTC\n\n\nNow we can merge the full data with the abbreviations\n\nCode# Merge the data frames to add the 'abbreviation' column\nfull_data &lt;- merge(full_data, journal_abbreviations, by.x = \"source_title\", by.y = \"full_name\", all.x = TRUE)\n\nunique(full_data$abbreviation)\n\n[1] \"JBTC\" \"TC\"   \"TCQ\"  \"WC\"  \n\nCodefull_data[sample(1:nrow(full_data), 20, replace = FALSE),]\n\n                                        source_title\n1374                           WRITTEN COMMUNICATION\n338                          TECHNICAL COMMUNICATION\n593                          TECHNICAL COMMUNICATION\n762                TECHNICAL COMMUNICATION QUARTERLY\n995                TECHNICAL COMMUNICATION QUARTERLY\n733                TECHNICAL COMMUNICATION QUARTERLY\n1470                           WRITTEN COMMUNICATION\n1502                           WRITTEN COMMUNICATION\n396                          TECHNICAL COMMUNICATION\n1484                           WRITTEN COMMUNICATION\n1300                           WRITTEN COMMUNICATION\n1071               TECHNICAL COMMUNICATION QUARTERLY\n103  JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\n39   JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\n410                          TECHNICAL COMMUNICATION\n1431                           WRITTEN COMMUNICATION\n796                TECHNICAL COMMUNICATION QUARTERLY\n936                TECHNICAL COMMUNICATION QUARTERLY\n371                          TECHNICAL COMMUNICATION\n242  JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\n                                                                                      author_full_names\n1374                                                                                     Spinuzzi, Clay\n338                                 Alley, Michael; Schreiber, Madeline; Ramsdell, Katrina; Muffo, John\n593                                                                                  van der Meij, Hans\n762                                                                                             Yu, Han\n995                                                                      Rose, Emma J.; Tenenberg, Josh\n733                                                                                  Johnson, Robert R.\n1470                                                                                     Segal, Judy Z.\n1502 Conijn, Rianne; Speltz, Emily Dux; Zaanen, Menno van; Waes, Luuk Van; Chukharev-Hudilainen, Evgeny\n396                                                                                  Moore, P; Kreth, M\n1484                                                                                    Davila, Bethany\n1300                                                                                      Seltzer, Kate\n1071                                                                                        Clark, Dave\n103                                                            Petersen, Emily January; Walton, Rebecca\n39                                                                                         Jablonski, J\n410                          Lanius, Candice; Weber, Ryan; Spiegle, Jackie; Robinson, Joy; Potts, Robin\n1431                                                                                    Suzuki, Shinobu\n796                                                                                       Ding, Huiling\n936                                              Walton, Rebecca; Zraly, Maggie; Mugengana, Jean Pierre\n371                                     Jochmann-Mannak, Hanna; Lentz, Leo; Huibers, Theo; Sanders, Ted\n242                                                                     Amidon, Stevens; Blythe, Stuart\n                                                                                                                                                        article_title\n1374                                                                           Secret Sauce and Snake Oil: Writing Monthly Reports in a Highly Contingent Environment\n338                                                                                     How the design of headlines in presentation slides affects audience retention\n593                                                                                                     Developing and Testing a Video Tutorial for Software Training\n762                                                        Intercultural Competence in Technical Communication: A Working Definition and Review of Assessment Methods\n995                                                                      Poor poor dumb mouths, and bid them speak for me: Theorizing the use of personas in practice\n733                                                                                        The Ubiquity Paradox: Further Thinking on the Concept of User Centeredness\n1470                                                                                                   Internet Health and the 21st-Century Patient A Rhetorical View\n1502                                                                                                  A Product- and Process-Oriented Tagset for Revisions in Writing\n396                                                      From Wordsmith to communication strategist: Heresthetic and political maneuvering in technical communication\n1484                       Indexicality and Standard Edited American English: Examining the Link Between Conceptions of Standardness and Perceived Authorial Identity\n1300                                   A Lot of Students Are Already There: Repositioning Language-Minoritized Students as Writers in Residence in English Classrooms\n1071                                                                                                Content Management and the Separation of Presentation and Content\n103                                                                         Bridging Analysis and Action: How Feminist Scholarship Can Inform the Social Justice Turn\n39   Seeing technical communication from a career perspective - The implications of career theory for technical communication theory, practice, and curriculum design\n410                                                                                                          Drawing on Personas: How User Personas Affect Creativity\n1431                                                                                           Perceptions of the Qualities of Written Arguments by Japanese Students\n796                                           Transcultural Risk Communication and Viral Discourses: Grassroots Movements to Manage Global Risks of H1N1 Flu Pandemic\n936                                                                         Values and Validity: Navigating Messiness in a Community-Based Research Project in Rwanda\n371                                                                             Three Types of Children's Informational Web Sites: An Inventory of Design Conventions\n242                                                                                    Wrestling with proteus - Tales of communication managers in a changing economy\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 abstract\n1374                                                                                                                                                                                                                                                                                                                                                                                                                              At a search marketing company, each search engine optimization (SEO) specialist writes up to 10 to 12 complex 20-page monthly reports in the first ten business days of each month. These SEO specialists do not consider themselves to be writers, yet they generate these structurally and rhetorically complex reports as a matter of course, while negotiating a constantly changing landscape of a contingent, rapidly changing business sector. Under these conditions, how did the SEO specialists manage to write these reports so quickly and so well? What is the standing set of transformations that they enact in order to develop and produce these reports? And given the multiple contingencies, rapid changes, and high individual discretion at this organization-seemingly a recipe for discohesive practices-how did they maintain and develop this standing set of transformations in order to turn out consistent reports? In this article, I draw on writing, activity, and genre research (WAGR) to examine how Semoptco's SEO specialists produced monthly reports, specifically in terms of their constant networking, audience analysis, and ethos building. Finally, I draw implications for applying WAGR to knowledge work organizations.\n338                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            center dot Challenges the conventional use of a single word or short phrase as a slide headline. center dot Provides evidence showing that a succinct sentence headline identifying the main assertion leads to statistically significant increases in audience retention.\n593                                                                                                                                                                                                                                                                                                                                                                                  Purpose: Video tutorials for software training are rapidly becoming popular. A set of dedicated guidelines for the construction of such tutorials was recently advanced in Technical Communication (Van der Meij & Van der Meij, 2013). The present study set out to assess the cognitive and motivational effects of a video tutorial based on these guidelines. Method: Participants were 65 students (mean age 12.0 years) from elementary school. The procedure was as follows. First, students completed a pre-test. Next, they viewed videos and completed practice tasks. Finally, students completed a post-test and retention-test. Results: The pre-test revealed low scores on task relevance, and low initial task performance. During training, students reported positive mood states, high flow, and significantly higher task relevance than in pre-testing. Task performance rose significantly during training, and was also substantially higher on the post-test and retention-test than in pre-testing. Only cognitive factors significantly predicted task performance. Conclusion: The effectiveness of the video tutorial attests to the quality of the design guidelines on which it was based. The critical contribution of specific guidelines are a potential area for further research.\n762                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 The field of technical communication has made notable progress in researching and teaching intercultural issues. Not enough discussion, however, is available on assessing students' intercultural competence. This article attempts to start this discussion and invite further research. It suggests a working definition to conceptualize intercultural competence and draws upon diverse disciplines to review different assessment methods, including their strengths, drawbacks, and potential applications in technical communication classes.\n995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Although personas are commonly used to represent users in design, their rhetorical function has been little explored. In this article, the authors theorize personas' rhetorical function as ventriloquization, where one person speaks with the voice of another. In ventriloquizing users through personas, practitioners speak for users, while scripting personas to speak for their creators: each magnifies the others' voice. Personas represent a strategic rhetorical gambit for gaining legitimacy within organizations and technological decision-making processes.\n733                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 This essay argues that user centeredness has become ubiquitous and is in danger of being rendered meaningless. To address this problem, a meditative essay theorizes user centeredness by examining a base term-use-as defined through the ancient concepts of techne and the four causes of making. It concludes that user-centered design should employ the causes in order to avoid inversions during the development of all things technological.\n1470                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Internet health-here, the public use of information Web sites to facilitate decision making on matters of health and illness-is a rhetorical practice, involving text and trajectories of influence. A fulsome account of it requires attention to all parts of the rhetorical triangle-the speaker, the subject matter, and the audience-yet most scholarship on Internet health focuses on the speaker only: it typically raises concerns primarily about the dangers of unreliable sources, suggesting that, where speakers are reliable and information is accurate, Internet health simply empowers patients. This essay turns attention to the other elements of the triangle. It argues that health information is a complex entity-not only transmitted but also transformed by the Web- and, further, that Internet-health users are a complex audience-not only informed but also transformed by the Web. Rhetorically-minded researchers are well positioned to study not simply the informed patient but rather, more comprehensively, the wired one.\n1502                                                                                                                                                                                                                                                                                                                                                                                                          The study of revision has been a topic of interest in writing research over the past decades. Numerous studies have, for instance, shown that learning-to-revise is one of the key competences in writing development. Moreover, several models of revision have been developed, and a variety of taxonomies have been used to measure revision in empirical studies. Current advances in data collection and analysis have made it possible to study revision in increasingly precise detail. The present study aimed to combine previous models and current advances by providing a comprehensive product- and process-oriented tagset of revision. The presented tagset includes properties of external revisions: trigger, orientation, evaluation, action, linguistic domain, spatial location, temporal location, duration, and sequencing. We identified how keystroke logging, screen replays, and eye tracking can be used to extract both manually and automatically extract features related to these properties. As a proof of concept, we demonstrate how this tagset can be used to annotate revisions made by higher education students in various academic tasks. To conclude, we discuss how this tagset forms a scalable basis for studying revision in writing in depth.\n396                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Propose William Riker's heresthetic, or structuring the world so your can win, as a strategizing method Suggests that this approach will better position technical communicators to succeed in the global information economy\n1484                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   This article explores the indexicality (the ideological process that links language and identity) of standard edited American English and the ideologies (specifically, standard language ideology and Whiteness) that work to create and justify common patterns that associate privileged White students with written standardness and that disassociate underrepresented-especially African American-students from standard edited American English. Drawing on interviews with composition instructors about their readings of anonymous student texts, the author argues that indexicality and standardness are mutually informative: The non/standard features of student texts operate as indexicals for student-author identities just as perceived student-author identities influence the reading of a text as non/standard. Ultimately, this article offers inroads to challenging destructive and enduring indexical patterns that offer unearned privilege to some students at the expense of others and, in the process, perpetuate race- and class-based privilege.\n1300                                                                                                                                                                                                                                                                                                                                                                        This article centers on Faith, a Latinx bilingual student who, because of her failure to pass a standardized exam in English language arts, had to repeat 11th-grade English. Despite this stigma of being a repeater, during the year-long ethnographic study I conducted in her classroom, Faith proved to be an insightful and critical reader and self-described poet who shared her writing with her peers as well as with other poets in online forums. Drawing from that more expansive classroom study, this article features Faith's metacommentary on language and her own writing process and explores how her insights (1) disrupt monoglossic, raciolinguistic ideologies by highlighting the disconnect between her sophisticated understandings of language and the writing process and her status as a struggling student; (2) draw attention her wayfinding, which chronicles her navigation of those ideologies that complicate her search for a writerly identity and obscure the translingual nature of all texts and all writers; and (3) can move teachers and researchers of writing to reimagine the writing classroom so that it (re)positions students like Faith as writers in residence, whose existing translingual writing practices and wayfinding can serve as mentors and guides for others.\n1071                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The importance of separating presentation from content is taken as a given in many kinds of publishing, despite the fact that the notion of separation has received little critical scrutiny. I provide a closer look at the separation, first by providing contemporary and historical context, then by laying out key distinctions in theways the separation argument is used in Web design versus Web content management versus full-featured content management systems (CMSs). I suggest that these distinctions are critical in how we should view the separation and the implications of the separation for the work of technical communicators.\n103                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          This article calls for recognition of ways in which feminisms have, do, and can inform social justice work in technical and professional communication (TPC)even social justice work that is not explicitly feminist. The authors distill some areas of feminist TPC scholarship that are relevant to future social justice work: (a) epistemological contributions, ways of knowing and methods for discovering them and (b) reclamations of dominant topics, groundwork laid by feminist research on technology and science. They close with nine recommendations to inspire scholars with specific ways to use feminist methodologies and theories to enhance social justice scholarship.\n39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  This article explores the implications of career research for the field of technical communication. The interdisciplinary strands of career theory provide a useful perspective on the contexts of work with which our field interacts and for which it prepares technical communicators. To help us gain an understanding of the historical, methodological, and ideological contexts of career studies, the article first provides a historical overview then reviews current trends, particularly in the way recent research diverges from traditional approaches. Finally, it discusses four broad but interrelated strands of inquiry that technical communication researchers might pursue based on research in career studies.\n410                                                                                                                                                                                                                                                                              Purpose: While many industry professionals, including user-experience designers, create personas to represent their target users, debate still exists about whether personas really help organizations improve user-centered attitudes and product design. This study tested whether personas increase performance and empathy on a creativity task. Method: 172 participants completed a creativity task in which they were given seven minutes to draw a space alien. Participants drew aliens either for themselves, an unspecified author, or an author represented by a persona. Participants also completed a survey collecting their attitudes about the activity and alien drawings. Four coders then used a five-item rubric to evaluate the creativity of each drawing. Results: There were no differences in creativity scores for the alien drawings between the persona, self, and other author groups. However, people drawing for themselves and the persona author were more confident in their alien drawings and more willing to share them. Within the persona group, those participants who reported thinking about the persona while drawing had more positive feelings about the drawing and the author who would use it. Conclusion: While the persona did not result in more creative drawings, personas may increase confidence and user-centered attitudes among designers when actively used.\n1431                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             This study examines how Japanese students perceive the qualities of written arguments that were constructed to have different forms. Based on the theoretical dimensions of verbal communication styles that Gudykunst and Ting-Toomey (1988) proposed, the research questions asked whether the respondents would perceive direct arguments to be of higher quality than indirect arguments. They also asked whether they would perceive elaborate arguments to be of higher quality than succinct arguments. Japanese college students voluntarily responded to a questionnaire. The results revealed that they gave higher ratings to direct arguments than to indirect arguments for both of the two indicators, and higher ratings to elaborate arguments than to succinct arguments for two indicators out of the three. The results were discussed and implications were offered.\n796                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        This article proposes a theoretical framework of transcultural risk communication to examine how global connectivities influence communication about H1N1 flu. A case study was conducted to investigate risk management policies at global, regional, and translocal levels to cope with health threats posed by the emerging H1N1 flu epidemic. We explored how risk management approaches by Chinese Internet users facilitated the employment of a unique risk measure of exit and entry screening for returnees to China.\n936                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Community-based research in technical communication is well suited to supporting empowerment and developing contextualized understandings, but this research is messy. Presenting fieldwork examples from an interdisciplinary technical communication/medical anthropology study in Rwanda, this article conveys challenges that the authors encountered during fieldwork and their efforts to turn the messy constraints of community-based research into openings. Explicitly considering values and validity provided a strategy for our efforts to democratically share power, maximize rigor, and navigate uncertainty.\n371  Purpose: Research on Web design conventions has an almost exclusive focus on Web design for adults. There is far less knowledge about Web design for children. For the first time, an overview is presented of the current design conventions for children's informational Web sites. Method: In this study a large corpus of 100 children's international, informational Web sites from four different domains (science, pets, arts, and health) is analyzed. The instrument for analyzing the Web sites included categories on visual design, navigation and information architecture. Results: The design conventions identified in this study show that designers of children's informational Web sites often follow general Web design guidelines. This study also shows that there is still much confusion about how to design Web sites for children. A closer look at the data revealed three categories of informational Web sites especially designed for children, diverging from a classical to a playful design approach. Conclusion: An overview is presented of the current design conventions for children's informational Web sites. The identified design conventions should be further tested and validated as design standards for children's informational Web design. Further, the design of children's informational Web sites is determined by two dimensions of aesthetics; classical and expressive. In this study, expressive aesthetics results in playful visual design or in a total playful interaction design. The effects of playful design on children's affect and cognition will be an important topic in future research on children's digital search behavior.\n242                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Because communication specialists often lack the power and prestige of other knowledge workers, such as engineers and product designers, managers who direct the work of communication specialists face unique challenges. This study, based on interviews with 11 communication managers, found that their agency and identity were determined both by the structure of the organizations in which they worked and by their use of genres, technologies, and regulatory techniques. With their work undergoing transition because of globalization, outsourcing, and rapid technological change, the stories that these managers tell demonstrate the importance of studying management as it specifically applies to communication specialists.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         cited_references\n1374                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 &lt;NA&gt;\n338                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  &lt;NA&gt;\n593                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  &lt;NA&gt;\n762                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Across Cultures LLC, 2010, PET CULT STYL IND; Allen J., 1990, J BUSINESS TECHNICAL, V4, P68, DOI DOI 10.1177/105065199000400204; Andrews DC, 2000, MANAGING GLOBAL COMMUNICATION IN SCIENCE AND TECHNOLOGY, P67; [Anonymous], 2014, COUNS PSYCHOL Q, DOI DOI 10.1080/713658487; [Anonymous], GLOBAL CONTEXTS CASE; [Anonymous], 1994, CROSS CULTURAL DIALO; [Anonymous], 1993, TEACHING CULTURE STR; [Anonymous], 1992, STUDENTS ABROAD STRA; [Anonymous], 1997, HUMAN COMMUNICATION; [Anonymous], TECHNICAL COMMUNICAT; [Anonymous], 2008, J TECH WRITING COMMU; [Anonymous], 2005, J INFORM SYSTEMS ED; [Anonymous], TECH COMMUN; [Anonymous], 1998, HUMAN CONNECTION; [Anonymous], 1995, INT TECHNICAL COMMUN; [Anonymous], 2004, HDB INTERCULTURAL TR, DOI DOI 10.4135/9781452231129.N4; Barker T, 2006, TECH COMMUN Q, V15, P191, DOI 10.1207/s15427625tcq1502_4; BHAWUK DPS, 1992, INT J INTERCULT REL, V16, P413, DOI 10.1016/0147-1767(92)90031-O; Bosley DS, 1999, EXPLORING THE RHETORIC OF INTERNATIONAL PROFESSIONAL COMMUNICATION: AN AGENDA FOR TEACHERS AND RESEARCHERS, P253; BOUD D, 1989, HIGH EDUC, V18, P529, DOI 10.1007/BF00138746; Byram M, 1994, TEACHING AND LEARNIN; Caligiuri PM, 2000, PERS PSYCHOL, V53, P67, DOI 10.1111/j.1744-6570.2000.tb00194.x; Chen GM., 2000, DEV VALIDATION INTER; Coleman HLK, 1996, COUNS PSYCHOL, V24, P216, DOI 10.1177/0011000096242003; Corbett J., 1996, TECHNICAL COMMUNICAT, V5, P411, DOI [10.1207/s15427625tcq0504_3, DOI 10.1207/S15427625TCQ0504_3]; Corbitt N, 1998, GLOBAL AWARENESS PRO; Cushner K., 1996, INTERCULTURAL INTERA; DANDREA M, 1991, J COUNS DEV, V70, P143, DOI 10.1002/j.1556-6676.1991.tb01576.x; Deardorff D. K., 2006, J STUD INT EDUC, V10, P241, DOI [10.1177/1028315306287002, DOI 10.1177/1028315306287002]; DeVoss D, 2002, J BUS TECH COMMUN, V16, P69, DOI 10.1177/1050651902016001003; Flammia M, 2005, IEEE T PROF COMMUN, V48, P401, DOI 10.1109/TPC.2005.859724; FREEDMAN A, 1994, WRIT COMMUN, V11, P193, DOI 10.1177/0741088394011002002; GUDYKUNST WB, 1977, COMMUNICATION YB, V1, P415; Hofstede G. J., 2002, EXPLORING CULTURE EX; Hunsinger RP, 2006, TECH COMMUN Q, V15, P31, DOI 10.1207/s15427625tcq1501_4; Huot B, 1996, COLL COMPOS COMMUN, V47, P549, DOI 10.2307/358601; IGB Network, ASS TOOLS; IMAHORI TT, 1989, INT J INTERCULT REL, V13, P269, DOI 10.1016/0147-1767(89)90013-8; Ingulsrud JE, 2002, INT J INTERCULT REL, V26, P473, DOI 10.1016/S0147-1767(02)00030-5; Jacobson W, 1999, INT J INTERCULT REL, V23, P467, DOI 10.1016/S0147-1767(99)00006-1; Johnson-Sheehan R., 2010, TECHNICAL COMMUNICAT, V3rd; KOESTER J, 1988, INT J INTERCULT REL, V12, P233, DOI 10.1016/0147-1767(88)90017-X; Kynell T. C., 1998, SCENARIOS TECHNICAL; Lazar Ildiko, 2007, DEVELOPING ASSESSING; Lievens F, 2003, J APPL PSYCHOL, V88, P476, DOI 10.1037/0021-9010.88.3.476; Lovitt CR, 1999, EXPLORING THE RHETORIC OF INTERNATIONAL PROFESSIONAL COMMUNICATION: AN AGENDA FOR TEACHERS AND RESEARCHERS, P1; MARKEL M, 2009, TECHNICAL COMMUNICAT; MARTIN JN, 1989, INT J INTERCULT REL, V13, P303, DOI 10.1016/0147-1767(89)90015-1; Matveeva N., 2007, J TECH WRIT COMMUN, V37, P151, DOI [10.2190/85J8-2P74-1378-2188, DOI 10.2190/85J8-2P74-1378-2188]; Maylath B, 1997, J BUS TECH COMMUN, V11, P339, DOI 10.1177/1050651997011003006; Munger R., 2005, DOCUMENT BASED CASES; Ruben B.D., 1976, GROUP ORGAN STUD, V1, P334, DOI DOI 10.1016/J.JACI.2012.05.050; Ruben BD., 1979, INT J INTERCULTURAL, V3, P15, DOI [10.1016/0147-1767(79)90045-2, DOI 10.1016/0147-1767(79)90045-2]; Spyridakis J. H., 1997, IEEE Transactions on Professional Communications, V40, P4, DOI 10.1109/47.557512; St Amant K., 2005, IEEE Transactions on Professional Communication, V48, P219, DOI 10.1109/TPC.2005.849659; St Amant K, 2005, J TECHNICAL WRITING, V35, P191; Thrush EA, 2001, TECH COMMUN, V48, P289; VALETTE RM, 1986, CULTURE BOUND BRIDGI, P179; Varner I., 2006, INTERCULTURAL COMMUN; WEISS T, 1992, TECHNICAL COMMUNICAT, V1, P23; Yancey KB, 1999, COLL COMPOS COMMUN, V50, P483, DOI 10.2307/358862\n995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [Anonymous], 1993, VOICES MIND SOCIOCUL; [Anonymous], 2001, WHO SPEAKS POOR NATL; [Anonymous], 2007, TALKING VOICES REPET; ASTINGTON JW, 1995, COGNITION EMOTION, V9, P151, DOI 10.1080/02699939508409006; Bakhtin M., 1986, SPEECH GENRES OTHER; Bakhtin M. M., 1981, DIALOGIC IMAGINATION; Bodker K., 2004, PARTICIPATORY IT DES; Cooper A., 1999, PROC SOFTWAREERGONOM; Cooper A., 2008, ORIGIN PERSONAS; Friess E., 2012, P SIGCHI C HUM FACT, DOI [DOI 10.1145/2207676.2208572, 10.1145/2207676.2208572]; GOFFMAN Erving, 1959, PRESENTATION SELF EV; Grudin J., 2002, PDC 2002. Proceedings of the Participatory Design Conference, P144; Gutierrez C., 2016, USER EXPERIENCE MAGA, V16; Harris J., 1994, WRITING THEORY CRITI, P141; Johnson RR, 2007, IEEE T PROF COMMUN, V50, P320, DOI 10.1109/TPC.2007.908730; Johnson Robert R., 1998, USER CENTERED TECHNO; KAPOR M, 1996, BRINGING DESIGN SOFT, P1; Kaptelinin Victor, 2006, ACTING TECHNOLOGY AC; Massanari AL, 2010, NEW MEDIA SOC, V12, P401, DOI 10.1177/1461444809346722; MCGINN J, 2008, P 26 ANN SIGCHI C HU, P1521; McNely B, 2015, TECH COMMUN Q, V24, P1, DOI 10.1080/10572252.2015.975958; Miaskiewicz T., 2009, P AM C INF SYST AMCI; Mulder S., 2006, USER IS ALWAYS RIGHT; Nieters J.E., 2007, CHI 07 EXTENDED ABST, DOI [10.1145/1240866.1240905, DOI 10.1145/1240866.1240905]; Pruitt J., 2003, P 2003 C DES US EXP, P1, DOI [10.1145/997078.997089, DOI 10.1145/997078.997089]; Pruitt J., 2010, PERSONA LIFECYCLE KE; Putnam C., 2012, ICTD 12 P 5 INT C IN; Putnam C., 2010, THESIS; Putnam C, 2009, INF TECHNOL INT DEV, V5, P51; Rose Emma J., 2015, International Journal of Sociotechnology and Knowledge Development, V7, P1, DOI 10.4018/IJSKD.2015070101; RUBENSTEIN R, 1984, HUMAN FACTOR DESIGNI; Salazar S., 2014, USER EXPERIENCE MAGA, V14; Sclove R. E., 1995, RESISTING VIRTUAL LI; Scott JB, 2008, TECH COMMUN Q, V17, P381, DOI 10.1080/10572250802324929; Shakespeare W., 1623, OXFORD SHAKESPEARE J; SMITH WR, 1956, J MARKETING, V21, P3, DOI 10.2307/1247695; Spinuzzi C., 2003, TRACING GENRES ORG S; Sun H., 2012, CROSS CULTURAL TECHN; Tannen D, 2010, J PRAGMATICS, V42, P307, DOI 10.1016/j.pragma.2009.06.002; Winograd T.A., 1996, BRINGING DESIGN SOFT\n733                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Anderson John M., 1966, DISCOURSE THINKING; [Anonymous], 1978, AUTONOMOUS TECHNOLOG; Blythe S., 2001, Computer and Composition, V18, P329, DOI 10.1016/S8755-4615(01)00066-4; Brady Ann, 2004, RHETOR REV, V23, P57; Carroll J., 1998, MINIMALISM NURNBERG; Carruthers Mary, 1998, CRAFT THOUGHT MEDITA; Certeau Michelde., 1984, PRACTICE EVERYDAY LI; Grabill J. T., 1998, TECH COMMUN Q, V7, P415, DOI [10.1080/10572259809364640, DOI 10.1080/10572259809364640]; Heidegger Martin, 1977, QUESTION TECHNOLOGY, P115; Johnson R. R., 1998, USER CTR TECHNOLOGY; Lakoff G, 2003, METAPHORS WE LIVE; Mitcham C., 1994, THINKING TECHNOLOGY; Nielsen J., 2000, DESIGNING WEB USABIL; Nielsen J., 1993, USABILITY ENG; Norman D.A., 2007, DESIGN FUTURE THINGS; Norman Donald A, 2004, EMOTIONAL DESIGN WHY; Ranney FrancesJ., 2000, TECHNICAL COMMUNICAT, V9, P9, DOI [10.1080/10572250009364683, DOI 10.1080/10572250009364683]; Rojcewicz R., 2006, GODS TECHNOLOGY READ; Salvo M. J., 2001, TECH COMMUN Q, V10, P273, DOI [DOI 10.1207/S15427625TCQ1003_3, 10.1207/s15427625tcq1003_3]; Sconce J, 2003, NEW MEDIA THEORIES P, P179; Scott JB, 2008, TECH COMMUN Q, V17, P381, DOI 10.1080/10572250802324929; Spinuzzi C., 2003, TRACING GENRES ORG S; Stiegler B., 1998, TECHNICS TIME; Vernant J.-P., 1982, ORIGINS GREEK THOUGH; WILD J, 1941, PHILOS PHENOMENOLOGI, V1, P255\n1470                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 &lt;NA&gt;\n1502                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 &lt;NA&gt;\n396                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  &lt;NA&gt;\n1484                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 &lt;NA&gt;\n1300                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 &lt;NA&gt;\n1071                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Albers MJ, 2003, TECH COMMUN, V50, P335; [Anonymous], DESIGN DISCOURSE; [Anonymous], 1982, MODERN ART MODERNISM; [Anonymous], DESIGN DISCOURSE HIS; [Anonymous], 2000, SORTING THINGS OUT C; [Anonymous], 1995, GENRE KNOWLEDGE DISC; [Anonymous], 2004, TECH COMMUN Q; [Anonymous], 1990, GENRE ANAL ENGLISH A; [Anonymous], 1996, DYNAMICS DOCUMENT DE; [Anonymous], POWERPOINT IS EVIL; Berners-Lee T., 1992, SGML; Billig M., 1987, ARGUING THINKING RHE; Birchfield, 2004, DEFENSE POWERPOINT; Broberg M, 2004, TECH COMMUN-STC, V51, P537; Burton G., 2007, SILVA RHETORICAE FOR; Carter L, 2003, TECH COMMUN, V50, P317; Clark D, 2002, P 20 ANN INT C COMP, P20, DOI [10.1145/584955.584959, DOI 10.1145/584955.584959]; Cohen M., 2004, SEPARATION WEB DESIG; Hackos J. T., 2002, CONTENT MANAGEMENT D; Intentional Design Inc, 2006, TYP CONT MAN; Joyce E., 2003, STUDY CONTENT MANAGE; Keller K. P., 2003, GREAT MAN HAS SPOKEN; McLuhan M., 1994, UNDERSTANDING MEDIA; Meyer E, 2003, INCOMPLETE DIVORCE; MILLER CR, 1984, Q J SPEECH, V70, P151, DOI 10.1080/00335638409383686; Norman D., 2004, AFFORDANCES DESIGN; Norman D., 2013, DESIGN EVERYDAY THIN; Parapadakis G, 2000, WHATS IN A NAME; Porter James E, 1998, RHETORICAL ETHICS IN; Postman N., 1992, TECHNOPOLY SURRENDER; Postman N., 1985, AMUSING OURSELVES DE; Rockley A., 2002, MANAGING ENTERPRISE; Rockley Group, 2002, WHAT IS UN CONT STRA; Sapienza F, 2004, TECH COMMUN-STC, V51, P399; Sapienza Filipp, 2002, J TECHNICAL WRITING, V32, P155; Simons T., 2004, EDWARD TUFTE DOESNT; Soegaard M., 2003, AFFORDANCES; Stein B., 2000, SEPARATION ANXIETY M; Tufte E., 2003, POWERPOINT DOES ROCK; Tufte E. R., 2003, COGNITIVE STYLE POWE; Wick C, 2000, TECHNICAL COMMUNICAT, V47, P15; Winsor DA, 2000, WRIT COMMUN, V17, P155, DOI 10.1177/0741088300017002001; World Wide Web Consortium, 2007, GOALS; World Wide Web Consortium, 2007, DEV IND PRINC; [No title captured]\n103                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  &lt;NA&gt;\n39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   &lt;NA&gt;\n410                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  &lt;NA&gt;\n1431                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 &lt;NA&gt;\n796                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [Anonymous], 2009, LANCET, V373, P1495, DOI 10.1016/S0140-6736(09)60826-6; [Anonymous], 2009, NATURE, V459, P9, DOI 10.1038/459009a; [Anonymous], 2010, CHINA MEDIA RES; [Anonymous], 2009, WEN JIABAO VISITED D; [Anonymous], HUMAN FLESH SEARCH E; [Anonymous], 2009, WEN WEI PO; [Anonymous], 2009, S CHINA MORNING POST, P10; [Anonymous], 2009, COMMUNICATION 2009; [Anonymous], J ENGLISH ACAD PURPO; [Anonymous], 2004, MAD COWS MOTHERS MIL; [Anonymous], 2009, TIANYA FORUM; [Anonymous], 2009, CALL ACT LET BA MANM; [Anonymous], 2009, JINGHUA TIMES; [Anonymous], 2009, GUANGZHOU DAILY; Appadurai A, 2000, PUBLIC CULTURE, V12, P627, DOI 10.1215/08992363-12-3-627; Appadurai A., 1996, MODERNITY LARGE CULT; Beck U., 2009, WORLD RISK; Bell D. M., 2004, EMERGING INFECT DIS, DOI [10.3201=eid1011.040729, DOI 10.3201=EID1011.040729]; Blackwell T., 2003, NATL POST, pA2; Branigan T., 2010, CHINAS INTERNET GENE; Brean J., 2003, NATL POST, pA1; Brean J., 2003, NATL POST, P6; Centers for Disease Control and Prevention, 2009, CDC BRI PUBL HE INV; Certeau Michelde., 1984, PRACTICE EVERYDAY LI; Chan M., 2009, WORLD HLTH ASSEMBLY; Chan M., 2009, WORLD HLTH ORG DIREC; Chen S., 2009, S CHINA MORNING POST, P4; Chen S., 2009, S CHINA MORNING POST, P5; Ding, 2007, RHETOR REV, V26, P142, DOI DOI 10.1080/07350190709336706; Ding H. F., 2007, THESIS; Ding HL, 2009, TECH COMMUN Q, V18, P327, DOI 10.1080/10572250903149548; Fang Y., 2009, SICHUAN DAILY; Fletcher H., 2008, TIMES; Grabill J. T., 1998, TECH COMMUN Q, V7, P415, DOI [10.1080/10572259809364640, DOI 10.1080/10572259809364640]; Grady D., 2009, NY TIMES, pA1; Grewal I, 2005, TRANSNATIONAL AM FEM; Hesford WS, 2008, COLL ENGL, V70, P461, DOI 10.2307/25472283; Huang Z., 1982, MINGMIN LOVE DRAGON; Huo L., 2009, FIRST FINANCE DAILY; Katz S. B., 1996, GREEN CULTURE ENV RH, P111; Lai C., 2009, S CHINA MORNING POST, P4; Lee AYL, 2008, DIS APPL POL SOC CUL, V30, P69; Lee E., 2009, S CHINA MORNING POST, P4; Lee E., 2009, S CHINA MORNING POST, P2; Li S., 2009, TIANJIN DAILY; Lin L., 2003, WALL PEOPLE CHINESE; Liu Y., 2009, WENWEIBO; Lu J, 2009, GUANGZHOU DAILY, P2; Lu J., 2009, GUANGZHOU DAILY, P3; Lu X, 2008, DIS APPL POL SOC CUL, V30, P109; MENGIN F, 2004, CYBER CHINA RESHAPIN; Ong A., 1999, FLEXIBLE CITIZENSHIP; Ong A, 2004, CERI SER INT REL POL, P237; Pisik B., 2009, WASHINGTON TIMES, pA01; Powers JH, 2008, DIS APPL POL SOC CUL, V30, P1; Price-Smith A. T., 2009, CONTAGION CHAOS DIS, DOI [10.7551/mitpress/7390.001.0001, DOI 10.7551/MITPRESS/7390.001.0001]; Public Health Agency of Canada, 2004, HEALTH CAN PUBL, V1210; ROSS A, 1989, RESPECT INTELLECTUAL; Sauer B. A., 2003, RHETORIC RISK TECHNI; Sauer BA, 1996, J BUS TECH COMMUN, V10, P306, DOI 10.1177/1050651996010003002; Schiller B., 2009, TORONTO STAR; Scott JB, 2006, Q J SPEECH, V92, P115, DOI 10.1080/00335630600816938; Simmons M, 2007, PARTICIPATION POWER; Song H., 2009, GLOBAL TIMES; Starke-Meyerring D, 2005, J BUS TECH COMMUN, V19, P468, DOI 10.1177/1050651905278033; Sum NL, 2004, CERI SER INT RELAT P, P205; Thompson A., 2003, TORONTO STAR, pA4; Wald Patricia, 2008, CONTAGIOUS CULTURES; Wang J., 2009, PEOPLES DAILY; Wang Z., 2009, CHINA DAILY; Weber I, 2008, DIS APPL POL SOC CUL, V30, P145; World Health Organization, 2003, UPD 11 WHO REC NEW; World Health Organization, 2003, UPD 17 ADV HONG KONG; World Health Organization, 2009, RET TRAV RESTR; Zeng G., 2009, COMMUNICATION; Zhang KHL, 2005, CHINA ECON REV, V16, P293, DOI 10.1016/j.chieco.2005.02.004\n936  Africa Development Bank, 2011, RWAND BANK GROUP COU; Agboka GY, 2013, TECH COMMUN Q, V22, P28, DOI 10.1080/10572252.2013.730966; [Anonymous], TECHNICAL COMMUNICAT; [Anonymous], QUALITATIVE NURSING; [Anonymous], P INT PROF COMM C IP; [Anonymous], CULTURE COMMUNICATIO; [Anonymous], AAAI SPRING S ART IN; [Anonymous], 2005, J URBAN HEALTH, DOI 10.1093/jurban/jti034; [Anonymous], 2008, COMMUNITY BASED PART; [Anonymous], 2005, REFLECTIONS J WRITIN; [Anonymous], 2003, RISKY RHETORIC AIDS; [Anonymous], 1997, VIDEO CRITICAL CHILD; [Anonymous], 2012, THE NEW TIMES; [Anonymous], HUMAN ORG RES FIELD; [Anonymous], 2006, INT COMMUN GAZ, DOI DOI 10.1177/1748048506065764; Bakardjieva M., 2004, READINGS VIRTUAL RES, P338; Baldauf S., 2007, CHRISTIAN SCI MONITO; Bandyopadhyay T., 2009, P SO ASS INF SYST C, P140; Berman Rachel, 2010, INT J QUAL METH, V10, P178; Blythe S, 2008, J BUS TECH COMMUN, V22, P272, DOI 10.1177/1050651908315973; Boal Augusto, 1993, THEATRE OPPRESSED; Bowdon M., 2004, TECHNICAL COMMUNICAT, V13, P325, DOI [10.1207/s15427625tcq1303_6, DOI 10.1207/S15427625TCQ1303_6]; Burawoy M, 2009, ETHNOGRAPHY, V10, P317, DOI 10.1177/1466138109342815; Clark D., 2004, TECH COMMUN Q, V13, P307; Clark Dave, 2010, DIGITAL LITERACY TEC, P85; Conquergood D, 2002, TDR-DRAMA REV-J PERF, V46, P145, DOI 10.1162/105420402320980550; Davison R, 2004, INFORM SYST J, V14, P65, DOI 10.1111/j.1365-2575.2004.00162.x; Ding HL, 2009, TECH COMMUN Q, V18, P327, DOI 10.1080/10572250903149548; Donner J, 2006, INF TECHNOL INT DEV, V3, P3; Dysart-Gale D, 2011, IEEE T PROF COMMUN, V54, P43, DOI 10.1109/TPC.2009.2035573; Edwards R., 1998, J ETHN MIGR STUD, V24, P197, DOI [10.1080/1369183X.1998.9976626, DOI 10.1080/1369183X.1998.9976626]; Evia C, 2012, J BUS TECH COMMUN, V26, P340, DOI 10.1177/1050651912439697; Faber Brenton D., 2002, COMMUNITY ACTION ORG; FEENBERG A., 2002, TRANSFORMING TECHNOL; Flammia M, 2005, IEEE T PROF COMMUN, V48, P401, DOI 10.1109/TPC.2005.859724; Fleckenstein KS, 2008, COLL COMPOS COMMUN, V60, P388; Gauntlett D., 2006, VISUAL STUD, V21, P82, DOI [DOI 10.1080/14725860600613261, 10.1080/14725860600613261]; Grabill J.T., 2000, TECHNICAL COMMUNICAT, V9, P29, DOI [10.1080/10572250009364684, DOI 10.1080/10572250009364684]; GUBA EG, 1981, ECTJ-EDUC COMMUN TEC, V29, P75; HUGHES MA, 2008, RES PRIMER TECHNICAL; Human Rights Watch, 2003, LAST WOUNDS CONSQ GE; Israel B A, 2001, Educ Health (Abingdon), V14, P182; Johnson R. R., 1998, USER CTR TECHNOLOGY; Jones N. N., 2014, RHETORIC PROFESSIONA, V5, P14; Kanyesigye F., 2012, THE NEW TIMES; Kapborga Inez, 2002, Nurs Inq, V9, P52, DOI 10.1046/j.1440-1800.2002.00127.x; Kerlinger FN, 1973, FDN BEHAV RES; Knowles J. G., 2008, HDB ARTS QUALITATIVE, P55, DOI DOI 10.4135/9781452226545; Lane SD, 2011, HUM ORGAN, V70, P289, DOI 10.17730/humo.70.3.v1hv08236w4411h6; Larkin PJ, 2007, QUAL HEALTH RES, V17, P468, DOI 10.1177/1049732307299258; Le Dantec CA, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P627; LONG RG, 2000, INT J VALUE BASED MA, V13, P189, DOI DOI 10.1023/A:1007850027589; Longo B., 2010, DIGITAL LITERACY TEC, P147; Mcintyre M, 2008, J HEALTH PSYCHOL, V13, P213, DOI 10.1177/1359105307086701; McNely Brian J., 2013, P 31 ACM INT C DESIG, P123; Melton JH, 2008, IEEE T PROF COMMUN, V51, P198, DOI 10.1109/TPC.2008.2000346; Miller Carolyn R., 1989, TECHNICAL WRITING TH, P14; MILLER CR, 1979, COLL ENGL, V40, P610, DOI 10.2307/375964; Mosher H, 2013, QUAL RES, V13, P428, DOI 10.1177/1468794113488131; Musoni E., 2010, THE NEW TIMES; Negash Solomon, 2012, International Journal of Information Systems and Social Change, V3, P39, DOI 10.4018/jissc.2012040103; Nyirabera M. C., 2012, UBUSHAKASHATSI BWA Y; Ornatowski C. M., 2004, TECH COMMUN Q, V13, P251, DOI [10.1207/s15427625tcq1303_2, DOI 10.1207/S15427625TCQ1303_2]; Pan ZD, 2011, ASIAN J COMMUN, V21, P116, DOI 10.1080/01292986.2010.543555; Price R.J., 2014, RHETORIC PROFESSIONA, V5, P90; Riessman C., 2000, NARRATIVE CULTURAL C, P128; Risku Hanna, 2001, CLAIMS CHANG CHALL T, P181; Rubin H. J., 1995, QUALITATIVE INTERVIE; Rubinstein-Avila E, 2013, INT J QUAL STUD EDUC, V26, P1041, DOI 10.1080/09518398.2012.736642; Rude CD, 2009, J BUS TECH COMMUN, V23, P174, DOI 10.1177/1050651908329562; Rylko-Bauer B, 2006, AM ANTHROPOL, V108, P178, DOI 10.1525/aa.2006.108.1.178; Schensul JJ, 2006, AM J COMMUN PSYCHOL, V38, P79, DOI 10.1007/s10464-006-9059-y; Schensul JJ, 1999, HEALTH EDUC BEHAV, V26, P266, DOI 10.1177/109019819902600209; SCHWABENLAND C, 2002, PARTICIPATION N S NE, P5; Seymour S., 2012, THESIS; Simmons W. Michelle., 2007, PARTICIPATION POWER; Simon Sherry, 1996, GENDER TRANSLATION C; Sommers M., 2006, 32 WORLD BANK; Soucy K., 2012, SMASHING MAGAZINE; Spinuzzi C, 2005, TECH COMMUN Q, V14, P411, DOI 10.1207/s15427625tcq1404_3; Spinuzzi Clay, 2003, TRACING GENRES ORG; Squires A, 2009, INT J NURS STUD, V46, P277, DOI 10.1016/j.ijnurstu.2008.08.006; Starke-Meyerring D, 2007, TECH COMMUN Q, V16, P139, DOI 10.1207/s15427625tcq1602_1; Sun H., 2012, CROSSCULTURAL TECHNO; Sun HT, 2006, TECH COMMUN Q, V15, P457, DOI 10.1207/s15427625tcq1504_3; Temple B., 2004, QUAL RES, V4, P161, DOI DOI 10.1177/1468794104044430; Thatcher B., 2010, RAW READING WRITING, P157; Thatcher B, 2006, TECH COMMUN Q, V15, P383, DOI 10.1207/s15427625tcq1503_6; Usengumukiza F., 2009, OVERVIEW RWANDAS ICT; Varpio L, 2007, J BUS TECH COMMUN, V21, P343, DOI 10.1177/1050651907303991; Visser F. S., 2005, CoDesign, V1, P119, DOI 10.1080/15710880500135987; Walton R., 2013, KAIROS J RHETORIC TE, V17; Walton R., 2013, J RHETORIC PROFESSIO, V4, P78; Walton R, 2012, INF TECHNOL INT DEV, V8, P69; Ward LM, 2009, INTERVENTION, V7, P17, DOI 10.1097/WTF.0b013e32832ad3ac; Youngblood SA, 2013, TECH COMMUN Q, V22, P260, DOI 10.1080/10572252.2013.775542; Zraly M., 2013, SOC PSYCH ANTHR BIEN; Zraly M., 2009, AM ANTHR ASS ANN M P\n371                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  &lt;NA&gt;\n242                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  &lt;NA&gt;\n     cited_reference_count publication_year publication_type abbreviation\n1374                    NA             2010                J           WC\n338                     13             2006                J           TC\n593                     45             2014                J           TC\n762                     61             2012                J          TCQ\n995                     40             2018                J          TCQ\n733                     25             2010                J          TCQ\n1470                    NA             2009                J           WC\n1502                    NA             2022                J           WC\n396                     59             2005                J           TC\n1484                    NA             2012                J           WC\n1300                    NA             2022                J           WC\n1071                    45             2007                J          TCQ\n103                     NA             2018                J         JBTC\n39                      NA             2005                J         JBTC\n410                    101             2020                J           TC\n1431                    NA             2011                J           WC\n796                     76             2013                J          TCQ\n936                     98             2015                J          TCQ\n371                     44             2012                J           TC\n242                     NA             2008                J         JBTC"
  },
  {
    "objectID": "demos/week03/wk03_wos_journals.html#visualize-the-full-data",
    "href": "demos/week03/wk03_wos_journals.html#visualize-the-full-data",
    "title": "Wk 03: Exploring TC journals, (pt 2)",
    "section": "Visualize the full data",
    "text": "Visualize the full data\nWe’ll try a few different displays.\nStacked bar\n\nCode# count of articles by year, by journal\nggplot(full_data, aes(x = publication_year, fill = abbreviation)) +\n  geom_bar() +\n  labs(title = \"Articles per Year in TC and TCQ\",\n       x = \"Publication Year\",\n       y = \"Number of Articles\") +\n  theme_light()\n\n\n\n\nFaceted bar\n\nCode# count of articles by year, by journal\nggplot(full_data, aes(x = publication_year)) +\n  geom_bar() +\n  labs(title = \"Articles per Year\",\n       x = \"Publication Year\",\n       y = \"Number of Articles\") +\n  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5, size = 4) +\n   facet_wrap(~ abbreviation, ncol = 1) + # Change ncol as needed\n   theme_fivethirtyeight()\n\n\n\n\nLine and points\nFor a line graph, we first have to create a new dataframe that includes article counts\n\nCode# Summarize the data to count the number of articles by source_title and publication_year\narticle_counts &lt;- full_data %&gt;%\n  group_by(abbreviation, publication_year) %&gt;%\n  summarise(article_count = n())\n\nglimpse(article_counts)\n\nRows: 76\nColumns: 3\nGroups: abbreviation [4]\n$ abbreviation     &lt;chr&gt; \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC…\n$ publication_year &lt;dbl&gt; 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013,…\n$ article_count    &lt;int&gt; 15, 13, 15, 16, 14, 16, 17, 14, 17, 15, 17, 14, 15, 1…\n\nCodehead(article_counts)\n\n# A tibble: 6 × 3\n# Groups:   abbreviation [1]\n  abbreviation publication_year article_count\n  &lt;chr&gt;                   &lt;dbl&gt;         &lt;int&gt;\n1 JBTC                     2005            15\n2 JBTC                     2006            13\n3 JBTC                     2007            15\n4 JBTC                     2008            16\n5 JBTC                     2009            14\n6 JBTC                     2010            16\n\nCodetail(article_counts)\n\n# A tibble: 6 × 3\n# Groups:   abbreviation [1]\n  abbreviation publication_year article_count\n  &lt;chr&gt;                   &lt;dbl&gt;         &lt;int&gt;\n1 WC                       2018            16\n2 WC                       2019            18\n3 WC                       2020            16\n4 WC                       2021            17\n5 WC                       2022            24\n6 WC                       2023            30\n\n\nNow we can create the plot.\n\nCodeline &lt;- ggplot(article_counts, aes(x = publication_year, y = article_count, color = abbreviation))+\n  geom_line() +\n  geom_point() +\n  labs(title = \"Number of Articles Published Each Year by Journal\",\n       x = \"Publication Year\",\n       y = \"Number of Articles\") +\n  theme_tufte()+\n  scale_color_discrete(name = \"Journal\") # change the label name of the color variable\n\nline\n\n\n\n\nSave a plot\n\nCodehelp(ggsave)\nggsave(\"plots/full_data_line_plot.png\", \n       plot = line, \n       width = 8, \n       height = 6, \n       dpi = 300,\n       bg = \"white\")\n\n\nSave out data\n\nCode# save as csv\n\nwrite_csv(full_data, \"data_out/full_data.csv\")\n\n\nsave(full_data, file = \"data_out/full_data.RData\")"
  },
  {
    "objectID": "demos/week02/wk02_wos_journals.html",
    "href": "demos/week02/wk02_wos_journals.html",
    "title": "Wk 02: Exploring TC journals (pt 1)",
    "section": "",
    "text": "Our source data is split between two CSV files, one for the journal “Technical Communication Quarterly” and one for “Technical Communication.”\n\nCode# install and load packages\n\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\nlibrary(readr)\n\n# read in both csv files\ntcq_data_raw &lt;- read_csv(\"data/tcq_wos_data.csv\")\ntc_data_raw &lt;- read_csv(\"data/tc_wos_data.csv\")"
  },
  {
    "objectID": "demos/week02/wk02_wos_journals.html#install-packages-and-read-in-data",
    "href": "demos/week02/wk02_wos_journals.html#install-packages-and-read-in-data",
    "title": "Wk 02: Exploring TC journals (pt 1)",
    "section": "",
    "text": "Our source data is split between two CSV files, one for the journal “Technical Communication Quarterly” and one for “Technical Communication.”\n\nCode# install and load packages\n\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\nlibrary(readr)\n\n# read in both csv files\ntcq_data_raw &lt;- read_csv(\"data/tcq_wos_data.csv\")\ntc_data_raw &lt;- read_csv(\"data/tc_wos_data.csv\")"
  },
  {
    "objectID": "demos/week02/wk02_wos_journals.html#data-preparation",
    "href": "demos/week02/wk02_wos_journals.html#data-preparation",
    "title": "Wk 02: Exploring TC journals (pt 1)",
    "section": "Data preparation",
    "text": "Data preparation\nLet’s take a quick look at the data and clean up any issues. Some questions we might answer:\n\nHow many rows and columns are in each dataset?\nWhat do the rows and columns correspond to?\n\n\nCode# shows dimensions (number of rows and columns)\ndim(tcq_data_raw) \n\n[1] 582  22\n\nCodedim(tc_data_raw)\n\n[1] 332  69\n\nCodeglimpse(tcq_data_raw)\n\nRows: 582\nColumns: 22\n$ `Publication Type`           &lt;chr&gt; \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"…\n$ Authors                      &lt;chr&gt; \"Fuglsby, BJ; Veeramoothoo, S\", \"Frost, E…\n$ `Author Full Names`          &lt;chr&gt; \"Fuglsby, Brandi J.; Veeramoothoo, Saveen…\n$ `Article Title`              &lt;chr&gt; \"Regulating Emotions for Social Action: E…\n$ `Source Title`               &lt;chr&gt; \"TECHNICAL COMMUNICATION QUARTERLY\", \"TEC…\n$ `Document Type`              &lt;chr&gt; \"Article\", \"Article\", \"Article\", \"Article…\n$ Abstract                     &lt;chr&gt; \"This article describes students' emotion…\n$ `Cited References`           &lt;chr&gt; \"Agboka Godwin Y., 2018, CITIZENSHIP ADVO…\n$ `Cited Reference Count`      &lt;dbl&gt; 32, 86, 54, 28, 66, 22, 27, 38, 5, 20, 50…\n$ `Times Cited, WoS Core`      &lt;dbl&gt; 0, 0, 1, 7, 7, 10, 11, 8, 0, 0, 8, 0, 9, …\n$ `Times Cited, All Databases` &lt;dbl&gt; 0, 0, 1, 7, 7, 10, 11, 8, 0, 0, 8, 0, 9, …\n$ `Publication Date`           &lt;chr&gt; \"JAN 2\", NA, NA, NA, NA, NA, NA, NA, NA, …\n$ `Publication Year`           &lt;dbl&gt; 2023, 2021, 2020, 2015, 2014, 2013, 2010,…\n$ Volume                       &lt;dbl&gt; 32, 30, 29, 24, 23, 22, 19, 18, 14, 29, 2…\n$ Issue                        &lt;dbl&gt; 1, 1, 2, 3, 3, 2, 3, 2, 1, 2, 4, 4, 1, 4,…\n$ `Start Page`                 &lt;chr&gt; \"98\", \"48\", \"136\", \"217\", \"184\", \"172\", \"…\n$ `End Page`                   &lt;chr&gt; \"113\", \"62\", \"154\", \"234\", \"206\", \"190\", …\n$ `Article Number`             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ DOI                          &lt;chr&gt; \"10.1080/10572252.2022.2079725\", \"10.1080…\n$ `DOI Link`                   &lt;chr&gt; \"http://dx.doi.org/10.1080/10572252.2022.…\n$ `Early Access Date`          &lt;chr&gt; \"JUN 2022\", NA, NA, NA, NA, NA, NA, NA, N…\n$ `Web of Science Record`      &lt;chr&gt; \"View Full Record in Web of Science\", \"Vi…\n\nCodeglimpse(tc_data_raw)\n\nRows: 332\nColumns: 69\n$ `Publication Type`           &lt;chr&gt; \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"…\n$ Authors                      &lt;chr&gt; \"Britt, BC; Britt, RK\", \"Davis, C\", \"Colt…\n$ `Author Full Names`          &lt;chr&gt; \"Britt, Brian C.; Britt, Rebecca K.\", \"Da…\n$ `Book Author Full Names`     &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Group Authors`              &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Article Title`              &lt;chr&gt; \"The Roles of Medium and Narrative Believ…\n$ `Source Title`               &lt;chr&gt; \"TECHNICAL COMMUNICATION\", \"TECHNICAL COM…\n$ `Book Series Title`          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Book Series Subtitle`       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Language                     &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Document Type`              &lt;chr&gt; \"Article\", \"Article\", \"Article\", \"Article…\n$ `Conference Title`           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Conference Date`            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Conference Location`        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Conference Sponsor`         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Conference Host`            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Author Keywords`            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Keywords Plus`              &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Abstract                     &lt;chr&gt; \"Purpose: This study investigates the rol…\n$ Addresses                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Affiliations                 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Reprint Addresses`          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Email Addresses`            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Researcher Ids`             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ORCIDs                       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Funding Orgs`               &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Funding Name Preferred`     &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Funding Text`               &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Cited References`           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Cited Reference Count`      &lt;dbl&gt; 82, 24, 73, 46, 30, 28, 12, 20, 27, 24, 7…\n$ `Times Cited, WoS Core`      &lt;dbl&gt; 1, 0, 4, 10, 4, 11, 0, 2, 19, 3, 3, 3, 0,…\n$ `Times Cited, All Databases` &lt;dbl&gt; 1, 0, 4, 10, 4, 11, 0, 2, 19, 3, 3, 3, 0,…\n$ `180 Day Usage Count`        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Since 2013 Usage Count`     &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Publisher                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Publisher City`             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Publisher Address`          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ISSN                         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ eISSN                        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ISBN                         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Journal Abbreviation`       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Journal ISO Abbreviation`   &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Publication Date`           &lt;chr&gt; \"AUG\", \"AUG\", \"FEB\", \"AUG\", \"NOV\", \"FEB\",…\n$ `Publication Year`           &lt;dbl&gt; 2021, 2019, 2019, 2018, 2014, 2012, 2011,…\n$ Volume                       &lt;dbl&gt; 68, 66, 66, 65, 61, 59, 58, 54, 54, 54, 6…\n$ Issue                        &lt;dbl&gt; 3, 3, 1, 3, 4, 1, 4, 4, 3, 1, 4, 3, 3, 1,…\n$ `Part Number`                &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Supplement                   &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Special Issue`              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Meeting Abstract`           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Start Page`                 &lt;chr&gt; \"76\", \"272\", \"53\", \"293\", \"215\", \"1\", \"11…\n$ `End Page`                   &lt;chr&gt; \"96\", \"283\", \"67\", \"308\", \"231\", \"7\", \"13…\n$ `Article Number`             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ DOI                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `DOI Link`                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Book DOI`                   &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Early Access Date`          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Number of Pages`            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `WoS Categories`             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Web of Science Index`       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Research Areas`             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `IDS Number`                 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Pubmed Id`                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Open Access Designations`   &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Highly Cited Status`        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Hot Paper Status`           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Date of Export`             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `UT (Unique WOS ID)`         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Web of Science Record`      &lt;chr&gt; \"View Full Record in Web of Science\", \"Vi…\n\n\nCleaning names\nWe’ll start by cleaning up the names with the janitor package. The convention is lowercase and joined by underscores.\n\nCode#install.packages(\"janitor\")\nlibrary(janitor)\n\n# use help(\"library_name\") for a description\nhelp(\"janitor\") \n\n\n# Syntax method 1 (on TCQ)\ntcq_data_raw &lt;- clean_names(tcq_data_raw)\n\nglimpse(tcq_data_raw)\n\nRows: 582\nColumns: 22\n$ publication_type          &lt;chr&gt; \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\",…\n$ authors                   &lt;chr&gt; \"Fuglsby, BJ; Veeramoothoo, S\", \"Frost, EA\",…\n$ author_full_names         &lt;chr&gt; \"Fuglsby, Brandi J.; Veeramoothoo, Saveena (…\n$ article_title             &lt;chr&gt; \"Regulating Emotions for Social Action: Emot…\n$ source_title              &lt;chr&gt; \"TECHNICAL COMMUNICATION QUARTERLY\", \"TECHNI…\n$ document_type             &lt;chr&gt; \"Article\", \"Article\", \"Article\", \"Article\", …\n$ abstract                  &lt;chr&gt; \"This article describes students' emotional …\n$ cited_references          &lt;chr&gt; \"Agboka Godwin Y., 2018, CITIZENSHIP ADVOCAC…\n$ cited_reference_count     &lt;dbl&gt; 32, 86, 54, 28, 66, 22, 27, 38, 5, 20, 50, 4…\n$ times_cited_wo_s_core     &lt;dbl&gt; 0, 0, 1, 7, 7, 10, 11, 8, 0, 0, 8, 0, 9, 0, …\n$ times_cited_all_databases &lt;dbl&gt; 0, 0, 1, 7, 7, 10, 11, 8, 0, 0, 8, 0, 9, 0, …\n$ publication_date          &lt;chr&gt; \"JAN 2\", NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ publication_year          &lt;dbl&gt; 2023, 2021, 2020, 2015, 2014, 2013, 2010, 20…\n$ volume                    &lt;dbl&gt; 32, 30, 29, 24, 23, 22, 19, 18, 14, 29, 28, …\n$ issue                     &lt;dbl&gt; 1, 1, 2, 3, 3, 2, 3, 2, 1, 2, 4, 4, 1, 4, 2,…\n$ start_page                &lt;chr&gt; \"98\", \"48\", \"136\", \"217\", \"184\", \"172\", \"300…\n$ end_page                  &lt;chr&gt; \"113\", \"62\", \"154\", \"234\", \"206\", \"190\", \"31…\n$ article_number            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ doi                       &lt;chr&gt; \"10.1080/10572252.2022.2079725\", \"10.1080/10…\n$ doi_link                  &lt;chr&gt; \"http://dx.doi.org/10.1080/10572252.2022.207…\n$ early_access_date         &lt;chr&gt; \"JUN 2022\", NA, NA, NA, NA, NA, NA, NA, NA, …\n$ web_of_science_record     &lt;chr&gt; \"View Full Record in Web of Science\", \"View …\n\nCode# Syntax method 2 (on TC)\ntc_data_raw &lt;- tc_data_raw %&gt;%\n  clean_names()\n\nglimpse(tc_data_raw)\n\nRows: 332\nColumns: 69\n$ publication_type          &lt;chr&gt; \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\",…\n$ authors                   &lt;chr&gt; \"Britt, BC; Britt, RK\", \"Davis, C\", \"Colton,…\n$ author_full_names         &lt;chr&gt; \"Britt, Brian C.; Britt, Rebecca K.\", \"Davis…\n$ book_author_full_names    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ group_authors             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ article_title             &lt;chr&gt; \"The Roles of Medium and Narrative Believabi…\n$ source_title              &lt;chr&gt; \"TECHNICAL COMMUNICATION\", \"TECHNICAL COMMUN…\n$ book_series_title         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ book_series_subtitle      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ language                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ document_type             &lt;chr&gt; \"Article\", \"Article\", \"Article\", \"Article\", …\n$ conference_title          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ conference_date           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ conference_location       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ conference_sponsor        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ conference_host           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ author_keywords           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ keywords_plus             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ abstract                  &lt;chr&gt; \"Purpose: This study investigates the role o…\n$ addresses                 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ affiliations              &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ reprint_addresses         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ email_addresses           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ researcher_ids            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ orci_ds                   &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ funding_orgs              &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ funding_name_preferred    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ funding_text              &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ cited_references          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ cited_reference_count     &lt;dbl&gt; 82, 24, 73, 46, 30, 28, 12, 20, 27, 24, 72, …\n$ times_cited_wo_s_core     &lt;dbl&gt; 1, 0, 4, 10, 4, 11, 0, 2, 19, 3, 3, 3, 0, 4,…\n$ times_cited_all_databases &lt;dbl&gt; 1, 0, 4, 10, 4, 11, 0, 2, 19, 3, 3, 3, 0, 4,…\n$ x180_day_usage_count      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ since_2013_usage_count    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ publisher                 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ publisher_city            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ publisher_address         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ issn                      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ e_issn                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ isbn                      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ journal_abbreviation      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ journal_iso_abbreviation  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ publication_date          &lt;chr&gt; \"AUG\", \"AUG\", \"FEB\", \"AUG\", \"NOV\", \"FEB\", \"N…\n$ publication_year          &lt;dbl&gt; 2021, 2019, 2019, 2018, 2014, 2012, 2011, 20…\n$ volume                    &lt;dbl&gt; 68, 66, 66, 65, 61, 59, 58, 54, 54, 54, 68, …\n$ issue                     &lt;dbl&gt; 3, 3, 1, 3, 4, 1, 4, 4, 3, 1, 4, 3, 3, 1, 2,…\n$ part_number               &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ supplement                &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ special_issue             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ meeting_abstract          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ start_page                &lt;chr&gt; \"76\", \"272\", \"53\", \"293\", \"215\", \"1\", \"11\", …\n$ end_page                  &lt;chr&gt; \"96\", \"283\", \"67\", \"308\", \"231\", \"7\", \"13\", …\n$ article_number            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ doi                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ doi_link                  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ book_doi                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ early_access_date         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ number_of_pages           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ wo_s_categories           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ web_of_science_index      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ research_areas            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ids_number                &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ pubmed_id                 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ open_access_designations  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ highly_cited_status       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ hot_paper_status          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ date_of_export            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ut_unique_wos_id          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ web_of_science_record     &lt;chr&gt; \"View Full Record in Web of Science\", \"View …\n\n\nSelect columns of interest\nNow we’ll use a function from a library called dplyr to retain only the columns we want. Let’s keep:\n\nauthor_full_names\narticle_title\nsource_title\nabstract\ncited_references\ncited_reference_count\npublication_year\npublication_type\n\nFirst on TCQ\n\nCodelibrary(dplyr)\n\n# the select function from dplyr on TCQ data\ntcq_clean &lt;- tcq_data_raw %&gt;%\n  select(author_full_names,\n         article_title,\n         source_title,\n         abstract,\n         cited_references,\n         cited_reference_count,\n         publication_year,\n         publication_type)\n\nglimpse(tcq_clean)\n\nRows: 582\nColumns: 8\n$ author_full_names     &lt;chr&gt; \"Fuglsby, Brandi J.; Veeramoothoo, Saveena (Chak…\n$ article_title         &lt;chr&gt; \"Regulating Emotions for Social Action: Emotiona…\n$ source_title          &lt;chr&gt; \"TECHNICAL COMMUNICATION QUARTERLY\", \"TECHNICAL …\n$ abstract              &lt;chr&gt; \"This article describes students' emotional inte…\n$ cited_references      &lt;chr&gt; \"Agboka Godwin Y., 2018, CITIZENSHIP ADVOCACY; […\n$ cited_reference_count &lt;dbl&gt; 32, 86, 54, 28, 66, 22, 27, 38, 5, 20, 50, 4, 55…\n$ publication_year      &lt;dbl&gt; 2023, 2021, 2020, 2015, 2014, 2013, 2010, 2009, …\n$ publication_type      &lt;chr&gt; \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\"…\n\n\nNow on TC\n\nCode# the select function from dplyr on TCQ data\ntc_clean &lt;- tc_data_raw %&gt;%\n  select(author_full_names,\n         article_title,\n         source_title,\n         abstract,\n         cited_references,\n         cited_reference_count,\n         publication_year,\n         publication_type)\n\nglimpse(tc_clean)\n\nRows: 332\nColumns: 8\n$ author_full_names     &lt;chr&gt; \"Britt, Brian C.; Britt, Rebecca K.\", \"Davis, Ca…\n$ article_title         &lt;chr&gt; \"The Roles of Medium and Narrative Believability…\n$ source_title          &lt;chr&gt; \"TECHNICAL COMMUNICATION\", \"TECHNICAL COMMUNICAT…\n$ abstract              &lt;chr&gt; \"Purpose: This study investigates the role of ne…\n$ cited_references      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ cited_reference_count &lt;dbl&gt; 82, 24, 73, 46, 30, 28, 12, 20, 27, 24, 72, 34, …\n$ publication_year      &lt;dbl&gt; 2021, 2019, 2019, 2018, 2014, 2012, 2011, 2007, …\n$ publication_type      &lt;chr&gt; \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\"…\n\n\nCombine the two sets\n\nCodeboth_data &lt;- rbind(tcq_clean, tc_clean)\n\ndim(both_data)\n\n[1] 914   8"
  },
  {
    "objectID": "demos/week02/wk02_wos_journals.html#exploring-the-data",
    "href": "demos/week02/wk02_wos_journals.html#exploring-the-data",
    "title": "Wk 02: Exploring TC journals (pt 1)",
    "section": "Exploring the data",
    "text": "Exploring the data\nSome quick ways to examine at a high level\n\nCode# provides overview of numeric variables\nsummary(both_data) \n\n author_full_names  article_title      source_title         abstract        \n Length:914         Length:914         Length:914         Length:914        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n cited_references   cited_reference_count publication_year publication_type  \n Length:914         Min.   :  0.00        Min.   :2005     Length:914        \n Class :character   1st Qu.: 18.00        1st Qu.:2008     Class :character  \n Mode  :character   Median : 34.00        Median :2014     Mode  :character  \n                    Mean   : 35.59        Mean   :2014                       \n                    3rd Qu.: 51.00        3rd Qu.:2019                       \n                    Max.   :169.00        Max.   :2023                       \n\nCode# overview of target column\nsummary(both_data$publication_year)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2005    2008    2014    2014    2019    2023 \n\nCode# for each column, shows data types and first few observations\nstr(both_data) \n\ntibble [914 × 8] (S3: tbl_df/tbl/data.frame)\n $ author_full_names    : chr [1:914] \"Fuglsby, Brandi J.; Veeramoothoo, Saveena (Chakrika)\" \"Frost, Erin A.\" \"Weber, Ryan\" \"Kreuter, Nate\" ...\n $ article_title        : chr [1:914] \"Regulating Emotions for Social Action: Emotional Intelligence's Role in TPC\" \"Ultrasound, Gender, and Consent: An Apparent Feminist Analysis of Medical Imaging Rhetorics\" \"The News from Mars\" \"The US Intelligence Community's Mathematical Ideology of Technical Communication\" ...\n $ source_title         : chr [1:914] \"TECHNICAL COMMUNICATION QUARTERLY\" \"TECHNICAL COMMUNICATION QUARTERLY\" \"TECHNICAL COMMUNICATION QUARTERLY\" \"TECHNICAL COMMUNICATION QUARTERLY\" ...\n $ abstract             : chr [1:914] \"This article describes students' emotional intelligence (EI) development when participating in the Trans-Atlant\"| __truncated__ \"This article uses an apparent feminist approach to engage a two-part research question: First, does gender affe\"| __truncated__ \"Bruno Latour advocates for portrayals of science in the making but does not explain how the public can access t\"| __truncated__ \"Reading historical intelligence community documents primarily through the lens of Kenneth Burke's essay ''Seman\"| __truncated__ ...\n $ cited_references     : chr [1:914] \"Agboka Godwin Y., 2018, CITIZENSHIP ADVOCACY; [Anonymous], 2007, SOCIAL JUSTICE THEOR; [Anonymous], 2020, T ATL\"| __truncated__ \"American Cancer Society, 2019, REC PROST CANC EARL; American College of Obstetricians and Gynecologists, 2019, \"| __truncated__ \"[Anonymous], 2007, J TECH WRIT COMMUN, DOI DOI 10.2190/TW.37.3.C; [Anonymous], 2001, WHAT SHOULD WE TEACH; [Ano\"| __truncated__ \"[Anonymous], 2005, REP PRES US; Barnard I, 2010, COLL COMPOS COMMUN, V61, P434; Best J., 2001, DAMNED LIES STAT\"| __truncated__ ...\n $ cited_reference_count: num [1:914] 32 86 54 28 66 22 27 38 5 20 ...\n $ publication_year     : num [1:914] 2023 2021 2020 2015 2014 ...\n $ publication_type     : chr [1:914] \"J\" \"J\" \"J\" \"J\" ...\n\nCode# shows first few rows\nhead(both_data)\n\n# A tibble: 6 × 8\n  author_full_names         article_title source_title abstract cited_references\n  &lt;chr&gt;                     &lt;chr&gt;         &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;           \n1 Fuglsby, Brandi J.; Veer… Regulating E… TECHNICAL C… This ar… Agboka Godwin Y…\n2 Frost, Erin A.            Ultrasound, … TECHNICAL C… This ar… American Cancer…\n3 Weber, Ryan               The News fro… TECHNICAL C… Bruno L… [Anonymous], 20…\n4 Kreuter, Nate             The US Intel… TECHNICAL C… Reading… [Anonymous], 20…\n5 Buehl, Jonathan           Toward an Et… TECHNICAL C… Over th… ANDERSON C, 199…\n6 Lauer, Claire             Examining th… TECHNICAL C… This ar… [Anonymous], SE…\n# ℹ 3 more variables: cited_reference_count &lt;dbl&gt;, publication_year &lt;dbl&gt;,\n#   publication_type &lt;chr&gt;\n\nCode# shows the first n rows\n\nhead(both_data, n = 10)\n\n# A tibble: 10 × 8\n   author_full_names        article_title source_title abstract cited_references\n   &lt;chr&gt;                    &lt;chr&gt;         &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;           \n 1 Fuglsby, Brandi J.; Vee… Regulating E… TECHNICAL C… This ar… Agboka Godwin Y…\n 2 Frost, Erin A.           Ultrasound, … TECHNICAL C… This ar… American Cancer…\n 3 Weber, Ryan              The News fro… TECHNICAL C… Bruno L… [Anonymous], 20…\n 4 Kreuter, Nate            The US Intel… TECHNICAL C… Reading… [Anonymous], 20…\n 5 Buehl, Jonathan          Toward an Et… TECHNICAL C… Over th… ANDERSON C, 199…\n 6 Lauer, Claire            Examining th… TECHNICAL C… This ar… [Anonymous], SE…\n 7 Ding, Huiling            Technical Co… TECHNICAL C… In this… [Anonymous], 20…\n 8 Kynell, Teresa; Tebeaux… The Associat… TECHNICAL C… This ar… Anderson P., 19…\n 9 Kitalong, Karla Saari    Working with… TECHNICAL C… &lt;NA&gt;     ALLEN N, 2002, …\n10 Pihlaja, Beau            Rhetoric, Te… TECHNICAL C… &lt;NA&gt;     Agboka Godwin, …\n# ℹ 3 more variables: cited_reference_count &lt;dbl&gt;, publication_year &lt;dbl&gt;,\n#   publication_type &lt;chr&gt;\n\nCode#shows last few rows\ntail(both_data)\n\n# A tibble: 6 × 8\n  author_full_names         article_title source_title abstract cited_references\n  &lt;chr&gt;                     &lt;chr&gt;         &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;           \n1 Wagner, Christian; Schro… Capabilities… TECHNICAL C… Purpose… &lt;NA&gt;            \n2 Lentz, Leo; De Jong, Men… How Do Exper… TECHNICAL C… Discuss… &lt;NA&gt;            \n3 Rife, Martine Courant     Technical co… TECHNICAL C… Maintai… &lt;NA&gt;            \n4 Mott, Richard K.; Ford, … The converge… TECHNICAL C… States … &lt;NA&gt;            \n5 Thrush, Emily A.; Hooper… Industry and… TECHNICAL C… Details… &lt;NA&gt;            \n6 Theofanos, MF; Redish, J  Helping low-… TECHNICAL C… This is… &lt;NA&gt;            \n# ℹ 3 more variables: cited_reference_count &lt;dbl&gt;, publication_year &lt;dbl&gt;,\n#   publication_type &lt;chr&gt;\n\nCode# creates a frequency table for a categorical variable \ntable(both_data$publication_year) \n\n\n2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 \n  68   53   69   49   42   39   27   42   34   35   41   41   48   52   60   58 \n2021 2022 2023 \n  56   53   47 \n\n\nVisualize\nLet’s create some exploratory visualizations.\nVisualize the articles published by year\n\nCode# count of articles by year\nggplot(both_data, aes(x = publication_year)) +\n  geom_bar() +\n  labs(title = \"Articles per Year in TC and TCQ\",\n       X = \"Publication Year\",\n       Y = \"Number of Articles\") +\n  theme_light()\n\n\n\n\nAdd another variable to the display\n\nCode# count of articles by year, by journal\nggplot(both_data, aes(x = publication_year, fill = source_title)) +\n  geom_bar() +\n  labs(title = \"Articles per Year in TC and TCQ\",\n       X = \"Publication Year\",\n       Y = \"Number of Articles\") +\n  theme_light()\n\n\n\n\nCreate two displays using facet wrap\n\nCode# count of articles by year, by journal\nggplot(both_data, aes(x = publication_year)) +\n  geom_bar() +\n  labs(title = \"Articles per Year in TC and TCQ\",\n       X = \"Publication Year\",\n       Y = \"Number of Articles\") +\n   facet_wrap(~ source_title, ncol = 2) # Change ncol as needed\n\n\n\n\nSpice things up with a theme from ggthemes\nCheck out this ggthemes gallery\n\nCode#install.packages(\"ggthemes\")\nlibrary(ggthemes)\n\n# count of articles by year, by journal\nggplot(both_data, aes(x = publication_year)) +\n  geom_bar() +\n  labs(title = \"Articles per Year in TC and TCQ\",\n       X = \"Publication Year\",\n       Y = \"Number of Articles\") +\n   facet_wrap(~ source_title, ncol = 1) +\n  theme_economist()\n\n\n\n\n\nCode# count of articles by year, by journal\nyear_plot &lt;- ggplot(both_data, aes(x = publication_year)) +\n  geom_bar() +\n  labs(title = \"Articles per Year in TC and TCQ\",\n       X = \"Publication Year\",\n       Y = \"Number of Articles\") +\n   facet_wrap(~ source_title, ncol = 1) +\n  theme_economist_white()\n\nyear_plot\n\n\n\n\nAdd labels above the bars\n\nCode# add labels above the bars\nyear_plot &lt;- year_plot +\n  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5, size = 4)\n\nyear_plot\n\n\n\n\nSave the chart\n\nCodehelp(ggsave)\nggsave(\"plots/articles_barplot.png\", \n       plot = year_plot, \n       width = 8, \n       height = 6, \n       dpi = 300,\n       bg = NULL)\n\n\nSave our dataset\n\nCode# save as csv\n\nwrite.csv(both_data, \"data_out/both_data.csv\")\n\nsave(both_data, file = \"data_out/both_data.RData\")"
  },
  {
    "objectID": "demos/week02/wk02_wos_journals.html#what-about-other-journals",
    "href": "demos/week02/wk02_wos_journals.html#what-about-other-journals",
    "title": "Wk 02: Exploring TC journals (pt 1)",
    "section": "What about other journals?",
    "text": "What about other journals?\nGather and add to our visuals all articles published after 2005 from Web of Science in these journals:\n\nJournal of Business and Technical Communication\nWritten Communication"
  },
  {
    "objectID": "demos/week03/wk03_text_analysis.html",
    "href": "demos/week03/wk03_text_analysis.html",
    "title": "Wk 03: Exploring TC journals, (pt 3)",
    "section": "",
    "text": "We start with data from four journals"
  },
  {
    "objectID": "demos/week03/wk03_text_analysis.html#overview",
    "href": "demos/week03/wk03_text_analysis.html#overview",
    "title": "Wk 03: Exploring TC journals, (pt 3)",
    "section": "",
    "text": "We start with data from four journals"
  },
  {
    "objectID": "demos/week03/wk03_text_analysis.html#load-libraries-and-data",
    "href": "demos/week03/wk03_text_analysis.html#load-libraries-and-data",
    "title": "Wk 03: Exploring TC journals, (pt 3)",
    "section": "Load libraries and data",
    "text": "Load libraries and data\nFor this analysis, we’ll be using the R package Quanteda: Quantitative Analysis of Textual Data.\n\nCodelibrary(tidyverse)\n\n\n#install.packages(\"Rtools\") # you may need to install Rtools to install all the quanteda packages\n\n#install.packages(\"remotes\")\n\n#install.packages(\"quanteda\")\n#install.packages(\"readtext\")\n#install.packages(\"spacyr\")\n#install.packages(\"quanteda.textmodels\")\n#install.packages(\"quanteda.textstats\")\n#install.packages(\"quanteda.textplots\")\n#remotes::install_github(\"kbenoit/quanteda.dictionaries\")\n\nlibrary(quanteda)\nlibrary(quanteda.dictionaries)\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\nlibrary(quanteda.textstats)"
  },
  {
    "objectID": "demos/week03/wk03_text_analysis.html#load-data",
    "href": "demos/week03/wk03_text_analysis.html#load-data",
    "title": "Wk 03: Exploring TC journals, (pt 3)",
    "section": "Load data",
    "text": "Load data\n\nCode#install.packages(\"here\")\nlibrary(here)\n\n# Use \"here\" to set the working directory \nhere::here()\n\n[1] \"/Users/dcard/Documents/GitHub/computational rhetorics/demo_docs\"\n\nCodegetwd()\n\n[1] \"/Users/dcard/Documents/GitHub/computational rhetorics/demo_docs/demos/week03\"\n\nCode# Use \"here\" to define the relative path to your data\ndata_file &lt;- here(\"demos/week03/data_out/full_data.RData\")\n\nload(data_file)\n\nglimpse(full_data)\n\nRows: 1,537\nColumns: 9\n$ source_title          &lt;chr&gt; \"JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION…\n$ author_full_names     &lt;chr&gt; \"Wickman, Chad\", \"DeJeu, Emily Barrow\", \"DeVasto…\n$ article_title         &lt;chr&gt; \"Genre and Metagenre in Biomedical Research Writ…\n$ abstract              &lt;chr&gt; \"The use of reporting guidelines is an establish…\n$ cited_references      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ cited_reference_count &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ publication_year      &lt;dbl&gt; 2023, 2022, 2016, 2009, 2009, 2020, 2016, 2012, …\n$ publication_type      &lt;chr&gt; \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\", \"J\"…\n$ abbreviation          &lt;chr&gt; \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", …"
  },
  {
    "objectID": "demos/week03/wk03_text_analysis.html#creating-a-corpus-object",
    "href": "demos/week03/wk03_text_analysis.html#creating-a-corpus-object",
    "title": "Wk 03: Exploring TC journals, (pt 3)",
    "section": "Creating a Corpus object",
    "text": "Creating a Corpus object\nA Quanteda Corpus is a special form of a character vector that includes metadata about the corpus and the “documents” within the corpus. In this case, our corpus includes all the articles results in our CSV and each article is a document.\nCreate a “text” column for analysis\n\nCode# Creates a new column in full_data from the title and abstract (separated by a tilde)\nfull_data$text &lt;- paste(full_data$article_title, full_data$abstract, sep = \" ~ \")\n\n\n# check the column\nfull_data$text[2:3]\n\n[1] \"The Ethics of Delivering Bad News: Evaluating Impression Management Strategies in Corporate Financial Reporting ~ Business communication textbooks offer impression management (IM) strategies to help students learn how to soften bad news. But corporations sometimes use these strategies in ethically questionable ways. This article analyzes IM strategies in a landmark case of ethically dubious corporate financial reporting. Findings suggest that the company, Ivax, manipulated three standard IM strategies by overamplifying its power to fix a financial crisis, substantially downplaying bad news, and concealing damaging information. Ivax also used a fourth, less familiar strategy: It buried contradictory information in legal disclaimers. Instructors need to help students become ethical writers who avoid questionable IM strategies like these.\"                                                                                     \n[2] \"Stasis and Matters of Concern: The Conviction of the L'Aquila Seven ~ On October 22, 2012, six scientists and one civil servant were convicted of manslaughter for failing to properly warn the people of L'Aquila, Italy, of an impending earthquake that resulted in over 300 deaths and 1,500 injuries. This article investigates a key event leading up to this conviction: An emergency meeting of scientists, civil servants, and politicians to determine whether or not an advanced warning should be issued to the residents of L'Aquila. The following investigation of this emergency meeting uses functional stasis analysis to identify the primary breakdown in deliberation that ultimately led to a message of calm and reassurance immediately prior to the devastating earthquake. The results provide insights into not only the events in L'Aquila but also broader issues of risk, uncertainty, fact, and value in science-policy deliberation.\"\n\n\nCreate the corpus\n\nCode# creates the corpus object\ncorp &lt;- corpus(full_data)\n\n# summary of the corpus (including metadata for the texts)\nsummary(corp, n = 3)\n\nCorpus consisting of 1537 documents, showing 3 documents:\n\n  Text Types Tokens Sentences                                    source_title\n text1    97    149         4 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\n text2    94    130         6 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\n text3   102    158         4 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\n                                       author_full_names\n                                           Wickman, Chad\n                                     DeJeu, Emily Barrow\n DeVasto, Danielle; Graham, S. Scott; Zamparutti, Louise\n                                                                                                   article_title\n                                                              Genre and Metagenre in Biomedical Research Writing\n The Ethics of Delivering Bad News: Evaluating Impression Management Strategies in Corporate Financial Reporting\n                                             Stasis and Matters of Concern: The Conviction of the L'Aquila Seven\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    abstract\n The use of reporting guidelines is an established yet still-evolving practice in the field of biomedicine. These documents are often linked to common methodologies (e.g., randomized clinical trials); they include multiple textual artifacts (e.g., checklists, flow diagrams) and have a history that is coextensive with the emergence and ongoing development of evidence-based medicine (e.g., as an epistemological orientation to research and decision making). Drawing on the concept of metagenre, this article examines how practitioners use reporting guidelines to define and regulate the boundaries of biomedical research and writing activity. The analysis, focusing on one prominent set of guidelines, shows how practitioners use the genre-metagenre dynamic to promote strategic intervention while upholding traditional principles and standards for evidence-based research and communication.\n                                                                                                                                                               Business communication textbooks offer impression management (IM) strategies to help students learn how to soften bad news. But corporations sometimes use these strategies in ethically questionable ways. This article analyzes IM strategies in a landmark case of ethically dubious corporate financial reporting. Findings suggest that the company, Ivax, manipulated three standard IM strategies by overamplifying its power to fix a financial crisis, substantially downplaying bad news, and concealing damaging information. Ivax also used a fourth, less familiar strategy: It buried contradictory information in legal disclaimers. Instructors need to help students become ethical writers who avoid questionable IM strategies like these.\n                              On October 22, 2012, six scientists and one civil servant were convicted of manslaughter for failing to properly warn the people of L'Aquila, Italy, of an impending earthquake that resulted in over 300 deaths and 1,500 injuries. This article investigates a key event leading up to this conviction: An emergency meeting of scientists, civil servants, and politicians to determine whether or not an advanced warning should be issued to the residents of L'Aquila. The following investigation of this emergency meeting uses functional stasis analysis to identify the primary breakdown in deliberation that ultimately led to a message of calm and reassurance immediately prior to the devastating earthquake. The results provide insights into not only the events in L'Aquila but also broader issues of risk, uncertainty, fact, and value in science-policy deliberation.\n cited_references cited_reference_count publication_year publication_type\n             &lt;NA&gt;                    NA             2023                J\n             &lt;NA&gt;                    NA             2022                J\n             &lt;NA&gt;                    NA             2016                J\n abbreviation\n         JBTC\n         JBTC\n         JBTC\n\nCode# Prints texts\nprint(corp)\n\nCorpus consisting of 1,537 documents and 9 docvars.\ntext1 :\n\"Genre and Metagenre in Biomedical Research Writing ~ The use...\"\n\ntext2 :\n\"The Ethics of Delivering Bad News: Evaluating Impression Man...\"\n\ntext3 :\n\"Stasis and Matters of Concern: The Conviction of the L'Aquil...\"\n\ntext4 :\n\"Integrating Social Media Into Existing Work Environments The...\"\n\ntext5 :\n\"Practitioner Research Instruction A Neglected Curricular Are...\"\n\ntext6 :\n\"Legally Minded Technical Communicators: A Case Study of a Le...\"\n\n[ reached max_ndoc ... 1,531 more documents ]\n\n\nPlot descriptive statistics\nPlot metadata: tokens per text, by journal\n\nCode# get metadata\ntokeninfo &lt;- summary(corp, n = 1537)\n\n# plot\nif (require(ggplot2)) ggplot(data = tokeninfo, aes(x = publication_year, y = Tokens, group = abbreviation, color = abbreviation)) +\n  geom_point() + \n  scale_x_continuous(labels = c(seq(2005, 2023, 3)),\n    breaks = seq(2005, 2023, 3)) + \n  labs(\n  title = \"Tokens per text over time\",\n  subtitle = \"Token counts by publication year\",\n  x = \"Publication Year\",\n  y = \"Tokens Count\"\n  ) +\n  theme_bw()\n\n\n\n\nPlot metadata: sentences per text, by journal\nWe can plot sentences in the title+abstract for each article (and color-coded by journal)\n\nCode# how many unique sentence values are there?\nunique(tokeninfo$Sentences)\n\n [1]  4  6  3  5  7  1 10  2  8 15  9 11 12 14 13 17\n\nCode# plot tokeninfo \nif (require(ggplot2)) ggplot(data = tokeninfo, aes(x = publication_year, y = Sentences, group = abbreviation, color = abbreviation)) +\n  geom_point() + \n  scale_x_continuous(labels = c(seq(2005, 2023, 3)),\n    breaks = seq(2005, 2023, 3)) + \n  labs(\n  title = \"Sentences per text over time\",\n  subtitle = \"Sentence counts by publication year\",\n  x = \"Publication Year\",\n  y = \"Sentence Count\"\n  ) +\n  theme_bw()\n\n\n\n\nBut wait, where are all the JBTC articles?!\n\nCode# get a list of unique sentence lengths in JBTC title+abstracts\nunique(tokeninfo$Sentences[tokeninfo$abbreviation == \"JBTC\"])\n\n[1]  4  6  3  5  7  1 10  2  8\n\nCode# get a list of unique years among JBTC observations\nunique(tokeninfo$publication_year[tokeninfo$abbreviation == \"JBTC\"])\n\n [1] 2023 2022 2016 2009 2020 2012 2011 2010 2007 2021 2006 2014 2008 2019 2018\n[16] 2015 2005 2013 2017\n\n\nIt seems like we have JBTC articles of varying sentence length across multiple years…\nSubset a corpus\nLet’s investigate further. Use the corpus_subset function to keep only texts from JBTC.\n\nCode# corpus_subset(corp, abbreviation == \"JBTC\")\n\njbtc_tokeninfo &lt;- summary(corpus_subset(corp, abbreviation == \"JBTC\"), n = 300)\n\n\nThen visualize sentence counts again, this time for just JBTC…\n\nCodeif (require(ggplot2)) ggplot(data = jbtc_tokeninfo, aes(x = publication_year, y = Sentences)) +\n  geom_point() + \n  scale_x_continuous(labels = c(seq(2005, 2023, 3)),\n    breaks = seq(2005, 2023, 3)) + \n  labs(\n  title = \"JBTC: Sentences per text over time\",\n  subtitle = \"Sentence counts in JBTC\",\n  x = \"Publication Year\",\n  y = \"Sentence Count\"\n  ) +\n  theme_bw()\n\n\n\n\nOk, so maybe it’s just a problem with the plot?\nAdd a layer: # of observations with x sentences\n\nCode# use geom_count instead of geom_point to let size reflect the count of the points\n  \nggplot(data = jbtc_tokeninfo, aes(x = publication_year, y = Sentences)) +\n  geom_count() + \n  scale_x_continuous(labels = c(seq(2005, 2023, 3)),\n    breaks = seq(2005, 2023, 3)) + \n  labs(\n  title = \"JBTC: Sentences per text over time\",\n  subtitle = \"Sentence counts in JBTC\",\n  x = \"Publication Year\",\n  y = \"Sentence Count\"\n  ) +\n  theme_bw()\n\n\n\n\nAdd size to all journal sentence counts\n\nCodeggplot(data = tokeninfo, aes(x = publication_year, y = Sentences, group = abbreviation, color = abbreviation)) +\n  geom_count() + \n  scale_x_continuous(labels = c(seq(2005, 2023, 3)),\n    breaks = seq(2005, 2023, 3)) + \n  labs(\n  title = \"Sentences per text over time\",\n  subtitle = \"Sentence counts by publication year\",\n  x = \"Publication Year\",\n  y = \"Sentence Count\"\n  ) +\n  theme_bw()\n\n\n\n\nIt’s not perfect, but definitely better."
  },
  {
    "objectID": "demos/week03/wk03_text_analysis.html#exploring-corpus-texts",
    "href": "demos/week03/wk03_text_analysis.html#exploring-corpus-texts",
    "title": "Wk 03: Exploring TC journals, (pt 3)",
    "section": "Exploring corpus texts",
    "text": "Exploring corpus texts\nBut token and sentence counts probably aren’t the most interesting aspect of the titles and abstracts…\nKWIC: search for patterns\nWe can search for patterns in multiple ways:\n\nsingle word: kwic(data_tokens, pattern = \"usability\")\n\nstring of characters: kwic(data_tokens, pattern = \"user-*\")\n\nphrase: kwic(data_tokens, phrase(\"social justice\"))\n\n\nKWIC for “usability”\nWe can search for usability and surrounding words.\n\n\n\n\n\n\nQuanteda Tokens object\n\n\n\nTokens: Each element of a tokens object typically represents a single word or a term. However, tokens can also represent larger text units such as sentences or paragraphs, depending on the tokenization process applied.\n\n\n\nCode# create a tokens object\ndata_tokens &lt;- tokens(corp)\n\n# data, pattern, number of tokens before and after \nkwic_usability &lt;- kwic(data_tokens, pattern = \"usability\", 5) \n\n# display the first 10 matches\nkwic_usability[0:10]\n\nKeyword-in-context with 10 matches.                                                                    \n  [text16, 102]           a practical influence on the | usability |\n   [text79, 97]           and technology; the cultural | usability |\n  [text126, 94]    answered questions about the tool's | usability |\n  [text165, 42]        transparency, learnability, and | usability |\n  [text165, 96] supported by task-based documentation, | usability |\n [text168, 117]             similar contexts: content, | usability |\n  [text264, 16]             Tracking as a Component of | Usability |\n   [text273, 6]               Listening to Students: A | Usability |\n  [text273, 79]             how students use feedback. | Usability |\n [text273, 107]              . This article reports on | usability |\n                                              \n of assembly instructions. This               \n research conducted and located accountability\n and communicative effectiveness, and         \n . Looking at questions asked                 \n problems were more prominent.                \n , and overall visual appeal                  \n and Sustainability ~ Framed around           \n Evaluation of Instructor Commentary ~        \n evaluation is ideally equipped for           \n testing of commentary provided to            \n\nCode# display the last 6 matches\ntail(kwic_usability)\n\nKeyword-in-context with 6 matches.                                                                 \n  [text1158, 6]      Revising the Online Classroom: | Usability |\n [text1158, 26]               by the authors to use | usability |\n [text1158, 59]   institutions can create their own | usability |\n [text1190, 41]         format. It investigates the | usability |\n [text1190, 62]          as YouTube analytics data, | usability |\n [text1306, 70] of argument effectiveness, document | usability |\n                                         \n Testing for Training Online Technical   \n testing as a component of               \n testing protocols for formative online  \n and design-implications of a live-action\n , and comprehension assessments.        \n , and professionalism. Three            \n\nCode# chart using kableExtra (for markdown to html version)\nlibrary(kableExtra)\nhead(kwic_usability) %&gt;%\n  kbl() %&gt;%\n  kable_minimal()\n\n\n\ndocname\nfrom\nto\npre\nkeyword\npost\npattern\n\n\n\ntext16\n102\n102\na practical influence on the\nusability\nof assembly instructions . This\nusability\n\n\ntext79\n97\n97\nand technology ; the cultural\nusability\nresearch conducted and located accountability\nusability\n\n\ntext126\n94\n94\nanswered questions about the tool's\nusability\nand communicative effectiveness , and\nusability\n\n\ntext165\n42\n42\ntransparency , learnability , and\nusability\n. Looking at questions asked\nusability\n\n\ntext165\n96\n96\nsupported by task-based documentation ,\nusability\nproblems were more prominent .\nusability\n\n\ntext168\n117\n117\nsimilar contexts : content ,\nusability\n, and overall visual appeal\nusability\n\n\n\n\n\nKWIC for user-x\n\nCodekwic_userx &lt;- kwic(data_tokens, pattern = \"user-*\", 3)\n\nhead(kwic_userx)\n\nKeyword-in-context with 6 matches.                                                       \n  [text4, 129] and repurposing their | user-generated |\n  [text37, 61]    tagging to compile | user-specific  |\n [text49, 119]  emphasis on creating | user-centered  |\n [text172, 51]  well acquainted with | user-centered  |\n [text172, 73] data collected within | user-centered  |\n [text190, 33]       as interactive, | user-generated |\n                            \n data.                      \n metadata on information    \n risk information that      \n design ( UCD               \n research and instead       \n documentation and describes\n\n\nKWIC for “social justice”\n\nCode# show context of the first six occurrences of 'social justice'\nkwic(data_tokens, pattern = phrase(\"social justice\")) %&gt;%\n    head()\n\nKeyword-in-context with 6 matches.                                                                            \n  [text25, 131:132]           It encourages a response to | social justice |\n   [text103, 12:13]   Feminist Scholarship Can Inform the | Social Justice |\n   [text103, 33:34]                    do, and can inform | social justice |\n   [text103, 45:46]            communication ( TPC ) even | social justice |\n   [text103, 68:69]           that are relevant to future | social justice |\n [text103, 124:125] methodologies and theories to enhance | social justice |\n                                       \n exigencies, invites participation from\n Turn ~ This article calls             \n work in technical and professional    \n work that is not explicitly           \n work: ( a )                           \n scholarship.                          \n\n\nThe tokens object\nLet’s dig into the tokens object.\n\nCodetokens &lt;- tokens(corp)\n\ntokens[1:3]\n\nTokens consisting of 3 documents and 9 docvars.\ntext1 :\n [1] \"Genre\"      \"and\"        \"Metagenre\"  \"in\"         \"Biomedical\"\n [6] \"Research\"   \"Writing\"    \"~\"          \"The\"        \"use\"       \n[11] \"of\"         \"reporting\" \n[ ... and 137 more ]\n\ntext2 :\n [1] \"The\"        \"Ethics\"     \"of\"         \"Delivering\" \"Bad\"       \n [6] \"News\"       \":\"          \"Evaluating\" \"Impression\" \"Management\"\n[11] \"Strategies\" \"in\"        \n[ ... and 118 more ]\n\ntext3 :\n [1] \"Stasis\"     \"and\"        \"Matters\"    \"of\"         \"Concern\"   \n [6] \":\"          \"The\"        \"Conviction\" \"of\"         \"the\"       \n[11] \"L'Aquila\"   \"Seven\"     \n[ ... and 146 more ]\n\n\nNotice what counts as a token by default.\nPreprocessing\nWe may want to remove certain words or characters that aren’t salient for our analysis\nRemove punctuation, separators, and numbers\n\nCode# create a tokens object without punctuation, separators, and numbers\ntokens &lt;- tokens(corp, remove_punct = TRUE,\n                 remove_separators = TRUE,\n                 remove_numbers = TRUE)\n\n# check the result\ntokens[1:3]\n\nTokens consisting of 3 documents and 9 docvars.\ntext1 :\n [1] \"Genre\"      \"and\"        \"Metagenre\"  \"in\"         \"Biomedical\"\n [6] \"Research\"   \"Writing\"    \"~\"          \"The\"        \"use\"       \n[11] \"of\"         \"reporting\" \n[ ... and 116 more ]\n\ntext2 :\n [1] \"The\"        \"Ethics\"     \"of\"         \"Delivering\" \"Bad\"       \n [6] \"News\"       \"Evaluating\" \"Impression\" \"Management\" \"Strategies\"\n[11] \"in\"         \"Corporate\" \n[ ... and 103 more ]\n\ntext3 :\n [1] \"Stasis\"     \"and\"        \"Matters\"    \"of\"         \"Concern\"   \n [6] \"The\"        \"Conviction\" \"of\"         \"the\"        \"L'Aquila\"  \n[11] \"Seven\"      \"~\"         \n[ ... and 127 more ]\n\n\nRemove stopwords and more\n\nCode# see list of stopwords\nhead(stopwords(\"en\"), 15)\n\n [1] \"i\"          \"me\"         \"my\"         \"myself\"     \"we\"        \n [6] \"our\"        \"ours\"       \"ourselves\"  \"you\"        \"your\"      \n[11] \"yours\"      \"yourself\"   \"yourselves\" \"he\"         \"him\"       \n\nCode# remove stopwords\ntokens &lt;- tokens %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(\"~\")\n\n# check the result\ntokens[1:3]\n\nTokens consisting of 3 documents and 9 docvars.\ntext1 :\n [1] \"Genre\"          \"Metagenre\"      \"Biomedical\"     \"Research\"      \n [5] \"Writing\"        \"use\"            \"reporting\"      \"guidelines\"    \n [9] \"established\"    \"yet\"            \"still-evolving\" \"practice\"      \n[ ... and 69 more ]\n\ntext2 :\n [1] \"Ethics\"     \"Delivering\" \"Bad\"        \"News\"       \"Evaluating\"\n [6] \"Impression\" \"Management\" \"Strategies\" \"Corporate\"  \"Financial\" \n[11] \"Reporting\"  \"Business\"  \n[ ... and 76 more ]\n\ntext3 :\n [1] \"Stasis\"     \"Matters\"    \"Concern\"    \"Conviction\" \"L'Aquila\"  \n [6] \"Seven\"      \"October\"    \"six\"        \"scientists\" \"one\"       \n[11] \"civil\"      \"servant\"   \n[ ... and 67 more ]\n\n\nCreating a document-feature matrix\nQuanteda uses a data structure called a document-feature matrix:\n\nDocument: In a DFM, each row represents a document or text unit. This can be a single document, a sentence, a paragraph, or any other defined text unit. In our case, it’s a title + abstract.\nFeature: Each column represents a feature, typically a word or a term that appears in the documents. These features are usually extracted from the text through tokenization, and they can be single words or multi-word phrases.\nMatrix: The DFM is a two-dimensional matrix where the rows correspond to documents, and the columns correspond to features. The values in the matrix represent the frequency of each feature in each document, but they can also be transformed into other measures such as term frequency-inverse document frequency (TF-IDF) scores.\n\n\nCode# create the dfm\ndfm &lt;- tokens(corp, remove_punct = TRUE,\n              remove_separators = TRUE,\n              remove_numbers = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(\"~\") %&gt;%\n  dfm()\n\n# view the dfm\nprint(dfm)\n\nDocument-feature matrix of: 1,537 documents, 12,399 features (99.56% sparse) and 9 docvars.\n       features\ndocs    genre metagenre biomedical research writing use reporting guidelines\n  text1     1         2          2        4       2   3         2          3\n  text2     0         0          0        0       0   1         2          0\n  text3     0         0          0        0       0   0         0          0\n  text4     0         0          0        1       0   2         0          0\n  text5     0         0          0        7       0   0         0          0\n  text6     0         0          0        0       3   0         0          0\n       features\ndocs    established yet\n  text1           1   1\n  text2           0   0\n  text3           0   0\n  text4           0   0\n  text5           0   1\n  text6           0   0\n[ reached max_ndoc ... 1,531 more documents, reached max_nfeat ... 12,389 more features ]\n\n\n\n\n\n\n\n\nSparse matrices\n\n\n\nIn this context, “sparse” refers to a type of data structure used to efficiently work with large data. In a sparse matrix, the majority of the elements have a value of zero. If your dfm is 99.56% sparse, it means that only .04% of the entries are something other than 0.\n\n\nCreate a wordcloud\n\nCode# simple wordcloud\ntextplot_wordcloud(dfm)\n\n\n\nCode# wordcloud with parameters\nset.seed(100)\ntextplot_wordcloud(dfm, \n                   min_count = 20, # include word only if it occurs at least n times in data set \n                   random_order = FALSE, \n                   rotation = 0.25,\n    color = RColorBrewer::brewer.pal(8, \"Dark2\"))\n\n\n\n\nView top features\n\nCode# 20 most frequent words\ntopfeatures(dfm, 20)\n\n    technical communication       writing         study       article \n         1546          1475          1377           960           913 \n     students      research      analysis       results           can \n          772           751           577           485           483 \n professional           use        design    rhetorical          work \n          468           457           453           445           427 \n       social       content          data     practices         using \n          412           388           386           360           356 \n\n\nDFM: Grouping by variables\n\nCode# group the dfm by a variable (docvar): journal\ndfm_journ &lt;- dfm %&gt;%\n  dfm_group(groups = abbreviation)\n\n# sort features by frequency and then view\ndfm_sort(dfm_journ)\n\nDocument-feature matrix of: 4 documents, 12,399 features (54.05% sparse) and 3 docvars.\n      features\ndocs   technical communication writing study article students research analysis\n  JBTC       244           375     158   236     212      131      119      102\n  TC         716           508     102   225     144      127      192      157\n  TCQ        561           531     149   175     297      154      183      110\n  WC          25            61     968   324     260      360      257      208\n      features\ndocs   results can\n  JBTC      84 107\n  TC       270 193\n  TCQ       39  95\n  WC        92  88\n[ reached max_nfeat ... 12,389 more features ]\n\n\nCreate a comparison cloud\n\nCode# cloud that compares top features for each journal\ncomparison_cloud &lt;- dfm_journ %&gt;%\n  dfm_trim(min_termfreq = 25,\n           verbose = FALSE) %&gt;%\n  textplot_wordcloud(comparison = TRUE)\n\n\n\n\nIt’s common joke in computational humanities and social scientists that “colleagues don’t let colleagues make wordclouds,” but maybe this one can help us generate or refine some RQs?\nPlot relative frequencies\nQuanteda’s texstat_frequency allows to plot the most frequent words in terms of relative frequency by group\n\nCode#help(\"dfm_weight\")\n#help(\"textstat_frequency\")\n\n# calculate the proportional weight (the proportion of the feature count relative to total feature count)\ndfm_weight_journ &lt;- dfm_journ %&gt;%\n  dfm_weight(scheme = \"prop\")\n\n# Calculate relative frequency by journal\nfreq_weight &lt;- textstat_frequency(dfm_weight_journ, n = 15, \n                                  groups = dfm_weight_journ$abbreviation)\n\nggplot(data = freq_weight, aes(x = nrow(freq_weight):1, y = frequency)) +\n     geom_point() +\n     facet_wrap(~ group, scales = \"free\") +\n     coord_flip() +\n     scale_x_continuous(breaks = nrow(freq_weight):1,\n                        labels = freq_weight$feature) +\n     labs(x = NULL, \n          y = \"Relative frequency\",\n          title = \"Most frequent terms as a proportion of terms in the journal\")\n\n\n\n\nIt seems like some of these terms are parts of phrases, no?"
  },
  {
    "objectID": "demos/week03/wk03_text_analysis.html#more-hastily",
    "href": "demos/week03/wk03_text_analysis.html#more-hastily",
    "title": "Wk 03: Exploring TC journals, (pt 3)",
    "section": "More, hastily",
    "text": "More, hastily\nPlot “keyness” in TCQ and TC\nKeyness is a score for top features that occur differentially across categories or groups.\n\nCode# get info on \"keyness\"\nhelp(\"textstat_keyness\")\n\n\n# Subset initial corpus to retain TCQ and TC \ntc_v_tcq_corpus &lt;- corpus_subset(corp, \n                            abbreviation %in% c(\"TCQ\", \"TC\"))\n\n# Create a dfm grouped by journal (abbreviation)\ntc_v_tcq_dfm &lt;- tokens(tc_v_tcq_corpus, remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  tokens_remove(\"~\") %&gt;%\n  tokens_group(groups = abbreviation) %&gt;%\n  dfm()\n\n# Calculate keyness and determine TC as target group\nresult_keyness &lt;- textstat_keyness(tc_v_tcq_dfm, target = \"TC\")\n\n# Plot estimated word keyness\ntextplot_keyness(result_keyness) \n\n\n\n\nNgrams\nYou can generate n-grams from a tokens object using tokens_ngrams().\n\nCode# creating a tokens object from a corpus\ntoks &lt;- tokens(corp, remove_punct = TRUE,\n              remove_separators = TRUE,\n              remove_numbers = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(\"~\")\n\n\n# generating ngrams from a tokens object\n\ntoks_ngram &lt;- tokens_ngrams(toks, n = 2) # specify combinations, e.g. 2 and 3 word combos -&gt; (toks, n = 2:3)\n\n\n# view result: first 10 ngrams in the first article\nhead(toks_ngram[[1]], 10)\n\n [1] \"Genre_Metagenre\"        \"Metagenre_Biomedical\"   \"Biomedical_Research\"   \n [4] \"Research_Writing\"       \"Writing_use\"            \"use_reporting\"         \n [7] \"reporting_guidelines\"   \"guidelines_established\" \"established_yet\"       \n[10] \"yet_still-evolving\"    \n\nCode# view result: last 10 ngrams in the first article\ntail(toks_ngram[[1]], 10)\n\n [1] \"dynamic_promote\"          \"promote_strategic\"       \n [3] \"strategic_intervention\"   \"intervention_upholding\"  \n [5] \"upholding_traditional\"    \"traditional_principles\"  \n [7] \"principles_standards\"     \"standards_evidence-based\"\n [9] \"evidence-based_research\"  \"research_communication\"  \n\n\nDFM with bigrams\n\nCode# create dfm from bigrams tokens object and group by journal \ndfm_bigrams &lt;- toks_ngram %&gt;%\n  dfm() %&gt;%\n  dfm_group(groups = abbreviation)\n\n# another wordcloud...why not!\nset.seed(101)\ntextplot_wordcloud(dfm_bigrams, \n                   min_count = 20, # include word only if it occurs at least n times in data set \n                   random_order = FALSE, \n                   rotation = 0.25,\n    color = RColorBrewer::brewer.pal(8, \"Dark2\"))\n\n\n\nCode# cloud that compares top bigrams for each journal\ndfm_bigrams %&gt;%\n  dfm_trim(min_termfreq = 15,\n           verbose = FALSE) %&gt;%\n  textplot_wordcloud(comparison = TRUE)"
  },
  {
    "objectID": "demos/week05/wk05_tc-titles-pt2.html",
    "href": "demos/week05/wk05_tc-titles-pt2.html",
    "title": "Wk 05: Titles in TC Journals, pt. 2",
    "section": "",
    "text": "Here, we conduct some computational text analysis on a dataset consisting of article metadata for articles published in 5 TC journals between 2005 and 2023.\nIn this exercise, we’ll work adjacent to Boettger and Friess (2014) in that we are working with a similar dataset. That said, our dataset doesn’t include Intercom but does feature 2000+ articles across 5 journals and 18 years. As such, rather than compare word usage across academic and trade publications, we might be able to do some additional analysis to trace shifts over time."
  },
  {
    "objectID": "demos/week05/wk05_tc-titles-pt2.html#overview",
    "href": "demos/week05/wk05_tc-titles-pt2.html#overview",
    "title": "Wk 05: Titles in TC Journals, pt. 2",
    "section": "",
    "text": "Here, we conduct some computational text analysis on a dataset consisting of article metadata for articles published in 5 TC journals between 2005 and 2023.\nIn this exercise, we’ll work adjacent to Boettger and Friess (2014) in that we are working with a similar dataset. That said, our dataset doesn’t include Intercom but does feature 2000+ articles across 5 journals and 18 years. As such, rather than compare word usage across academic and trade publications, we might be able to do some additional analysis to trace shifts over time."
  },
  {
    "objectID": "demos/week05/wk05_tc-titles-pt2.html#quantitative-analysis-of-textual-data",
    "href": "demos/week05/wk05_tc-titles-pt2.html#quantitative-analysis-of-textual-data",
    "title": "Wk 05: Titles in TC Journals, pt. 2",
    "section": "Quantitative Analysis of Textual Data",
    "text": "Quantitative Analysis of Textual Data\nQuantitative analysis of textual data has been a mainstay in corpus linguistics for some time. It’s been much less popular in RCWS, but can be a useful approach for working with large datasets.\nQuanteda\nWhile Ding and Kong (2019) and Boettger and Friess (2014) both use Laurence Anthony’s AntConc and there are a number of similar WYSIWYG corpus analysis tools out there, we’ll be using Quanteda. Quanteda is an R package designed to provide an open source alternative to expensive corpus tools that is simultaneously powerful and relatively easy to learn.\nHere are some concepts and vocabulary that are salient to corpus analysis with Quanteda:\n\n\nCorpus: A corpus is a collection of text documents. It’s the primary data structure in Quanteda, and it can consist of a single document or a large collection of documents.\n\nDocument-Term Matrix (DTM): A DTM is a table that represents the frequency of words (terms) in each document of a corpus. It’s a fundamental tool for text analysis and allows you to perform various operations on text data.\n\nTokenization: Tokenization is the process of breaking text into individual words or tokens. Here, a “token” refers to a single, meaningful unit of text. Tokens are the building blocks of textual data, and they are usually words, but they can also be phrases, subword units, punctuation marks, and more. Quanteda can tokenize text documents, which is the first step in many text analysis tasks.\n\nStop Words: Stop words are common words like “and,” “the,” “is,” etc., that are often removed from text before analysis. While most disciplines remove them without hesitation, scholars in rhetoric may ask questions for which stop words are significant.\n\nStemming and Lemmatization: These are techniques used to reduce words to their base or root forms. Stemming removes suffixes from words, while lemmatization maps words to their dictionary forms. Quanteda provides functions for both.\n\nDictionary: A dictionary is a list of words or phrases used to identify specific features or attributes in text. You can create custom dictionaries or use predefined ones in Quanteda.\n\nn-grams: N-grams are contiguous sequences of n items (usually words) from a given text. Quanteda can help you create n-grams to capture multi-word phrases and patterns.\n\nTidy Data Principles: Quanteda often follows the tidy data principles, which emphasize organizing data into a structured format that facilitates analysis. This includes using data frames and long-format data structures.\nInstall and Load Quanteda\nQuanteda is split into a series of modular packages. We’ll install each of them as well as a few others. For reference, read about the Quanteda family of packages.\n\nCode#install.packages(\"Rtools\") # you may need to install Rtools to install all the quanteda packages\n\n#install.packages(\"remotes\")\n\n#install.packages(\"quanteda\")\n#install.packages(\"readtext\")\n#install.packages(\"spacyr\")\n#install.packages(\"quanteda.textmodels\")\n#install.packages(\"quanteda.textstats\")\n#install.packages(\"quanteda.textplots\")\n#remotes::install_github(\"kbenoit/quanteda.dictionaries\")\n\n# load quanteda family of packages\nlibrary(quanteda)\nlibrary(quanteda.dictionaries)\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\nlibrary(quanteda.textstats)\n\n# load other libraries\nlibrary(readtext)\nlibrary(spacyr)\nlibrary(tidyverse)"
  },
  {
    "objectID": "demos/week05/wk05_tc-titles-pt2.html#quantitative-analysis-of-tc-titles-and-abstracts",
    "href": "demos/week05/wk05_tc-titles-pt2.html#quantitative-analysis-of-tc-titles-and-abstracts",
    "title": "Wk 05: Titles in TC Journals, pt. 2",
    "section": "Quantitative Analysis of TC Titles and Abstracts",
    "text": "Quantitative Analysis of TC Titles and Abstracts\nLoad data\n\nCode# define location of datafile\ndata_file &lt;- \"data/tc_journals.RData\"\n\n# load data\nload(data_file)\n\nglimpse(tc_journals)\n\nRows: 2,002\nColumns: 6\n$ source_title      &lt;chr&gt; \"JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\", \"…\n$ author_full_names &lt;chr&gt; \"Wickman, Chad\", \"DeJeu, Emily Barrow\", \"DeVasto, Da…\n$ article_title     &lt;chr&gt; \"Genre and Metagenre in Biomedical Research Writing\"…\n$ abstract          &lt;chr&gt; \"The use of reporting guidelines is an established y…\n$ publication_year  &lt;dbl&gt; 2023, 2022, 2016, 2009, 2009, 2020, 2016, 2012, 2011…\n$ abbreviation      &lt;chr&gt; \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBT…\n\n\nFor reference, here’s our data in a nifty table made with the reactable package. You can sort and filter by column, which may come in handy as you check your code results. For viewing purposes I’ve combined authors, journal, and year into a single column.\n\nCode#install.packages(\"reactable\")\nlibrary(reactable)\n\n# drop source title\ntable_data &lt;- tc_journals %&gt;%\n  mutate(\n    article = paste(author_full_names,\" (\",abbreviation,\", \",publication_year,\")\"\n    )\n  ) %&gt;%\n  select(article,\n         article_title,\n         abstract)\n\n# create table (define columns, add parameters & formatting)\nreactable(table_data,\n  columns = list(\n    article = colDef(name = \"Article\", sortable = TRUE, filterable = TRUE),\n    article_title = colDef(name = \"Title\", sortable = TRUE, filterable = TRUE, width = 175),\n    abstract = colDef(name = \"Abstract\", sortable = TRUE, filterable = TRUE, width = 500)\n  ),\n  defaultColDef = colDef(align = \"left\", width = 125),\n  searchable = TRUE, # Enable search\n  sortable = TRUE, # Enable sorting\n  defaultPageSize = 3,\n  highlight = TRUE,\n  outlined = TRUE,\n  striped = TRUE,\n  compact = TRUE\n)\n\n\n\n\n\n\nNow that we have packages installed, libraries loaded, and our data looks good, let’s try to answer a series of questions…\nWhat are the most common words in TC Journals?\nTo answer this question, we need to\n\ncreate a corpus object in which titles function as the texts\ntokenize each text (title) in the corpus\nremove stopwords (or decide not to)\ncreate a document-feature matrix\nsort and visualize the feature (token/word) counts\n\nCreate a corpus of titles\nCrete a corpus object.\n\nCode# Create a corpus object called \"title_corp\"\ntitle_corp &lt;- corpus(tc_journals, text_field = \"article_title\")\n\n# print the corpus\nprint(title_corp)\n\nCorpus consisting of 2,002 documents and 5 docvars.\ntext1 :\n\"Genre and Metagenre in Biomedical Research Writing\"\n\ntext2 :\n\"The Ethics of Delivering Bad News: Evaluating Impression Man...\"\n\ntext3 :\n\"Stasis and Matters of Concern: The Conviction of the L'Aquil...\"\n\ntext4 :\n\"Integrating Social Media Into Existing Work Environments The...\"\n\ntext5 :\n\"Practitioner Research Instruction A Neglected Curricular Are...\"\n\ntext6 :\n\"Legally Minded Technical Communicators: A Case Study of a Le...\"\n\n[ reached max_ndoc ... 1,996 more documents ]\n\nCode# summary of the corpus (including metadata for the texts)\n#summary(title_corp, n = 2)\n\n\n\n\n\n\n\n\nCorpus summary\n\n\n\nYou can call summary(corpus_name) to get summary statistics about the corpus.\n\n\nCreate a tokens object\nNow that we have a corpus, we can tokenize our texts (article titles) so that each word in the title becomes on in a list of tokens associated with that article. We can view the first three results to better see what the object looks like.\n\nCode# create a tokens object without punctuation, separators, and numbers\ntitle_tokens &lt;- tokens(title_corp, remove_punct = TRUE,\n                 remove_separators = TRUE,\n                 remove_numbers = TRUE)\n\n# check the result\ntitle_tokens[1:3]\n\nTokens consisting of 3 documents and 5 docvars.\ntext1 :\n[1] \"Genre\"      \"and\"        \"Metagenre\"  \"in\"         \"Biomedical\"\n[6] \"Research\"   \"Writing\"   \n\ntext2 :\n [1] \"The\"        \"Ethics\"     \"of\"         \"Delivering\" \"Bad\"       \n [6] \"News\"       \"Evaluating\" \"Impression\" \"Management\" \"Strategies\"\n[11] \"in\"         \"Corporate\" \n[ ... and 2 more ]\n\ntext3 :\n [1] \"Stasis\"     \"and\"        \"Matters\"    \"of\"         \"Concern\"   \n [6] \"The\"        \"Conviction\" \"of\"         \"the\"        \"L'Aquila\"  \n[11] \"Seven\"     \n\n\nRemove stopwords\nFor this analysis, we might also remove stopwords. We can view the first 15 words in a standard list of stopwords.\n\nCode# see a list of stopwords\nhead(stopwords(\"en\"), 15)\n\n [1] \"i\"          \"me\"         \"my\"         \"myself\"     \"we\"        \n [6] \"our\"        \"ours\"       \"ourselves\"  \"you\"        \"your\"      \n[11] \"yours\"      \"yourself\"   \"yourselves\" \"he\"         \"him\"       \n\n\nNotice that “you” was a key word in B&G’s comparative analysis of academic and trade publications and also happens to be one of the stopwords in our list.\nWe’ll create a separate tokens object without stopwords so that we can compare the results with and without.\n\nCode# create a new tokens object by removing stopwords from the existing tokens object  \ntitle_tokens_nostop &lt;- title_tokens %&gt;%\n  tokens_remove(stopwords(\"en\"))\n\n# check the result\ntitle_tokens_nostop[1:3]\n\nTokens consisting of 3 documents and 5 docvars.\ntext1 :\n[1] \"Genre\"      \"Metagenre\"  \"Biomedical\" \"Research\"   \"Writing\"   \n\ntext2 :\n [1] \"Ethics\"     \"Delivering\" \"Bad\"        \"News\"       \"Evaluating\"\n [6] \"Impression\" \"Management\" \"Strategies\" \"Corporate\"  \"Financial\" \n[11] \"Reporting\" \n\ntext3 :\n[1] \"Stasis\"     \"Matters\"    \"Concern\"    \"Conviction\" \"L'Aquila\"  \n[6] \"Seven\"     \n\n\nCreate a document-feature matrix\nNext we can use a tokens object to create a document-feature matrix (dfm). For reference:\n\nDocument: In a DFM, each row represents a document or text unit. This can be a single document, a sentence, a paragraph, or any other defined text unit. In our case, it’s a title + abstract.\nFeature: Each column represents a feature, typically a word or a term that appears in the documents. These features are usually extracted from the text through tokenization, and they can be single words or multi-word phrases.\nMatrix: The DFM is a two-dimensional matrix where the rows correspond to documents, and the columns correspond to features. The values in the matrix represent the frequency of each feature in each document, but they can also be transformed into other measures such as term frequency-inverse document frequency (TF-IDF) scores.\n\nLet’s create two dfms: one that includes stopwords and another that doesn’t.\n\nCode# Below we create two dfms: one from each of our tokens objects (w/ stopwords and w/o stopwords)\n\n# syntax option 1 (with stopwords)\ntitles_dfm &lt;- title_tokens %&gt;%\n  dfm()\n\n\n# syntax option 2 (without stopwords)\ntitles_nostop_dfm &lt;- dfm(title_tokens_nostop)\n\n\nNow we can print each matrix.\n\nCode# dfm with stopwords\nprint(titles_dfm)\n\nDocument-feature matrix of: 2,002 documents, 4,523 features (99.76% sparse) and 5 docvars.\n       features\ndocs    genre and metagenre in biomedical research writing the ethics of\n  text1     1   1         1  1          1        1       1   0      0  0\n  text2     0   0         0  1          0        0       0   1      1  1\n  text3     0   1         0  0          0        0       0   2      0  2\n  text4     0   0         0  0          0        0       0   1      0  1\n  text5     0   0         0  1          0        1       0   0      0  0\n  text6     0   0         0  0          0        0       1   0      0  1\n[ reached max_ndoc ... 1,996 more documents, reached max_nfeat ... 4,513 more features ]\n\nCode# dfm without stopwords\nprint(titles_nostop_dfm)\n\nDocument-feature matrix of: 2,002 documents, 4,422 features (99.83% sparse) and 5 docvars.\n       features\ndocs    genre metagenre biomedical research writing ethics delivering bad news\n  text1     1         1          1        1       1      0          0   0    0\n  text2     0         0          0        0       0      1          1   1    1\n  text3     0         0          0        0       0      0          0   0    0\n  text4     0         0          0        0       0      0          0   0    0\n  text5     0         0          0        1       0      0          0   0    0\n  text6     0         0          0        0       1      0          0   0    0\n       features\ndocs    evaluating\n  text1          0\n  text2          1\n  text3          0\n  text4          0\n  text5          0\n  text6          0\n[ reached max_ndoc ... 1,996 more documents, reached max_nfeat ... 4,412 more features ]\n\n\n\n\n\n\n\n\nSparse matrices\n\n\n\nIn this context, “sparse” refers to a type of data structure used to efficiently work with large data. In a sparse matrix, the majority of the elements have a value of zero. If your dfm is 99.56% sparse, it means that only .04% of the entries are something other than 0.\n\n\nView top features (words)\n\nCode# 20 most frequent words in dfm (with stop)\ntopfeatures(titles_dfm, 20)\n\n          and           the            of            in communication \n         1058          1053          1025           820           615 \n            a     technical           for            to        design \n          599           546           378           266           197 \n      writing            an            on          from            as \n          183           173           137           132           129 \n     rhetoric  professional      research        online         study \n          120           113           106           100            95 \n\nCode# 20 most frequent words in dfm (with stop)\ntopfeatures(titles_nostop_dfm, 20)\n\ncommunication     technical        design       writing      rhetoric \n          615           546           197           183           120 \n professional      research        online         study        social \n          113           106           100            95            85 \n   rhetorical      analysis       content   information        review \n           83            80            79            76            72 \n         case    technology          work       science          user \n           69            69            68            67            64 \n\n\nVisualize top words (with stopwords)\n\nCode# get top n features\nfeatures_titles_dfm &lt;- textstat_frequency(titles_dfm, n = 50)\n\n# sort by reverse frequency order\nfeatures_titles_dfm$feature &lt;- with(features_titles_dfm, reorder(feature, -frequency))\n\nggplot(features_titles_dfm, aes(x = feature, y = frequency)) +\n    geom_point() + \n    theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(title = \"Top words in TC Article Titles (2005-2023)\")\n\n\n\n\nVisualize top words (without stopwords)\n\nCode# get top n features\nfeatures_titles_nostop_dfm &lt;- textstat_frequency(titles_nostop_dfm, n = 50)\n\n# sort by reverse frequency order\nfeatures_titles_nostop_dfm$feature &lt;- with(features_titles_nostop_dfm, reorder(feature, -frequency))\n\nggplot(features_titles_nostop_dfm, aes(x = feature, y = frequency)) +\n    geom_point() + \n    theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(title = \"Top words in TC Article Titles (2005-2023)\")\n\n\n\n\nReplicate B&G’s frequency table (no stop words)\nTop words in TC Article Titles (2005-2023)\n\nCodesorted_features &lt;- features_titles_nostop_dfm %&gt;%\n  arrange(desc(frequency))%&gt;%\n  select(feature, frequency, docfreq)%&gt;%\n  reactable(defaultPageSize = 20,\n  highlight = TRUE,\n  outlined = TRUE,\n  striped = TRUE,\n  compact = TRUE)\n\nsorted_features\n\n\n\n\n\n\nNice! But are “technical” and “communication” really top words? Or is “technical communication” the top phrase?\nWhat are the top words or phrases?\nHere, we can use Quanteda’s vignette Working with multi-word expressions.\nDiscover collocations\nHere, I start with the tokens object created earlier (no punctuation, separators, or numbers). We then remove stopwords, make the words lowercase, and\n\nCode# min count is a big parameter here. \ncol &lt;- title_tokens %&gt;% \n       tokens_remove(stopwords(\"en\")) %&gt;% \n       tokens_select(pattern = \"^[A-Z]\", valuetype = \"regex\", \n                     case_insensitive = TRUE, padding = TRUE) %&gt;% \n       textstat_collocations(min_count = 15, tolower = TRUE)\n\nhead(col)\n\n                 collocation count count_nested length   lambda        z\n1    technical communication   349            0      2 4.608652 41.40442\n2                 case study    43            0      2 6.221791 21.40411\n3              editor's desk    30            0      2 7.796537 17.94783\n4               social media    26            0      2 5.196207 17.94057\n5            user experience    23            0      2 6.069663 17.42236\n6 professional communication    55            0      2 3.148093 16.35628\n\n\nWe can then use that statistical scoring of word associations to automatically compound collocates into multi-word expressions.\n\nCodecomp_title_toks &lt;- tokens_compound(title_tokens, pattern = col)\n\nhead(comp_title_toks)\n\nTokens consisting of 6 documents and 5 docvars.\ntext1 :\n[1] \"Genre\"      \"and\"        \"Metagenre\"  \"in\"         \"Biomedical\"\n[6] \"Research\"   \"Writing\"   \n\ntext2 :\n [1] \"The\"        \"Ethics\"     \"of\"         \"Delivering\" \"Bad\"       \n [6] \"News\"       \"Evaluating\" \"Impression\" \"Management\" \"Strategies\"\n[11] \"in\"         \"Corporate\" \n[ ... and 2 more ]\n\ntext3 :\n [1] \"Stasis\"     \"and\"        \"Matters\"    \"of\"         \"Concern\"   \n [6] \"The\"        \"Conviction\" \"of\"         \"the\"        \"L'Aquila\"  \n[11] \"Seven\"     \n\ntext4 :\n [1] \"Integrating\"  \"Social_Media\" \"Into\"         \"Existing\"     \"Work\"        \n [6] \"Environments\" \"The\"          \"Case\"         \"of\"           \"Delicious\"   \n\ntext5 :\n [1] \"Practitioner\"            \"Research\"               \n [3] \"Instruction\"             \"A\"                      \n [5] \"Neglected\"               \"Curricular\"             \n [7] \"Area\"                    \"in\"                     \n [9] \"Technical_Communication\" \"Undergraduate\"          \n[11] \"Programs\"               \n\ntext6 :\n [1] \"Legally\"                 \"Minded\"                 \n [3] \"Technical_Communicators\" \"A\"                      \n [5] \"Case_Study\"              \"of\"                     \n [7] \"a\"                       \"Legal\"                  \n [9] \"Writing\"                 \"Course\"                 \n\n\nNow that we have a tokens object that includes multi-word expressions…\nFor reference:\n\nQuanteda Tutorials\nQuanteda Documentation"
  },
  {
    "objectID": "demos/week06/wk06_tracking-frames.html",
    "href": "demos/week06/wk06_tracking-frames.html",
    "title": "Wk 06: Tracking ngrams in TC Research",
    "section": "",
    "text": "This week we explore the techniques used in Majdik (2019) and Graham (2021) to track ngrams in our dataset of TC articles. The techniques that follow are similar to the exploratory work that both authors advocate. That is, you might build on this work as you develop a more nuanced approach to your data.\nWhile we could use Quanteda or a number of other approaches, we’ll draw on Chapter 4 of Text Mining with R: A Tidy Approach."
  },
  {
    "objectID": "demos/week06/wk06_tracking-frames.html#overview",
    "href": "demos/week06/wk06_tracking-frames.html#overview",
    "title": "Wk 06: Tracking ngrams in TC Research",
    "section": "",
    "text": "This week we explore the techniques used in Majdik (2019) and Graham (2021) to track ngrams in our dataset of TC articles. The techniques that follow are similar to the exploratory work that both authors advocate. That is, you might build on this work as you develop a more nuanced approach to your data.\nWhile we could use Quanteda or a number of other approaches, we’ll draw on Chapter 4 of Text Mining with R: A Tidy Approach."
  },
  {
    "objectID": "demos/week06/wk06_tracking-frames.html#preparation",
    "href": "demos/week06/wk06_tracking-frames.html#preparation",
    "title": "Wk 06: Tracking ngrams in TC Research",
    "section": "Preparation",
    "text": "Preparation\nLoad libraries\n\nCodelibrary(tidyverse)\n\n#install.packages(\"tidytext\")\nlibrary(tidytext)\n\n\nLoad data\n\nCoderaw_data &lt;- read_csv(\"data/tc_journals.csv\")\n\nglimpse(raw_data)\n\nRows: 2,002\nColumns: 6\n$ source_title      &lt;chr&gt; \"JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\", \"…\n$ author_full_names &lt;chr&gt; \"Wickman, Chad\", \"DeJeu, Emily Barrow\", \"DeVasto, Da…\n$ article_title     &lt;chr&gt; \"Genre and Metagenre in Biomedical Research Writing\"…\n$ abstract          &lt;chr&gt; \"The use of reporting guidelines is an established y…\n$ publication_year  &lt;dbl&gt; 2023, 2022, 2016, 2009, 2009, 2020, 2016, 2012, 2011…\n$ abbreviation      &lt;chr&gt; \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBT…"
  },
  {
    "objectID": "demos/week06/wk06_tracking-frames.html#exploring-ngrams-in-titleabstracts",
    "href": "demos/week06/wk06_tracking-frames.html#exploring-ngrams-in-titleabstracts",
    "title": "Wk 06: Tracking ngrams in TC Research",
    "section": "Exploring ngrams in title+abstracts",
    "text": "Exploring ngrams in title+abstracts\nCreate a “text” column that is title and abstract combined\n\nCoderaw_data$text &lt;- paste(raw_data$article_title, raw_data$abstract, sep = \" . \")\n\nhead(raw_data$text, n = 2)\n\n[1] \"Genre and Metagenre in Biomedical Research Writing . The use of reporting guidelines is an established yet still-evolving practice in the field of biomedicine. These documents are often linked to common methodologies (e.g., randomized clinical trials); they include multiple textual artifacts (e.g., checklists, flow diagrams) and have a history that is coextensive with the emergence and ongoing development of evidence-based medicine (e.g., as an epistemological orientation to research and decision making). Drawing on the concept of metagenre, this article examines how practitioners use reporting guidelines to define and regulate the boundaries of biomedical research and writing activity. The analysis, focusing on one prominent set of guidelines, shows how practitioners use the genre-metagenre dynamic to promote strategic intervention while upholding traditional principles and standards for evidence-based research and communication.\"\n[2] \"The Ethics of Delivering Bad News: Evaluating Impression Management Strategies in Corporate Financial Reporting . Business communication textbooks offer impression management (IM) strategies to help students learn how to soften bad news. But corporations sometimes use these strategies in ethically questionable ways. This article analyzes IM strategies in a landmark case of ethically dubious corporate financial reporting. Findings suggest that the company, Ivax, manipulated three standard IM strategies by overamplifying its power to fix a financial crisis, substantially downplaying bad news, and concealing damaging information. Ivax also used a fourth, less familiar strategy: It buried contradictory information in legal disclaimers. Instructors need to help students become ethical writers who avoid questionable IM strategies like these.\"                                                                                                 \n\n\nBreak “text” into a list of bigrams\nWe use unnest_tokens from tidytext to break our “text” column into individual observations of bigrams.\nNote that the “text” column will be replaced by a “bigram” column.\n\nCodetc_bigrams &lt;- raw_data %&gt;%\n  unnest_tokens(bigram, text, token = \"ngrams\", n = 2) %&gt;%\n  filter(!is.na(bigram))\n\n\nNotice that we’ve transformed our 2002 articles into 227,304 bigrams.\nWe can then count the most common bigrams in the dataset\n\nCodetc_bigrams %&gt;%\n  count(bigram, sort = TRUE)\n\n# A tibble: 105,848 × 2\n   bigram                      n\n   &lt;chr&gt;                   &lt;int&gt;\n 1 of the                   1232\n 2 technical communication  1197\n 3 in the                    960\n 4 this article              883\n 5 of technical              570\n 6 and the                   512\n 7 as a                      435\n 8 technical writing         427\n 9 to the                    424\n10 on the                    395\n# ℹ 105,838 more rows\n\n\nfilter stopwords\n\nCodelibrary(tidyr)\n\n# transform \"bigram\" column into two columns: \"word1\" and \"word2\"\nbigrams_separated &lt;- tc_bigrams %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\n# filter to keep only rows where both word1 and word2 are not stopwords\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\n\n# new bigram counts\nbigram_counts &lt;- bigrams_filtered %&gt;%\n  count(word1, word2, sort = TRUE)\n\nbigram_counts\n\n# A tibble: 39,418 × 3\n   word1        word2             n\n   &lt;chr&gt;        &lt;chr&gt;         &lt;int&gt;\n 1 technical    communication  1197\n 2 technical    writing         427\n 3 technical    communicators   380\n 4 author       copyright       248\n 5 professional communication   241\n 6 writing      communication   237\n 7 sage         publications    212\n 8 multiple     sites           182\n 9 copyright    holder's        155\n10 holder's     express         146\n# ℹ 39,408 more rows\n\n\nCustom stopwords\n\nCodecustom_stopwords &lt;- c(\"copyright\",\n                      \"sage\",\n                      \"holder's\",\n                      \"express\",\n                      \"permission\",\n                      \"download\")\n\n# add custom stopwords to filter process\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)%&gt;%\n  filter(!word1 %in% custom_stopwords) %&gt;%\n  filter(!word2 %in% custom_stopwords)\n\n# new bigram counts\nbigram_counts &lt;- bigrams_filtered %&gt;%\n  count(word1, word2, sort = TRUE)\n\n\nbigram_counts\n\n# A tibble: 39,374 × 3\n   word1        word2             n\n   &lt;chr&gt;        &lt;chr&gt;         &lt;int&gt;\n 1 technical    communication  1197\n 2 technical    writing         427\n 3 technical    communicators   380\n 4 professional communication   241\n 5 writing      communication   237\n 6 multiple     sites           182\n 7 social       media           135\n 8 user         experience      102\n 9 social       justice          94\n10 email        articles         92\n# ℹ 39,364 more rows\n\n\nNow we can reunite our two columns into a single bigram column\n\nCodebigrams_united &lt;- bigrams_filtered %&gt;%\n  unite(bigram, word1, word2, sep = \" \")\n\nbigrams_united\n\n# A tibble: 58,563 × 7\n   source_title        author_full_names article_title abstract publication_year\n   &lt;chr&gt;               &lt;chr&gt;             &lt;chr&gt;         &lt;chr&gt;               &lt;dbl&gt;\n 1 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n 2 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n 3 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n 4 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n 5 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n 6 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n 7 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n 8 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n 9 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n10 JOURNAL OF BUSINES… Wickman, Chad     Genre and Me… The use…             2023\n# ℹ 58,553 more rows\n# ℹ 2 more variables: abbreviation &lt;chr&gt;, bigram &lt;chr&gt;\n\n\nTrigrams (all at once)\n\nCodetc_trigrams &lt;- raw_data %&gt;%\n  unnest_tokens(trigram, text, token = \"ngrams\", n = 3) %&gt;%\n  filter(!is.na(trigram)) %&gt;%\n  separate(trigram, c(\"word1\", \"word2\", \"word3\"), sep = \" \") %&gt;%\n  filter(!word1 %in% stop_words$word,\n         !word2 %in% stop_words$word,\n         !word3 %in% stop_words$word,\n         !word1 %in% custom_stopwords,\n         !word2 %in% custom_stopwords,\n         !word3 %in% custom_stopwords) %&gt;%\n  unite(trigram, word1, word2, word3, sep = \" \")\n\n\ntc_trigrams %&gt;%\n  count(trigram, sort = TRUE)\n\n# A tibble: 22,185 × 2\n   trigram                               n\n   &lt;chr&gt;                             &lt;int&gt;\n 1 technical writing communication     235\n 2 professional communication tpc       72\n 3 user centered design                 37\n 4 original published version           31\n 5 tactical technical communication     31\n 6 technical communication classroom    30\n 7 technical communication research     29\n 8 technical communication programs     24\n 9 covid 19 pandemic                    22\n10 user experience design               20\n# ℹ 22,175 more rows"
  },
  {
    "objectID": "demos/week06/wk06_tracking-frames.html#tracking-counts-over-time",
    "href": "demos/week06/wk06_tracking-frames.html#tracking-counts-over-time",
    "title": "Wk 06: Tracking ngrams in TC Research",
    "section": "Tracking Counts over time",
    "text": "Tracking Counts over time\nFiltering bigrams of interest\nWe can use filter() to retain ngrams of interest, which we can then visualize…\n\nCode# define bigram of interest\nsj &lt;-  \"social justice\"\n\n\n# filter for presence of bigram\nsj_bigrams &lt;- bigrams_united %&gt;%\n  filter(bigram == sj)\n\n# check result\nglimpse(sj_bigrams)\n\nRows: 94\nColumns: 7\n$ source_title      &lt;chr&gt; \"JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION\", \"…\n$ author_full_names &lt;chr&gt; \"Frost, Erin A.\", \"Petersen, Emily January; Walton, …\n$ article_title     &lt;chr&gt; \"Apparent Feminism as a Methodology for Technical Co…\n$ abstract          &lt;chr&gt; \"This article introduces apparent feminism, which is…\n$ publication_year  &lt;dbl&gt; 2016, 2018, 2018, 2018, 2018, 2018, 2022, 2022, 2022…\n$ abbreviation      &lt;chr&gt; \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBTC\", \"JBT…\n$ bigram            &lt;chr&gt; \"social justice\", \"social justice\", \"social justice\"…\n\nCode# Calculate the frequency of the bigram by year\nsj_bigram_freq &lt;- sj_bigrams %&gt;%\n  group_by(publication_year) %&gt;%\n  summarize(frequency = n()) %&gt;%\n  ungroup()\n\n# Plot the frequency of the bigram by year\nggplot(sj_bigram_freq, aes(x = publication_year, y = frequency)) +\n  geom_line() +\n  ggtitle(\"Frequency of 'social justice' Bigram by Year\") +\n  xlab(\"Publication Year\") +\n  ylab(\"Frequency\") +\n  scale_x_continuous(breaks = seq(min(sj_bigram_freq$publication_year), max(sj_bigram_freq$publication_year), by = 1))\n\n\n\n\nWe can also add other dimensions to the analysis, e.g. frequency by year and journal\n\nCode# Calculate the frequency of the bigram by year and journal\nsj_bigram_freq &lt;- sj_bigrams %&gt;%\n  group_by(publication_year, abbreviation) %&gt;%\n  summarize(frequency = n()) %&gt;%\n  ungroup()\n\n# Plot the frequency of the \"social justice\" bigram by year and journal\nggplot(sj_bigram_freq, aes(x = publication_year, y = frequency)) +\n  geom_line() +\n  ggtitle(\"Frequency of 'social justice' Bigram by Year and Journal\") +\n  xlab(\"Publication Year\") +\n  ylab(\"Frequency\") +\n  facet_wrap(~abbreviation, scales = \"free_x\", ncol = 2)\n\n\n\n\nAnd we can make that look a little nicer.\n\nCode#install.packages(\"ggthemes\")\nlibrary(ggthemes)\n\n# Calculate the frequency of the bigram by year and journal\nsj_bigram_freq &lt;- sj_bigrams %&gt;%\n  group_by(publication_year, abbreviation) %&gt;%\n  summarize(frequency = n()) %&gt;%\n  ungroup()\n\n# Plot the frequency of the \"social justice\" bigram by year and journal\nggplot(sj_bigram_freq, aes(x = publication_year, y = frequency, color = abbreviation)) +\n  geom_line() +\n  ggtitle(\"Frequency of 'social justice' by Year and Journal\") +\n  xlab(\"Publication Year\") +\n  ylab(\"Frequency\") +\n  scale_x_continuous(breaks = seq(min(sj_bigram_freq$publication_year), max(sj_bigram_freq$publication_year), by = 1)) +\n  scale_y_continuous(breaks = seq(0, max(sj_bigram_freq$frequency), by = 2)) +\n  theme_fivethirtyeight()\n\n\n\n\nFrom target bigram to more complex constructs\nWe can also create a list of bigrams as a proxy for a construct.\n\nCode# List of bigrams you want to analyze\nconstruct_list &lt;- c(\"bigram1\", \"bigram2\", \"bigram3\")  # Add your list of bigrams here\n\n# Filter for the specific bigrams in the list\nfiltered_data &lt;- bigrams_united %&gt;%\n  filter(bigram %in% construct_list)\n\n# calculate frequency\n\n# plot\n\n\nAlternatively, if you wanted to track complex constructions a la Majdik you might use the stringr package to develop some regular expressions."
  },
  {
    "objectID": "demos/week06/wk06_tracking-frames.html#some-other-exploratory-analyses",
    "href": "demos/week06/wk06_tracking-frames.html#some-other-exploratory-analyses",
    "title": "Wk 06: Tracking ngrams in TC Research",
    "section": "Some other exploratory analyses",
    "text": "Some other exploratory analyses\nTF-IDF\nWe can use term frequency inverse document frequency (TF-IDF). Similar to “keyness” in Quanteda, tf-idf can help us identify ngrams that are distinctive of a particular subset of the corpus.\n\nCodebigram_tf_idf &lt;- bigrams_united %&gt;%\n  count(abbreviation, bigram) %&gt;%\n  bind_tf_idf(bigram, abbreviation, n) %&gt;%\n  arrange(desc(tf_idf))\n\nbigram_tf_idf\n\n# A tibble: 43,753 × 6\n   abbreviation bigram                      n      tf   idf  tf_idf\n   &lt;chr&gt;        &lt;chr&gt;                   &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 JTWC         multiple sites            182 0.0135  1.61  0.0217 \n 2 JTWC         writing communication     235 0.0174  0.916 0.0160 \n 3 JTWC         email articles             92 0.00683 1.61  0.0110 \n 4 JTWC         copy users                 46 0.00342 1.61  0.00550\n 5 JTWC         original published         36 0.00267 1.61  0.00430\n 6 JTWC         editor's desk              31 0.00230 1.61  0.00370\n 7 JTWC         published version          31 0.00230 1.61  0.00370\n 8 CDQ          communication design       60 0.00624 0.511 0.00319\n 9 CDQ          communication designers    19 0.00197 1.61  0.00318\n10 CDQ          university press           12 0.00125 1.61  0.00201\n# ℹ 43,743 more rows\n\n\nBigram tf-idf, by journal\n\nCodelibrary(ggplot2)\n\nbigram_tf_idf %&gt;%\n  arrange(desc(tf_idf)) %&gt;%\n  group_by(abbreviation) %&gt;%\n  slice_max(tf_idf, n = 10) %&gt;%\n  ungroup() %&gt;%\n  mutate(bigram = reorder(bigram, tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, bigram, fill = abbreviation)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ abbreviation, ncol = 2, scales = \"free\") +\n  labs(x = \"tf-idf of bigram\", y = NULL)\n\n\n\n\nBigram tf-idf, by year\n\nCode# get tf-idf by year\nbigram_tf_idf_year &lt;- bigrams_united %&gt;%\n  count(publication_year, bigram) %&gt;%\n  bind_tf_idf(bigram, publication_year, n) %&gt;%\n  arrange(desc(tf_idf))\n\n# plot tf-idf by year\nbigram_tf_idf_year %&gt;%\n  arrange(desc(tf_idf)) %&gt;%\n  group_by(publication_year) %&gt;%\n  slice_max(tf_idf, n = 5) %&gt;%\n  ungroup() %&gt;%\n  mutate(bigram = reorder(bigram, tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, bigram, fill = publication_year)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ publication_year, ncol = 3, scales = \"free\") +\n  labs(x = \"tf-idf of bigram\", y = NULL)\n\n\n\n\n\nCodelibrary(igraph)\n\nbigram_counts\n\n# A tibble: 39,374 × 3\n   word1        word2             n\n   &lt;chr&gt;        &lt;chr&gt;         &lt;int&gt;\n 1 technical    communication  1197\n 2 technical    writing         427\n 3 technical    communicators   380\n 4 professional communication   241\n 5 writing      communication   237\n 6 multiple     sites           182\n 7 social       media           135\n 8 user         experience      102\n 9 social       justice          94\n10 email        articles         92\n# ℹ 39,364 more rows\n\nCodebigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 25) %&gt;%\n  graph_from_data_frame()\n\nbigram_graph\n\nIGRAPH 4d6f8b4 DN-- 81 69 -- \n+ attr: name (v/c), n (e/n)\n+ edges from 4d6f8b4 (vertex names):\n [1] technical    -&gt;communication technical    -&gt;writing      \n [3] technical    -&gt;communicators professional -&gt;communication\n [5] writing      -&gt;communication multiple     -&gt;sites        \n [7] social       -&gt;media         user         -&gt;experience   \n [9] social       -&gt;justice       email        -&gt;articles     \n[11] article      -&gt;examines      content      -&gt;strategy     \n[13] web          -&gt;sites         covid        -&gt;19           \n[15] communication-&gt;tpc           communication-&gt;design       \n+ ... omitted several edges\n\n\n\nCode#install.packages(\"ggraph\")\nlibrary(ggraph)\nset.seed(999)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1)\n\n\n\nCodea &lt;- grid::arrow(type = \"closed\", length = unit(.1, \"inches\"))\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,\n                 arrow = a, end_cap = circle(.05, 'inches')) +\n  geom_node_point(color = \"lightblue\", size = 3) +\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "demos/week09/wk09_networks_pt2.html",
    "href": "demos/week09/wk09_networks_pt2.html",
    "title": "Wk 09: Network Analysis, pt 2",
    "section": "",
    "text": "Codelibrary(tidyverse)\nlibrary(bibliometrix)\nlibrary(stringr)\nRead in combined data\nCodeM &lt;- read_rds(\"data/comb.rds\")"
  },
  {
    "objectID": "demos/week09/wk09_networks_pt2.html#create-subsets-for-analysis",
    "href": "demos/week09/wk09_networks_pt2.html#create-subsets-for-analysis",
    "title": "Wk 09: Network Analysis, pt 2",
    "section": "Create subsets for analysis",
    "text": "Create subsets for analysis\nWe can manipulate the data here and then explore further with bibliometrix.\nHere is a list of WOS/Bibliometrix tags, for reference. Some key tags:\n\nPY: publication year\nTI: document title\nAU: authors\nDE: author-supplied keywords\nAB: abstract\nCR: list of cited references\nNR: count of cited references\n\nFilter articles by publication year\n\nCode# Only articles after 1992\n\npost92 &lt;- M %&gt;%\n  filter(PY &gt; 1992)\n\n\nFilter articles by “word” in title\n\nCodeword &lt;- \"ethics\"\n\nethics &lt;- M %&gt;%\n  filter(str_detect(TI, regex(word, ignore_case = TRUE)))\n\n\nFilter articles by one or more words in abstract\n\nCodesearch_terms &lt;- c(\"Aristotle\", \"Plato\", \"Socrates\")  # List of words to check for\n\n# create a regular expression pattern by pasting the search terms together and separating them with \\\\b|\\\\b. The \\\\b is a word boundary anchor, ensuring that we match whole words or phrases rather than substrings \npattern &lt;- paste0(\"\\\\b\", paste(search_terms, collapse = \"\\\\b|\\\\b\"), \"\\\\b\")\n\ngreeks &lt;- M %&gt;%\n  filter(str_detect(AB, regex(pattern, ignore_case = TRUE)))\n\ngreeks$AB\n\n[1] \"THIS ARTICLE USES THE CROSS-CULTURAL CONCEPTS OF CONTEXT AND TIME TO EXAMINE THE RHETORIC OF GERMAN UNIVERSITY STUDENTS IN AN ENGLISH BUSINESS WRITING COURSE. THIS PARTICIPANT-OBSERVER ACCOUNT, WHICH INCLUDES NUMEROUS STUDENT EXAMPLES AND OBSERVATIONS, PROVIDES AFRESH PERSPECTIVE FOR AMERICAN TEACHERS IN INCREASINGLY MULTINATIONAL, MULTICULTURAL CLASSROOMS. IT ALSO SUGGESTS HOW ARISTOTLE'S CONCEPTS OF ETHOS, LOGOS, AND PATHOS TOGETHER WITH THE CASE METHOD AND GROUP WORK CAN HELP TEACHERS RESPOND TO THE CHALLENGES IN SUCH CLASSROOMS. THE ARTICLE CONCLUDES BY SUGGESTING THAT UNDERSTANDING THE RHETORIC OF CULTURE IS AN IMPORTANT STEP IN ACCEPTING AND NEGOTIATING CULTURAL DIFFERENCES.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n[2] \"THIS REVIEW OF THE RELATIONSHIP OF LAW AND ART IN THE LITIGATIVE CONTEXT EXPLORES WAYS IN WHICH THE METHODOLOGIES OF THE NOVELIST AND OTHER ARTISTS CAN BE INVOKED BY THE LAWYER IN STRUCTURING AND DEVELOPING A CASE AND PRESENTING IT TO A COURT. TO THE LITIGATORS WHO TRANSCEND THE FORM BOOKS AND STEREOTYPES AND SEE THEIR CASES WITH AFRESH EYE, NEITHER THE LAW NOR THE FACTS ARE FIXED IN STONE BUT RATHER CREATED TO MEET THE DEEPEST REALITIES OF THE CASE WITHIN THE CONTEXT OF OUR MOST FUNDAMENTAL VALUES AND BELIEFS. LITIGATORS, BY THE WAY THEY DEFINE AND PROJECT THE ISSUES, CAN AFFECT, EVEN DETERMINE, WHAT LAW AND FACTS ARE LEGALLY RELEVANT AND DISPOSITIVE. THEY MUST DEVISE AND WRITE THE STORY THAT THREADS THE CLIENT'S WAY OUR OF THE LABYRINTH. MASTERY OF THE FORMAL REQUIREMENTS OF LITIGATIVE WRITING IS ONLY A NECESSARY FIRST STEP. FREEWRITING; HEMINGWAYESQUE CHOICE OF WORDS AND SYNTAX; HARNESSING THE SYMBOLIC, OFTEN HIDDEN, POWER OF LANGUAGE; ACHIEVING THE DRAMATIC POTENTIAL OF CASE PRESENTATION-ALL THESE AND MORE FROM THE CREATIVE ARTIST'S REPERTOIRE EMPOWER LITIGATORS TO WIN THEIR CASES. RESORT IS MADE NOT ONLY TO THE APPLICABLE STATUTORY, REGULATORY, AND CASE LAW BUT ALSO TO THE PROCESSES OF THE LIKE OF CEZANNE, CONRAD, HEMINGWAY, TOLSTOY, JOYCE, ARISTOTLE, AND FAULKNER.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n[3] \"THE REPORT FOR DECISION MAKING SHARES SOME COMMON GROUND WITH THE PROPOSAL, THE REPORT OF SCIENTIFIC EXPERIMENT, AND EVEN THE PERSUASIVE ESSAY, YET THESE GENRES DIFFER. RECOGNIZING THESE DIFFERENCES IS NECESSARY FOR EFFECTIVE INQUIRY, PEDAGOGY, AND DECISION MAKING. THE GENRES ARE MEANS OF SOLVING DIFFERENT TYPES OF PROBLEMS: PRACTICAL, EMPIRICAL, AND THEORETICAL. THEY SERVE DIFFERENT AIMS: ACTION, DEMONSTRATION, AND CONVICTION. THE PROPOSAL, LIKE THE REPORT, MAY SOLVE PRACTICAL PROBLEMS, BUT THE PROPOSAL ADVOCATES, WHEREAS THE REPORT INQUIRES. THESE GENRES ALL EMBODY ASSUMPTIONS ABOUT PROBLEM SOLVING AND INQUIRY IN THEIR FORMS. APPLYING THE PROBLEM-SOLVING GOALS AND METHODS OF THE PROPOSAL, EXPERIMENTAL REPORT, OR ESSAY TO THE REPORT FOR DECISION-MAKING COMPROMISES THE QUALITY OF THE INQUIRY AND OF THE RESULTING DECISION. COMPLEX PROBLEMS FOR DECISION MAKING REQUIRE A RHETORICAL METHOD OF INQUIRY BASED ON ARISTOTLE'S SPECIAL TOPICS. THE REPORT GENRE REFLECTS THE INVENTION HEURISTICS AND ANALYSIS IN ITS FORM.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[4] \"PURPOSE: TO IDENTIFY THE MAIN RHETORICAL TECHNIQUES ACTUALLY USED TO SECURE INVESTORS' SUPPORT IN SOME OF THE MOST SUCCESSFUL (MOST-FUNDED) WEB-BASED CROWD FUNDING PROJECTS. THE STUDY SERVES TO BRIDGE THE GAP BETWEEN THEORETICAL RESEARCH OF RHETORIC AND THE NEEDS OF BUSINESS COMMUNICATION PRACTITIONERS BY IDENTIFYING THE MEANS OF PERSUASION THAT CAN BE USED BY ONLINE CROWD FUNDING ENTREPRENEURS. METHOD: QUALITATIVE ANALYSIS OF THIRTEEN CROWD FUNDING PROJECT DESCRIPTIONS POSTED ON A MAJOR WEB SITE-WWW.KICKSTARTER.COM-WAS PERFORMED TO IDENTIFY SPECIFIC RHETORICAL TECHNIQUES VIA TEXT CODING. THE SAMPLE INCLUDED THE MOST-FUNDED PROJECTS TO DATE, ONE FROM EACH OF THE THIRTEEN PROJECT CATEGORIES ON KICKSTARTER. ARISTOTLE'S CONCEPT OF ETHOS, PATHOS, AND LOGOS SERVED AS A BASIC FRAMEWORK FOR DEVELOPING A MORE DETAILED CLASSIFICATION OF RHETORICAL MEANS OF PERSUASION USED IN THE PROJECTS. RESULTS: THE MOST-FUNDED PROJECTS HAVE BEEN FOUND TO CONTAIN ALL THREE TYPES OF RHETORICAL APPEALS (ETHOS, PATHOS, AND LOGOS), SUBDIVIDED INTO A TOTAL OF TWELVE SPECIFIC SUBTYPES MOST COMMONLY ENCOUNTERED IN THE DESCRIPTIONS FROM THE SAMPLE. THE SUBTYPE DEFINITIONS HAVE BEEN DEVELOPED AND REFINED OVER THE COURSE OF SEVERAL REVIEWS. CONCLUSION: THE RESEARCH DATA MADE IT POSSIBLE TO CREATE A ``RHETORICAL PROFILE'' OF A SUCCESSFUL CROWD FUNDING PROJECT DESCRIPTION REPRESENTING A SUMMARY OF THE RHETORICAL TECHNIQUES IDENTIFIED DURING THE STUDY. ALTHOUGH THIS SUMMARY REFLECTS A HYPOTHETICAL ALL-INCLUSIVE CASE, IT CAN BE USED AS A BENCHMARK WHEN DRAFTING CROWD FUNDING PROJECT DESCRIPTIONS. THE STUDY ALSO IDENTIFIED SPECIFIC DIRECTIONS FOR FUTURE RESEARCH THAT COULD DETERMINE THE INFLUENCE OF PROJECT DESCRIPTION RHETORIC ON DONOR DECISIONS.\"                                                                                                                                            \n[5] \"PURPOSE: I ARGUE THAT EMOTIONAL APPEALS, PREVALENT IN CHARTS AND GRAPHS DURING THE LATER NINETEENTH CENTURY BUT LARGELY DORMANT SINCE THEN, HAVE RAPIDLY RE-EMERGED IN CONTEMPORARY DATA VISUALIZATION. CHANGING THE RELATIONSHIP BETWEEN DESIGNER AND USER, THIS NEW FORM OF DATA DESIGN HAS INTENSIFIED THE AFFECTIVE IMPACT OF DATA DISPLAYS BY ELICITING EMOTIONS RANGING FROM EXCITEMENT AND EMPATHY TO ANXIETY AND FEAR. METHODS: THIS ARTICLE DRAWS ON HISTORICAL AND CONTEMPORARY SOURCES TO BUILD ITS CASE. IT GIVES AN OVERVIEW OF EMOTIONAL APPEALS IN THE RHETORICAL TRADITION, FROM ARISTOTLE TO MODERN THEORISTS LIKE GEORGE CAMPBELL, WHO EMPHASIZED SENSORY RESPONSES THROUGH PERSONALIZATION AND PROXIMITY. THE ARTICLE PROVIDES AN HISTORICAL OVERVIEW OF PATHOS APPEALS IN DATA DESIGN DURING THE LATER NINETEENTH CENTURY AND THE SHIFT TO MODERNIST MINIMALISM IN THE TWENTIETH CENTURY. CONTEMPORARY EXAMPLES FROM COMPANIES, NONPROFITS, GOVERNMENT AGENCIES, AND INDIVIDUAL DESIGNERS ILLUSTRATE HOW DATA VISUALIZATION AROUSES EMOTION. RESULTS: EMOTIONAL APPEALS DURING THE NINETEENTH CENTURY FOCUSED PRIMARILY ON COLOR AND DESIGN NOVELTY, WHICH, BY APPEALING LARGELY TO THE SENSES, FOSTERED EMOTIONAL RESPONSES SUCH AS EXCITEMENT AND CURIOSITY. CONTEMPORARY DATA VISUALIZATION MAKES SIMILAR EMOTIONAL APPEALS THROUGH THE USE OF COLOR, NOVELTY, AND MULTIMODAL FEATURES; HOWEVER, DIGITAL TECHNOLOGY ALSO ALLOWS DESIGNERS TO APPEAL TO THE EMOTIONS BY PERSONALIZING DISPLAYS THROUGH INTERACTIVITY, SPATIAL AND TEMPORAL PROXIMITY, AND AESTHETIC AND EXPRESSIVE ELEMENTS. CONCLUSION: PATHOS (EMOTIONAL) APPEALS HAVE BECOME AN INTEGRAL PART OF CONTEMPORARY DATA VISUALIZATION, LARGELY BECAUSE OF THE MULTIMODAL AND INTERACTIVE AFFORDANCES OF DIGITAL TECHNOLOGY. DESIGNERS WHO UNDERSTAND THIS DIMENSION OF DATA DESIGN CAN DEPLOY TECHNOLOGY TO MAKE THEIR DISPLAYS MORE ENGAGING, HUMANE, AND USABLE.\"\n[6] \"ANALOGICAL REASONING HAS LONG BEEN AN IMPORTANT TOOL IN THE PRODUCTION OF SCIENTIFIC KNOWLEDGE, YET MANY SCIENTISTS REMAIN HESITANT TO FULLY ENDORSE (OR EVEN ADMIT) ITS USE. AS THE TEACHERS OF SCIENTIFIC AND TECHNICAL WRITERS, WE HAVE AN OPPORTUNITY AND RESPONSIBILITY TO TEACH THEM TO USE ANALOGY WITHOUT THEIR WRITING BECOMING ``OVERLY INDUCTIVE,'' AS ARISTOTLE WARNED. TO THAT END, I HERE OFFER AN ANALYSIS OF AN EXAMPLE OF THE EFFECTIVE USE OF ANALOGY IN RODNEY BROOKS'S ``INTELLIGENCE WITHOUT REPRESENTATION.'' IN THIS ARTICLE, BROOKS PROVIDES A MODEL FOR INCORPORATING THESE TOOLS INTO AN ARGUMENT BY BUILDING FOUR OF THEM INTO AN ENTHYMEME THAT CLEARLY ORGANIZES HIS ARGUMENT. THIS COMBINATION OF INDUCTIVE AND DEDUCTIVE REASONING HELPED THE ARTICLE BECOME A VERY INFLUENTIAL PIECE OF SCHOLARSHIP IN ARTIFICIAL INTELLIGENCE RESEARCH, AND IT CAN HELP OUR STUDENTS LEARN TO USE ANALOGY IN THEIR OWN WRITING.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n\n\nFilter articles that contain one of the keywords in either title or abstract\n\nCodesearch_words &lt;- c(\"Intersectionality\", \"Intersectional\")\n\n# Filter the data frame to select rows with at least one word from the list in column1 or column2\nintersectional &lt;- M %&gt;% \n  rowwise() %&gt;%\n  filter(any(str_detect(c(TI, AB), regex(paste(search_words, collapse = \"|\"), ignore_case = TRUE))))\n\nintersectional$TI\n\n [1] \"BUILDING TOWARD MORE JUST DATA PRACTICES\"                                                                                                          \n [2] \"PRIORITIZING ACCESS AS A SOCIAL JUSTICE CONCERN: ADVOCATING FOR ABLEISM STUDIES AND DISABILITY JUSTICE IN TECHNICAL AND PROFESSIONAL COMMUNICATION\"\n [3] \"PLAIN LANGUAGE TO MINIMIZE COGNITIVE LOAD: A SOCIAL JUSTICE PERSPECTIVE\"                                                                           \n [4] \"LIVING TESTIMONIOS: HOW LATINX GRADUATE STUDENTS PERSIST AND ENACT SOCIAL JUSTICE WITHIN HIGHER EDUCATION\"                                         \n [5] \"EMBODYING PUBLIC FEMINISMS: COLLABORATIVE INTERSECTIONAL MODELS FOR ENGAGEMENT\"                                                                    \n [6] \"FEMINIST DIGITAL RESEARCH METHODOLOGY FOR RHETORICIANS OF HEALTH AND MEDICINE\"                                                                     \n [7] \"``CHANGING THE FACE OF TECHNOLOGY'': STORYTELLING AS INTERSECTIONAL FEMINIST PRACTICE IN CODING ORGANIZATIONS\"                                     \n [8] \"INCREASING INCLUSION IN TECHNICAL COMMUNICATION ACADEMIC PROGRAMS\"                                                                                 \n [9] \"RISKING DISCLOSURE: UNRULY RHETORICS AND QUEER(ING) HIV RISK COMMUNICATION ON GRINDR\"                                                              \n[10] \"SUPERDIVERSITY: AN AUDIENCE ANALYSIS PRAXIS FOR ENACTING SOCIAL JUSTICE IN TECHNICAL COMMUNICATION\"                                                \n[11] \"HEALTH AND WELLNESS AS RESISTANCE: TACTICAL FOLK MEDICINE\""
  },
  {
    "objectID": "demos/week09/wk09_networks_pt2.html#explore-new-data-in-bibliometrix",
    "href": "demos/week09/wk09_networks_pt2.html#explore-new-data-in-bibliometrix",
    "title": "Wk 09: Network Analysis, pt 2",
    "section": "Explore new data in bibliometrix",
    "text": "Explore new data in bibliometrix\nTake the result of your filtering and analyze it!\nStock descriptive analysis\n\nCode# run a stock analysis (generates a list of dataframes)\nresults &lt;- biblioAnalysis(intersectional, sep = \";\")\n\n# create a summary of the results\noptions(width=100)\nS &lt;- summary(object = results, k = 10, pause = FALSE)\n\n\n\nMAIN INFORMATION ABOUT DATA\n\n Timespan                              2017 : 2023 \n Sources (Journals, Books, etc)        4 \n Documents                             11 \n Annual Growth Rate %                  0 \n Document Average Age                  2 \n Average citations per doc             2.182 \n Average citations per year per doc    0.5476 \n References                            569 \n \nDOCUMENT TYPES                     \n article      11 \n \nDOCUMENT CONTENTS\n Keywords Plus (ID)                    28 \n Author's Keywords (DE)                74 \n \nAUTHORS\n Authors                               17 \n Author Appearances                    17 \n Authors of single-authored docs       7 \n \nAUTHORS COLLABORATION\n Single-authored docs                  7 \n Documents per Author                  0.647 \n Co-Authors per Doc                    1.55 \n International co-authorships %        0 \n \n\nAnnual Scientific Production\n\n Year    Articles\n    2017        1\n    2018        1\n    2021        3\n    2022        5\n    2023        1\n\nAnnual Percentage Growth Rate 0 \n\n\nMost Productive Authors\n\n   Authors        Articles Authors        Articles Fractionalized\n1   ALEXANDER JJ         1  BENNETT KC                        1.0\n2   BENNETT KC           1  CARDINAL A                        1.0\n3   CARDINAL A           1  CHEUNG IW                         1.0\n4   CARLSON EB           1  DAYLEY C                          1.0\n5   CHEUNG IW            1  DE HERTOGH LB                     1.0\n6   DAVIS C              1  GREEN MK                          1.0\n7   DAYLEY C             1  REA EA                            1.0\n8   DE HERTOGH LB        1  ALEXANDER JJ                      0.5\n9   DELEON RL            1  CARLSON EB                        0.5\n10  EDENFIELD AC         1  DELEON RL                         0.5\n\n\nTop manuscripts per citations\n\n                                 Paper                                    DOI TC TCperYear   NTC\n1  DE HERTOGH LB, 2018, J. Bus. Tech. Commun.   10.1177/1050651918780188       7     1.167 1.000\n2  CHEUNG IW, 2017, IEEE Trans. Prof. Commun.   10.1109/TPC.2017.2759639       6     0.857 1.000\n3  ALEXANDER JJ, 2021, Tech. Commun. Q.         10.1080/10572252.2021.1930181  5     1.667 1.667\n4  GREEN MK, 2021, Tech. Commun. Q.             10.1080/10572252.2021.1930185  3     1.000 1.000\n5  BENNETT KC, 2022, IEEE Trans. Prof. Commun.  10.1109/TPC.2022.3140570       1     0.500 2.500\n6  MCKOY T, 2022, IEEE Trans. Prof. Commun.     10.1109/TPC.2022.3143352       1     0.500 2.500\n7  REA EA, 2021, Tech. Commun.                  NA                             1     0.333 0.333\n8  GOUGE CC, 2022, IEEE Trans. Prof. Commun.    10.1109/TPC.2021.3137675       0     0.000 0.000\n9  PHILLIPS LL, 2022, IEEE Trans. Prof. Commun. 10.1109/TPC.2022.3140569       0     0.000 0.000\n10 DAYLEY C, 2023, Tech. Commun.                10.55177/tc963195              0     0.000   NaN\n\n\nMost Relevant Sources\n\n                                   Sources        Articles\n1 IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION        5\n2 TECHNICAL COMMUNICATION QUARTERLY                      3\n3 TECHNICAL COMMUNICATION                                2\n4 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION        1\n\n\nMost Relevant Keywords\n\n      Author Keywords (DE)      Articles  Keywords-Plus (ID)     Articles\n1  SOCIAL JUSTICE                      6 RACE                           4\n2  CULTURAL DIFFERENCES                3 TECHNICAL COMMUNICATION        3\n3  STATISTICS                          3 DESIGN                         2\n4  COMMUNICATION                       2 AIDS                           1\n5  EDUCATION                           2 BIG DATA                       1\n6  ETHICS                              2 CARE                           1\n7  GLOBAL COMMUNICATION                2 CHALLENGES                     1\n8  HEALTH/MEDICAL COMMUNICATION        2 CHOICE                         1\n9  RESEARCH METHODS                    2 COMMUNICATION                  1\n10 SOCIOLOGY                           2 DISCRIMINATION                 1\n\n\n\nCode#plot(x = results, k = 10, pause = FALSE)\n\n\nCitation analysis\nWhen writing about intersectionality, who do TC authors cite?\nMost cited articles\n\nCode# Get citations\nCR &lt;- citations(intersectional, field = \"article\", sep = \";\")\n\n# Top 50 most cited articles\ncbind(CR$Cited[1:50])\n\n                                                                                                                                                [,1]\nJONES NN, 2016, TECH COMMUN Q, V25, P211, DOI 10.1080/10572252.2016.1224655                                                                        7\nAGBOKA G. Y., 2014, J TECHNICAL WRITING, V44, P297                                                                                                 5\nANONYMOUS, 2011, PROGRAMMATIC PERSPEC                                                                                                              5\nWALTON R., 2019, TECHNICAL COMMUNICAT                                                                                                              5\nHAAS AM, 2012, J BUS TECH COMMUN, V26, P277, DOI 10.1177/1050651912439539                                                                          4\nSHELTON C, 2020, TECH COMMUN Q, V29, P18, DOI 10.1080/10572252.2019.1640287                                                                        4\nWILLIAMS M.F., 2014, COMMUNICATING RACE E                                                                                                          4\nAGBOKA GY, 2013, TECH COMMUN Q, V22, P28, DOI 10.1080/10572252.2013.730966                                                                         3\nJONES N. N., 2016, J TECH WRIT COMMUN, V46, P342, DOI DOI 10.1177/0047281616639472                                                                 3\nSALDA├A┬▒A J., 2016, CODING MANUAL QUALIT                                                                                                          3\nSHIVERS-MCNAIR A, 2017, TECH COMMUN-STC, V64, P97                                                                                                  3\nACHARYA, 2018, P 36 ACM INT C DES C, P1, DOI 10.1145/3233756.3233960, DOI 10.1145/3233756.3233960                                                  2\nAGBOKA G., 2012, J TECH WRIT COMMUN, V42, P159, DOI DOI 10.2190/TW.42.2.E                                                                          2\nALBERS M., 2003, J TECH WRIT COMMUN, V33, P263, DOI DOI 10.2190/6KJN-95QV-JMD3-E5EE                                                                2\nANONYMOUS, 2010, RHETORICA MOTION FEM                                                                                                              2\nANONYMOUS, 2012, FEMINIST RHETORICAL                                                                                                               2\nANONYMOUS, 2014, PROGRAMMATIC PERSPEC                                                                                                              2\nANONYMOUS, METHODOLOGIES RHETOR                                                                                                                    2\nCOLLINS PH, 2021, CONTEMP POLIT THEORY, V20, P690, DOI 10.1057/S41296-021-00490-0                                                                  2\nCRENSHAW K., 1989, UNIV CHICAGO LEG FOR, V140, P139                                                                                                2\nCRENSHAW K., 1989, UNIV CHICAGO LEG FOR, V1989, P139, DOI DOI 10.4324/9780429500480-5                                                              2\nDAYLEY C, 2020, TECH COMMUN Q, V29, P49, DOI 10.1080/10572252.2019.1635210                                                                         2\nEDENFIELD AC, 2019, TECH COMMUN Q, V28, P177, DOI 10.1080/10572252.2019.1607906                                                                    2\nEDENFIELD AC., 2019, J TECH WRIT COMMUN, V49, P433, DOI DOI 10.1177/0047281619871211                                                               2\nFROST EA, 2016, J BUS TECH COMMUN, V30, P3, DOI 10.1177/1050651915602295                                                                           2\nHAAS AM, 2018, KEY THEORETICAL FRAMEWORKS: TEACHING TECHNICAL COMMUNICATION IN THE TWENTY-FIRST CENTURY, P3, DOI 10.7330/9781607327585.C000        2\nJONES N. N., 2016, J TECH WRIT COMMUN, V46, P471, DOI 10.1177/0047281616653489, DOI 10.1177/0047281616653489                                       2\nJONES NN, 2017, BUS PROF COMMUN Q, V80, P6, DOI 10.1177/2329490616680360                                                                           2\nJONES NN, 2018, KEY THEORETICAL FRAMEWORKS: TEACHING TECHNICAL COMMUNICATION IN THE TWENTY-FIRST CENTURY, P241, DOI 10.7330/9781607327585.C010     2\nMILLER CR, 1979, COLL ENGL, V40, P610, DOI 10.2307/375964                                                                                          2\nMOORE KR, 2018, KEY THEORETICAL FRAMEWORKS: TEACHING TECHNICAL COMMUNICATION IN THE TWENTY-FIRST CENTURY, P185, DOI 10.7330/9781607327585.C008     2\nROSE EMMA, 2018, COMMUNICATION DESIGN QUARTERLY REVIEW, V6, P9, DOI 10.1145/3282665.3282667                                                        2\nSCOTT J. BLAKE, 2003, RISKY RHETORIC AIDS                                                                                                          2\nSHIVERS-MCNAIR ANN, 2019, COMPUTERS AND COMPOSITION, V51, P43, DOI 10.1016/J.COMPCOM.2018.11.005                                                   2\nWALTON R, 2019, J TECH WRIT COMMUN                                                                                                                 2\nWALTON R., 2016, J TECH WRIT COMMUN, V60, P402, DOI DOI 10.1177/0047281616653496                                                                   2\n*NAT BIOETH ADV CO, 2001, ETH POL ISS RES INV                                                                                                      1\nACEVEDO-GIL N, 2017, RACE ETHNIC EDUC-UK, V20, P829, DOI 10.1080/13613324.2017.1343294                                                             1\nAGARWAL P, 2020, FORBES                                                                                                                            1\nAGBOKA G. Y., 2013, CONNEXIONS, V1, P29                                                                                                            1\nAGBOKA G. Y., 2020, IEEE PROFESSIONAL CO                                                                                                           1\nAGBOKA G. Y., 2020, J TECH WRIT COMMUN, DOI 10.1177/0047281620901484, DOI 10.1177/0047281620901484                                                 1\nAGBOKA G. Y., 2020, J TECH WRIT COMMUN, V34, P159                                                                                                  1\nAGBOKA GY, 2018, KEY THEORETICAL FRAMEWORKS: TEACHING TECHNICAL COMMUNICATION IN THE TWENTY-FIRST CENTURY, P114, DOI 10.7330/9781607327585.C005    1\nAHMED AA, 2018, INTERACT COMPUT, V30, P53, DOI 10.1093/IWC/IWX018                                                                                  1\nAJANA B, 2017, DIGIT HEALTH, V3, DOI 10.1177/2055207616689509                                                                                      1\nALCOFF L, 1988, SIGNS, V13, P405, DOI 10.1086/494426                                                                                               1\nALFREY L, 2017, GENDER SOC, V31, P28, DOI 10.1177/0891243216680590                                                                                 1\nALLIANCE FOR BOARD DIVERSITY, 2017, MISS PIEC REP 2016 B                                                                                           1\nALLYN B., 2020, NPR                                                                                                                                1\n\n\nMost cited first authors\n\nCodeCR &lt;- citations(intersectional, field = \"author\", sep = \";\")\n\ncbind(CR$Cited[1:20])\n\n                 [,1]\nANONYMOUS          51\nJONES NN           14\nWALTON R           10\nAGBOKA G Y          9\nCRENSHAW K          8\nHAAS AM             7\nGONZALES L          5\nJONES N N           5\nSHELTON C           5\nAGBOKA GY           4\nEDENFIELD AC        4\nMOORE KR            4\nWILLIAMS M F        4\nCDC                 3\nCOLLINS PH          3\nFROST EA            3\nSALDA A A J         3\nSCOTT J BLAKE       3\nSHIVERS MCNAIR A    3\nACHARYA             2"
  },
  {
    "objectID": "demos/week10/wk10_reddit.html",
    "href": "demos/week10/wk10_reddit.html",
    "title": "Wk 10: Reddit API",
    "section": "",
    "text": "Using RedditExtractoR to collect data from the reddit API.\n\n\n\nRedditExtractoR documentation on Github\n\n\nYoutube tutorial on RedditExtractoR (16min, James Cook)"
  },
  {
    "objectID": "demos/week10/wk10_reddit.html#overview",
    "href": "demos/week10/wk10_reddit.html#overview",
    "title": "Wk 10: Reddit API",
    "section": "",
    "text": "Using RedditExtractoR to collect data from the reddit API.\n\n\n\nRedditExtractoR documentation on Github\n\n\nYoutube tutorial on RedditExtractoR (16min, James Cook)"
  },
  {
    "objectID": "demos/week10/wk10_reddit.html#collecting-data",
    "href": "demos/week10/wk10_reddit.html#collecting-data",
    "title": "Wk 10: Reddit API",
    "section": "Collecting data",
    "text": "Collecting data\nlibraries\n\nCode#install.packages(\"RedditExtractoR\")\nlibrary(RedditExtractoR)\nlibrary(tidyverse)\n\n\nGet thread metadata\nSome key arguments in find_thread_urls:\n\n\nsubreddit. This allows us to find the thread URLs for a particular subreddit. Alternatively, we could have used keywords = \"keyword\" to get posts by keyword instead of subreddit.\n\nsort_by. Here we designate the sorting method we want to apply to our search.\n\nkeyword search sort options: relevance, comments, new, hot, top\nnon-keyword search sort options: hot, new, top, rising\n\n\n\nperiod. Timeframe of results. Options: hour, day, week, month, year, all\n\n\nCodemy_threads &lt;- find_thread_urls(\n  subreddit = \"Professors\",\n  sort_by = \"new\",\n  period = \"week\"\n)\n\nglimpse(my_threads)\n\n\nGet thread comments\n\n\n\n\n\n\nWarning\n\n\n\nget_thread_content() can take a LONG time, depending on the number of URLs and the size of the corresponding threads.\n\n\n\nCodemy_comments &lt;- get_thread_content(\n  my_threads$url\n)\n\nglimpse(my_comments)\n\n\nThe reddit API will limit how many comments we can grab from each thread. Let’s check how many comments we have in our threads.\n\nCodelibrary(ggplot2)\nlibrary(ggthemes)\n\n# Create a histogram\nggplot(my_threads, aes(x = comments)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n  labs(title = \"Distribution of Number of Comments\", x = \"Number of Comments\", y = \"Frequency\") +\n  theme_minimal()\n\n\nJoin my_threads and my_comments$comments\n\nCodemy_both &lt;- my_threads %&gt;%\n  left_join(my_comments$comments, by = \"url\")\n\nglimpse(my_both)\n\n\ntrying more URLs\n\nCodemy_threads_all &lt;- find_thread_urls(\n  subreddit = \"Professors\",\n  sort_by = \"new\",\n  period = \"all\"\n)\n\nglimpse(my_threads_all)\n\n\n\nCodemy_threads_profgpt &lt;- find_thread_urls(\n  subreddit = \"Professors\",\n  keywords = \"chatgpt\",\n  sort_by = \"new\",\n  period = \"all\"\n)\n\nglimpse(my_threads_profsgpt)\n\n\nFinding subreddits\nIf we want multiple subreddits, there’s a function called find_subreddits() that allows us to search for relevant subreddits based on keywords.\n\nCode#help(\"find_subreddits\")\nmy_subreddits &lt;- find_subreddits(\"food stamps\")\n\nglimpse(my_subreddits)\n\n\nWe can get a list of the subreddit names that the keyword search turned up:\n\nCodemy_subreddits$subreddit\n\n\nWe could in theory perform find_thread_urls() on all of them, but we’ll just target a few:\n\nCodetarget_subreddits &lt;- c(\"Conservative\",\n                       \"Libertarian\",\n                       \"progressive\",\n                       \"democrats\",\n                       \"Liberal\")\ntarget_subreddits"
  },
  {
    "objectID": "demos/week10/wk10_reddit.html#getting-a-big-dataset",
    "href": "demos/week10/wk10_reddit.html#getting-a-big-dataset",
    "title": "Wk 10: Reddit API",
    "section": "Getting a big dataset",
    "text": "Getting a big dataset\nMaybe we can abide by the API limits and still get a pretty sizeable dataset?\nUsing purrr to find_thread_urls\n\nHere, we use the map function from the tidyverse library purr to politely iterate over a list of subreddits\nIn the code below, we:\n\ndefine a list of subreddits\ncreate a function that:\nperforms find_thread_urls on a target subreddit (with keywords, sort, and period parameters)\nPrints to the console what subreddit the function is working on\ndefines an amount of time between 3 and 7 seconds and then waits that amount of time before proceeding to the next subreddit\nreturns the result\nwe use purrr::map to apply that function to each subreddit in our list of target subreddits\nfinally, we combine our results for each subreddit into a single dataframe\n\n\nCodelibrary(purrr)\n\n# Define the vector of subreddit names\ntarget_subreddits &lt;- c(\"Conservative\", \"Libertarian\", \"progressive\", \"democrats\", \"Liberal\")\n\n# Initialize an empty list to store the results\nresults_list &lt;- list()\n\n# Define the function to process a single subreddit \nprocess_subreddit &lt;- function(subreddit) {\n  \n  find_threads &lt;- find_thread_urls(\n    subreddit = subreddit,\n    keywords = \"food stamps\",\n    sort_by = \"new\",\n    period = \"all\"\n  )\n  \n  cat(\"Processing subreddit:\", subreddit, \"\\n\")\n  \n  # Generate a random sleep duration between 3 and 7 seconds\n  sleep_duration &lt;- runif(1, min = 6, max = 7)\n  cat(\"Sleeping for\", sleep_duration, \"seconds\\n\")\n  Sys.sleep(sleep_duration)\n  \n  # Return the result\n  return(find_threads)\n}\n\n# Use purrr::map to apply the function to each subreddit name\nresults_list &lt;- map(target_subreddits, process_subreddit)\n\n# Combine the results into a single dataframe\ntarget_results &lt;- bind_rows(results_list)\n\n\nNow target_results contains the results for all our target subreddits in a single dataframe. We can save these out for later use, if needed.\n\nCode# Save out as needed\n#write_csv(target_results, \"data/food_stamps/ideology_foodstamps.csv\")\n#saveRDS(target_results, \"data/food_stamps/ideology_foodstamps.rds\")\n\n\nNow we can visualize the results to see how many threads we collected from each subreddit in our list\n\nCode# Calculate the total number of threads for each subreddit\nsubreddit_totals &lt;- target_results %&gt;%\n  group_by(subreddit) %&gt;%\n  summarise(total_threads = n())\n\n# Create a bar plot with totals\nggplot(subreddit_totals, aes(x = subreddit, y = total_threads)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = total_threads), vjust = -0.5, size = 3) +\n  labs(x = \"Subreddit\", y = \"Number of Threads\") +\n  ggtitle(\"Number of Threads Collected from Each Subreddit\") +\n  theme_minimal()\n\n\nUsing Purrr to get_thread_content\n\nIf you need the data and have the time to collect it, we can use purr again. Instead of collecting all the threads for a given subreddit, pausing, and moving on to the next subreddit, this time we’ll collect all the comments for a thread, pause, and then move on to the next thread.\n\n\n\n\n\n\nWarning\n\n\n\nget_thread_content() can take a LONG time, depending on the number of URLs and the size of the corresponding threads.\n\n\nJust how big are the threads we’re about to collect?\n\nCode# Create a histogram\nggplot(target_results, aes(x = comments)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n  labs(title = \"Distribution of Number of Comments\", x = \"Number of Thread Comments\", y = \"Frequency\") +\n  theme_minimal()\n\n\nAgain, this next one would take a LONG time, e.g. over two hours for me to grab the comments for 835 threads. Instead, we’ll start by testing on a subset."
  },
  {
    "objectID": "demos/week10/wk10_reddit.html#subset-the-data-for-testing",
    "href": "demos/week10/wk10_reddit.html#subset-the-data-for-testing",
    "title": "Wk 10: Reddit API",
    "section": "Subset the data for testing",
    "text": "Subset the data for testing\nGenerate a sample threads list\n\nCodeset.seed(123) # Set a seed for reproducibility\n\n\n# Sample a specific number of rows from the data frame (e.g., 2%)\nsample_size &lt;- 0.02 * nrow(target_results)\n\n# Create a new data frame with the random sample\ntr_sample &lt;- target_results %&gt;%\n  sample_n(size = sample_size, replace = FALSE)\n\nglimpse(tr_sample)\n\n\nAdapted: define function to get comments and thread title and url from list of threads\n\nCode### ADAPTED CODE\n\n# Define the modified function to collect comments for a given URL\ncollect_comments &lt;- function(url, title) {\n  tryCatch({\n    # Call the get_thread_content function with the URL\n    content &lt;- get_thread_content(url)\n    \n    # Check if content$comments is empty or NULL, and skip if it is\n    if (is.null(content$comments) || nrow(content$comments) == 0) {\n      cat(\"No comments found for URL:\", url, \"\\n\")\n      return(NULL)\n    }\n    \n    # Add the \"thread_url\" column with the URL value to content$comments\n    content$comments &lt;- content$comments %&gt;% mutate(thread_url = url)\n    \n    # Add the \"thread_title\" column with the title\n    content$comments &lt;- content$comments %&gt;% mutate(thread_title = title)\n    \n    \n    # Convert \"comment_id\" to character to ensure consistent data types\n    content$comments &lt;- content$comments %&gt;% mutate(comment_id = as.character(comment_id))\n    \n    # Introduce a random pause between 6-7 seconds\n    sleep_duration &lt;- runif(1, min = 6, max = 7)\n    Sys.sleep(sleep_duration)\n    \n    # Return content$comments\n    return(content$comments)\n  }, error = function(e) {\n    cat(\"Error collecting comments for URL:\", url, \"\\n\")\n    return(NULL)\n  })\n}\n\n# Use purrr::map to apply the function to each URL with a progress bar\nsamp_comments_list2 &lt;- map2(tr_sample$url, tr_sample$title, collect_comments, .progress = \"getting thread comments\")\n\n# Filter out NULL elements (URLs with no comments)\nsamp_comments_list2 &lt;- samp_comments_list2[!sapply(samp_comments_list2, is.null)]\n\n# Combine all the comments data frames into a single data frame\ncombined_comments &lt;- bind_rows(samp_comments_list2)\n\n\nLet’s see what we got\n\nCodeglimpse(combined_comments)"
  }
]